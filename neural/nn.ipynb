{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu, relu\n",
    "import time\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import optax\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n",
    "num_particles = 2\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases for each layer\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        if hidden_sizes != [0]:\n",
    "            sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        else:\n",
    "            sizes = [input_size, output_size]\n",
    "\n",
    "        for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1])\n",
    "            b = np.random.randn(1, sizes[i+1])\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def __call__(self, x, params):\n",
    "        self.weights, self.biases = self.unflatten_params(params)\n",
    "        a = x\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = jnp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = celu(z)\n",
    "        a = jnp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        return a[0][0]\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def flatten_params(self):\n",
    "        params = jnp.array([])\n",
    "        for i in range(len(self.weights)):\n",
    "            params = jnp.concatenate((params, self.weights[i].flatten()))\n",
    "            params = jnp.concatenate((params, self.biases[i].flatten()))\n",
    "        return jnp.array(params)\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def unflatten_params(self, params):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        start = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            end = start + self.weights[i].size\n",
    "            weights.append(jnp.reshape(jnp.array(params[start:end]), self.weights[i].shape))\n",
    "            start = end\n",
    "            end = start + self.biases[i].size\n",
    "            biases.append(jnp.reshape(jnp.array(params[start:end]), self.biases[i].shape))\n",
    "            start = end\n",
    "        return weights, biases\n",
    "    \n",
    "\n",
    "# initialize the network\n",
    "nn = NeuralNetwork(num_particles, [20], 1)\n",
    "\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return jnp.exp(-nn(coords, params)) * jnp.exp(-coords**2)\n",
    "\n",
    "@jit\n",
    "def sample_body(coords_t, params, key, variation_size):    \n",
    "    gen_rand = jax.random.uniform(key, minval=-variation_size, maxval=variation_size)\n",
    "    new_key, subkey = jax.random.split(key)\n",
    "    \n",
    "    coords_prime = coords_t + gen_rand\n",
    "    temp_rand = jax.random.uniform(subkey, minval=0, maxval=1)\n",
    "    return (jax.lax.cond(temp_rand < psi(coords_prime, params)**2/psi(coords_t, params)**2, lambda x, _: x, lambda _, y : y, coords_prime, coords_t), new_key)\n",
    "\n",
    "def sample(params, num_samples=10**3, thermalization_steps=200, skip_count=50, variation_size=1.0, key=jax.random.PRNGKey(np.random.randint(0,10000)), skipping = True):\n",
    "    outputs = []\n",
    "    all_data = []\n",
    "\n",
    "    coords_t = np.random.uniform(-variation_size, variation_size)\n",
    "    for step in range(num_samples*skip_count + thermalization_steps + 1):\n",
    "        coords_t, key = sample_body(coords_t, params, key, variation_size)\n",
    "        if ((step > thermalization_steps) & (step % skip_count == 0) & (skipping == True)):\n",
    "            outputs.append(coords_t)\n",
    "        elif skipping == False:\n",
    "            all_data.append(coords_t)\n",
    "    if skipping == False:\n",
    "        return all_data\n",
    "    return jnp.array(outputs)\n",
    "\n",
    "\n",
    "# sample_body function except it also returns whether or not the move was accepted\n",
    "@jit\n",
    "def sample_body_accept(coords_t, params, key,variation_size):\n",
    "    gen_rand = jax.random.uniform(key, minval=-variation_size, maxval=variation_size)\n",
    "    new_key, subkey = jax.random.split(key)\n",
    "    \n",
    "    coords_prime = coords_t + gen_rand\n",
    "    condition = jax.random.uniform(subkey, minval=0, maxval=1) < psi(coords_prime, params)**2/psi(coords_t, params)**2\n",
    "    return (jax.lax.cond(condition, lambda x, _: x, lambda _, y : y, coords_prime, coords_t), new_key, condition)\n",
    "\n",
    "\n",
    "# the sample function without any thermalization steps or skipping steps\n",
    "def accept_ratio(params, num_samples=10**3, variation_size=5.0, key=jax.random.PRNGKey(np.random.randint(0,100))):\n",
    "    coords_t = np.random.uniform(-variation_size, variation_size)\n",
    "    num_accepted = 0\n",
    "    for _ in range(num_samples):\n",
    "        coords_t, key, accepted = sample_body_accept(coords_t, params, key, variation_size)\n",
    "        if accepted:\n",
    "            num_accepted += 1\n",
    "\n",
    "    return num_accepted / num_samples\n",
    "\n",
    "\n",
    "\n",
    "# second derivative of the wavefunction with respect to the coordinate\n",
    "ddpsi = jit(grad(jit(grad(psi, 0, allow_int = True)), 0, allow_int = True))\n",
    "\n",
    "@jit\n",
    "def Hpsi(coords, params):\n",
    "    return (m*.5*omega**2*coords**2) - hbar**2 / (2*m) * ddpsi(coords, params) * 1/psi(coords, params)\n",
    "\n",
    "venergy = jit(vmap(Hpsi, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def logpsi(coords, params):\n",
    "    return jnp.log(psi(coords, params))\n",
    "\n",
    "# define the derivative with respect to every parameter of the log of psi:\n",
    "dlogpsi_dtheta_stored = jit(grad(logpsi, 1))\n",
    "\n",
    "vlog_term = jit(vmap(dlogpsi_dtheta_stored, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "vboth = vmap(jnp.multiply, in_axes=(0, 0), out_axes=0)\n",
    "\n",
    "def gradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False):\n",
    "    # get the samples\n",
    "    samples = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    psiHpsi = venergy(samples, params)\n",
    "    logs = vlog_term(samples, params)\n",
    "    \n",
    "    uncert = jnp.std(psiHpsi)/jnp.sqrt(num_samples)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(psiHpsi)\n",
    "    if verbose:\n",
    "        print(energy)\n",
    "    log_term = 1/num_samples * jnp.sum(logs,0)\n",
    "\n",
    "    both = 1/num_samples * jnp.sum(vboth(psiHpsi, logs),0)\n",
    "\n",
    "    gradient_calc = (2 * both - 2 * energy * log_term)\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "# define a function that takes in samples, bins them, and returns the average of each bin\n",
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "# define a function that gets all samples, and then bins them with different bin sizes\n",
    "def autocorrelation(params):\n",
    "    samples = sample(params, num_samples=10**3, thermalization_steps=200, skip_count=40, variation_size=1, key=jax.random.PRNGKey(np.random.randint(0,100)), skipping = False)\n",
    "    energies = [Hpsi(s, params) for s in samples]\n",
    "    \n",
    "    bins = np.linspace(1, 100, 100, dtype=int)\n",
    "    # now plot the average energy as a function of the number of bins\n",
    "    us = []\n",
    "    for b_size in bins:\n",
    "        us.append(bin_samples(energies, b_size))\n",
    "    plt.scatter(bins, us)\n",
    "    plt.title(\"Bin size vs. Uncertainty\")\n",
    "    plt.xlabel(\"Bin size\")\n",
    "    plt.ylabel(\"Uncertainty\")\n",
    "    plt.show()\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, optimizer):\n",
    "    hs = []\n",
    "    us = []\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    def step(params, opt_state, N, thermal, skip, variation_size):\n",
    "        gr = gradient(params, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        hs.append(gr[1])\n",
    "        us.append(gr[2])\n",
    "        updates, opt_state = optimizer.update(gr[0], opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return params, opt_state, gr[1]\n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "    for step_num in pbar:   \n",
    "        params, opt_state, energy = step(params, opt_state, N, thermal, skip, variation_size)\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept/Reject ratio 0.491\n"
     ]
    }
   ],
   "source": [
    "variation = 1.4\n",
    "print(\"Accept/Reject ratio\",accept_ratio(nn.flatten_params(), num_samples=10**3, variation_size=variation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
