{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 3\n",
    "N_down = 3\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"3+3/large_g_150_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.150851788756388\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143106\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:02<00:00, 1978.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5400901783963928\n"
     ]
    }
   ],
   "source": [
    "step_size = .4\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 22.32392974218153: 100%|██████████| 100/100 [54:27<00:00, 32.67s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=10\n",
    "# first find the step size\n",
    "step_size = .4\n",
    "resultsa = train(params, 40, 2000, 1000, 10, step_size, g)\n",
    "resultsb = train(resultsa[3], 100,5000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 21.046131709791016: 100%|██████████| 50/50 [52:35<00:00, 63.11s/it] \n"
     ]
    }
   ],
   "source": [
    "resultsc = train(resultsb[3], 50,10000,1000,10, find_step_size(resultsb[3],step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 20.558729113548807: 100%|██████████| 15/15 [45:10<00:00, 180.70s/it]\n"
     ]
    }
   ],
   "source": [
    "resultsd = train(resultsc[3], 15,30000,1000,10, find_step_size(resultsc[3],step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0]+ resultsc[0] + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1]  + resultsc[1] + resultsd[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = .5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1\n",
    "resultsa = train(results_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_1 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.5\n",
    "resultsa = train(results_1, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_15 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2\n",
    "resultsa = train(results_15, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_2 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=2.5\n",
    "resultsa = train(results_2, 1000, 800, 100, 10, find_step_size(results_2,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_25 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -.5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1\n",
    "resultsa = train(results_neg_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# load the g=2.5 results from the checkpoint file \n",
    "params = load_params(\"5+5/large_g_150_params_g_2.5.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "params = load_params(\"5+5/large_g_150_params_g_3.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_35 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_4 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_45 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_55 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_6 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_65 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_7 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_75 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_8 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_85 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_9 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "g = 10\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# params = load_params(\"5+5/large_g_150_params_g_9.5.pkl\")\n",
    "params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "\n",
    "resultsa = train(params, 10, 30000, 1000, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 15,50000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = acc_train(resultsb[3], 10, 300000,1000,10, find_step_size(resultsb[3],step_size), g)\n",
    "resultsd = acc_train(resultsc[3], 10, 1000000, 10000,10, find_step_size(resultsc[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "g = 10\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10.5_extrapolated.pkl\")\n",
    "g = 10.5\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_11_extrapolated.pkl\")\n",
    "g = 11\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_11 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
