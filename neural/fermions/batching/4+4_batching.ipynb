{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"false\"\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "# jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 4\n",
    "N_down = 4\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"2+2/\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up] / SYM_DEN\n",
    "    sym_piece2 = reordered[N_up:] / SYM_DEN\n",
    "\n",
    "    new1 = [jnp.sum(sym_piece1 ** i) for i in range(1, N_up)]\n",
    "    new2 = [jnp.sum(sym_piece2 ** i) for i in range(1, N_down + 1)]\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1] / SYM_DEN\n",
    "    sym_piece2 = reordered[N_up + 1:] / SYM_DEN\n",
    "    \n",
    "    new1 = [jnp.sum(sym_piece1 ** i) for i in range(1, N_up + 1)]\n",
    "    new2 = [jnp.sum(sym_piece2 ** i) for i in range(1, N_down)]\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    rng = np.random.default_rng(int(time.time()))\n",
    "    randoms = rng.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = rng.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved:\n",
    "                counter += 1\n",
    "        \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = jnp.array(sq.copy())\n",
    "    for i in range(len(sq)):\n",
    "        a = jnp.array(sq[i])\n",
    "        a = a.at[N_up].set(a[0])\n",
    "        sq_prime = sq_prime.at[i].set(jnp.array(a))\n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        print(gr[0])\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "#TODO: stop precomputing all the random numbers and storing them, that takes too much memory\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "#     subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "#     randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "#     randoms = jnp.transpose(randoms)\n",
    "#     subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "#     limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev, stepkey = val\n",
    "        # get a random number between -stepsize and stepsize\n",
    "        rng_keys = jax.random.split(stepkey, 3)\n",
    "        random_1 = jax.random.uniform(rng_keys[0],(N,), jnp.float32, -stepsize, stepsize)\n",
    "        random_2 = jax.random.uniform(rng_keys[1], (), jnp.float32, 0.0, 1.0)\n",
    "#         new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        new, moved = mcstep_E(random_1, random_2, positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev, rng_keys[2]\n",
    "    \n",
    "    sq, positions_prev, key = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev, key))\n",
    "    del positions_prev\n",
    "    del key\n",
    "    \n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[N_up].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def batch_gradient(samples, samples_prime, params):\n",
    "    num_samples = len(samples)\n",
    "    ys = jnp.array(samples_prime[:, N_up])\n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "    \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def batch_step(params_arg, step_num, N, N_batches, thermal, skip, variation_size, g, start_key):\n",
    "    # compute the gradient for each batch\n",
    "    samples_per_batch = N//N_batches\n",
    "    grads = []\n",
    "    energies = []\n",
    "    uncerts = []\n",
    "    \n",
    "    def grad_wrapper(key):\n",
    "        samples, samples_prime = sample_pmap(params_arg, samples_per_batch, thermal, skip, variation_size, key)\n",
    "        return batch_gradient(samples, samples_prime, params_arg)\n",
    "\n",
    "    grad_pmap = jax.pmap(grad_wrapper, backend=\"cpu\")\n",
    "\n",
    "    inputs = jax.random.split(start_key, N_batches)\n",
    "    out = grad_pmap(inputs)\n",
    "    \n",
    "    # average the gradients\n",
    "    gradient_avg = jnp.mean(out[0], axis=0)\n",
    "\n",
    "    # average the averages\n",
    "    energy_calc = jnp.mean(out[1])\n",
    "    uncert_calc = jnp.sqrt(jnp.sum(jnp.square(out[2])))/N_batches\n",
    "    \n",
    "    \n",
    "    opt_state = opt_init(params_arg)\n",
    "    new = opt_update(step_num, gradient_avg, opt_state)\n",
    "    return get_params(new), energy_calc, uncert_calc\n",
    "\n",
    "\n",
    "def batch_train(params, iterations, N, N_batches, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = batch_step(old_params, step_num, N, N_batches, thermal, skip, variation_size, g, jax.random.key(int(time.time())))\n",
    "\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_ar(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "\n",
    "    sq = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    rng = np.random.default_rng(int(time.time()))\n",
    "    randoms = rng.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = rng.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved:\n",
    "                counter += 1\n",
    "        \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "\n",
    "\n",
    "    return jnp.array(sq), counter/num_total\n",
    "\n",
    "\n",
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(jax.devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.175383304940375\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193208\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:07<00:00, 750.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45992334610898183\n"
     ]
    }
   ],
   "source": [
    "step_size = .335\n",
    "samples = sample_ar(params, 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])\n",
    "# print(samples[0].shape)\n",
    "# print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 16.06917: 100%|██████████| 20/20 [42:00<00:00, 126.02s/it] \n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "\n",
    "resultsa = batch_train(params, 20, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0] \n",
    "# + resultsb[0] \n",
    "# + resultsc[0]  + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] \n",
    "\n",
    "# + resultsb[1]  \n",
    "# + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsa[3],\"4+4_data/g0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2104.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.523079486752208\n"
     ]
    }
   ],
   "source": [
    "step_size = .33\n",
    "samples = sample_ar(resultsa[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7afe30f3c65a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresultsb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultsa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-60f5247beca6>\u001b[0m in \u001b[0;36mbatch_train\u001b[0;34m(params, iterations, N, N_batches, thermal, skip, variation_size, g)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0mold_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mnew_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muncert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthermal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-60f5247beca6>\u001b[0m in \u001b[0;36mbatch_step\u001b[0;34m(params_arg, step_num, N, N_batches, thermal, skip, variation_size, g, start_key)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_pmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;31m# average the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filtering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0mexecute\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m       \u001b[0mexecute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_pmap_impl_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_bind_continuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mxla_pmap_impl_lazy\u001b[0;34m(fun, backend, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, is_explicit_global_axis_size, *args)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_emap_apply_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m   \u001b[0mabstract_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m   compiled_fun, fingerprint = parallel_callable(\n\u001b[0m\u001b[1;32m    412\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_axis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0min_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axes_thunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonated_invars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_stores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mparallel_callable\u001b[0;34m(fun, backend_name, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, is_explicit_global_axis_size, *avals)\u001b[0m\n\u001b[1;32m    676\u001b[0m                       \u001b[0mis_explicit_global_axis_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                       *avals):\n\u001b[0;32m--> 678\u001b[0;31m   pmap_computation = lower_parallel_callable(\n\u001b[0m\u001b[1;32m    679\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_axis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0min_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axes_thunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonated_invars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mlower_parallel_callable\u001b[0;34m(fun, backend_name, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, is_explicit_global_axis_size, avals, lowering_platform)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;34m\"Finished jaxpr to MLIR module conversion {fun_name} in {elapsed_time} sec\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         fun_name=str(name_stack), event=dispatch.JAXPR_TO_MLIR_MODULE_EVENT):\n\u001b[0;32m--> 882\u001b[0;31m       lowering_result = mlir.lower_jaxpr_to_module(\n\u001b[0m\u001b[1;32m    883\u001b[0m           \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0mclosed_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_module\u001b[0;34m(module_name, jaxpr, ordered_effects, backend_or_name, platform, axis_context, name_stack, donated_args, replicated_args, arg_shardings, result_shardings, arg_names, result_names, num_replicas, num_partitions)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mhlo.num_replicas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi32_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_replicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mhlo.num_partitions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi32_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_partitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mreplace_tokens_with_dummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1176\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1178\u001b[0m                  **eqn.params)\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1372\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1031\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1162\u001b[0m             f\"found for platform {ctx.platform}\")\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0meqn_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0meffects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffects_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered_effects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m       \u001b[0mtokens_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, **kw)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeepalives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepalive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/dataclasses.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(*args, **changes)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[0;31m# If a field is not in 'changes', read its value from the provided obj.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_FIELDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m         \u001b[0;31m# Only consider normal fields or InitVars.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_FIELD_CLASSVAR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g = -.5\n",
    "\n",
    "resultsb = batch_train(resultsa[3], 5, 150000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] \n",
    "# + resultsc[0]  + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  \n",
    "# + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsb[3],\"4+4_data/g0.5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2107.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5385769038493584\n"
     ]
    }
   ],
   "source": [
    "step_size = .3\n",
    "samples = sample_ar(resultsb[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 13.405044: 100%|██████████| 20/20 [46:24<00:00, 139.23s/it]\n"
     ]
    }
   ],
   "source": [
    "g=-1\n",
    "\n",
    "resultsc = batch_train(resultsb[3], 20, 100000,64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] \n",
    "# + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1] \n",
    "# + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsc[3],\"4+4_data/g1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2047.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5539076820529911\n"
     ]
    }
   ],
   "source": [
    "step_size = .3\n",
    "samples = sample_ar(resultsc[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 12.035563: 100%|██████████| 20/20 [46:14<00:00, 138.74s/it] \n"
     ]
    }
   ],
   "source": [
    "g=-1.5\n",
    "\n",
    "resultsd = batch_train(resultsc[3], 20, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXzcV33v/9eZfR/NaEb7bkvyGjteYid24qyQBBrCUkpaaAopPKAb9FduS+G299IHvQ9u6aUbLSVlLxDKEgpJIJuzOCHxmsT7bsuy1tG+z35+f8xIlizJlmVJMyN9no9HHpK+s32kyO85+nzP9xyltUYIIUTuMWS6ACGEELMjAS6EEDlKAlwIIXKUBLgQQuQoCXAhhMhRpoV8sUAgoKuqqhbyJYUQIucdOHCgU2sdvPz4ggZ4VVUV+/fvX8iXFEKInKeUujDVcWmhCCFEjpIAF0KIHCUBLoQQOUoCXAghcpQEuBBC5CgJcCGEyFES4EIIkaNyIsDDsQShgXCmyxBCiKySEwH++SeOcv8/vZLpMoQQIqvkRID7HBZ6hmPI5hNCCHFJTgS432khkdT0h+OZLkUIIbJGzgQ4QPdQNMOVCCFE9siJAPdJgAshxCQ5EeD56QDvkQAXQogxORHgPoeMwIUQ4nI5EeBjPfBhCXAhhBiVEwHusBixmgzSQhFCiHFyIsCVUvgcFrokwIUQYkxOBDiAz2mWEbgQQoyTMwGe77TKCFwIIcbJmQD3Oy0yC0UIIcbJqQDvkVkoQggxJqcCfCAcJ5ZIZroUIYTICjkT4D65GlMIISbImQD3O+RiHiGEGO+qAa6UKldKvaiUOq6UOqqU+mT6uF8p9ZxS6nT6o28+C5UVCYUQYqKZjMDjwJ9prVcCW4E/VEqtAj4D7NRa1wI701/PG/9YCyU2ny8jhBA546oBrrVu1Vq/kf58ADgOlALvAr6Tvtt3gAfnq0hIXcgD0D0Umc+XEUKInHFNPXClVBVwI7AHKNRat0Iq5IGCaR7zMaXUfqXU/o6OjlkXemlFQhmBCyEEXEOAK6VcwE+BT2mt+2f6OK31o1rrTVrrTcFgcDY1AmA2GvDYTDIXXAgh0mYU4EopM6nw/r7W+vH04XalVHH69mIgND8lXuJzyoJWQggxaiazUBTwDeC41vrL4276BfBw+vOHgZ/PfXkTpS6nlx64EEIAmGZwn23Ah4DDSqm30sc+C3wR+JFS6hGgEfjN+Snxknynhebekfl+GSGEyAlXDXCt9auAmubmu+a2nCvzOSwcbu5byJcUQoislTNXYgL4XRZ6hmNorTNdihBCZFxuBbjDQjSeZDiayHQpQgiRcTkV4D65nF4IIcbkVIDnS4ALIcSYnArwsRG4XMwjhBC5FeBjS8oOSoALIURuBbgrvSKhjMCFECK3AtxtNWEyKOmBCyEEORbgSil8DtmdXgghIMcCHEbXQ5EAF0IICXAhhMhREuBCCJGjcjLAZRaKEELkYID7nBZ6R2IkkrKglRBiacu5APc7zGgNvTIKF0IscbkX4C4rIBfzCCFE7gW47E4vhBBADga4z2kGkL0xhRBLXs4FeL4z1UKREbgQYqnLuQDPc6RG4NIDF0IsdTkX4DazEafFSJcsKSuEWOJyLsBBLuYRQgjI0QD3yeX0QgiRmwEu66EIIYQEuBBC5KyrBrhS6ptKqZBS6si4Y+uVUruVUm8ppfYrpW6a3zIn8jukBy6EEDMZgX8buPeyY38HfF5rvR746/TXC8bntDAcTRCOJRbyZYUQIqtcNcC11ruA7ssPA570516gZY7ruqJ85+jl9DIKF0IsXaZZPu5TwDNKqb8n9SZwy9yVdHW+cQFekmdfyJcWQoisMduTmJ8A/lRrXQ78KfCN6e6olPpYuk++v6OjY5YvN5E/HeDSBxdCLGWzDfCHgcfTn/8YmPYkptb6Ua31Jq31pmAwOMuXm6g0Peo+3T44J88nhBC5aLYB3gLsSH9+J3B6bsqZmZI8O9UBJy+fmpsRvRBC5KKr9sCVUo8BtwMBpVQT8L+AjwL/pJQyAWHgY/NZ5FRurw/ygz2NhGMJbGbjQr+8EEJk3FUDXGv90DQ3bZzjWq7J7fUFfOvXDew5382OurlpzQghRC7JySsxAbZU+7GaDLx8UtooQoilKWcD3GY2srUmnxdPhjJdihBCZETOBjjAjrog5zuHuNg9nOlShBBiweV2gNenet8yG0UIsRTldIDXBJyU+ewS4EKIJSmnA1wpxe31QX59ppNoPJnpcoQQYkHldIAD7KgrYDiaYP+Fy9fbEkKIxS3nA/zmZfmYjUraKEKIJSfnA9xlNbGp0i/zwYUQS07OBzikLqs/0TZAe38406UIIcSCWRQBPjadUEbhQoglZFEEeH2hmwK3lWeOtmW6FCGEWDCLIsCVUjx0UwU7T4TYfa4r0+UIIcSCWBQBDvDxHcsozbPzV/99hFhC5oQLIRa/RRPgdouR//3Aak6HBvnOaw2ZLkcIIebdoglwgLtXFnBHfZAvP3dKZqQIIRa9RRXgSin+9wOriSc0X3jyWKbLEUKIebWoAhygMt/JJ25fxhOHWnntbGemyxFCiHmz6AIc4BO3L6PMlzqhORCOZbocIYSYF4sywG1mI194cA0NncO8819e5URbf6ZLEkKIObcoAxxSmx7/4KNbGI4mePArv+YnB5oyXZIQQsypRRvgAFtq8nnqT7azvjyPT//4IH/+k4OEY4lMlyWEEHNiUQc4QIHbxvd+fwt/eMcyfrS/iR1fepEf7GmUi32EEDlv0Qc4gMlo4H+8fQU//NhWirw2Pvuzw9z59y/x0wNNJJI60+UJIcSsKK0XLsA2bdqk9+/fv2CvNxWtNS+d7OBLz5zkWGs/LqsJs1GhNSTTP4vaQjebKn1sqPSxocJH0G0FIJnUxJJJtE6dKBVCiIWglDqgtd406fhSC/BRWmueOdrGK6c7UQoMSmFQingyyZHmfo629BFLpH42NpOBeFITHzda9zstVOU7qA64qMp38K71pVTkOzL17QghFrHpAtw0gwd+E3gnENJarxl3/I+BPwLiwFNa6z+fw3rnnVKKe9cUc++a4ilvD8cSHG3p48CFHkL9ESwmAxaTAbPRgNaapp4RznYM8srpDn76RoQT7QP8629vWODvQgixlF01wIFvA18Bvjt6QCl1B/Au4AatdUQpVTA/5WWOzWxkY6WfjZX+q9734/95gCPNfQtQlRBCXHLVk5ha613A5Vu+fwL4otY6kr5PaB5qyxmrSjxc6BpmMBLPdClCiCVktrNQ6oBblVJ7lFIvK6U2T3dHpdTHlFL7lVL7OzoW55Znq0s8ABxvlSs+hRALZ7YBbgJ8wFbgfwA/Ukqpqe6otX5Ua71Ja70pGAzO8uWy2+oSLwBHpY0ihFhAsw3wJuBxnbIXSAKBuSsrtxR6rPgcZo7JCFwIsYBmG+D/DdwJoJSqAyzAkl27VSnF6hIvR5olwIUQC+eqAa6Uegx4HahXSjUppR4BvgnUKKWOAD8EHtYLOaE8C60u9XA6NEA0LpfoCyEWxlWnEWqtH5rmpg/OcS05bVWxh1hCcyY0yKr0SU0hhJhPS2ItlIUwdiKzRU5kCiEWhgT4HKkOOLGbjXIiUwixYCTA54jRoKgvcssVmUKIBSMBPofWlHo43jpAUpaoFUIsAAnwObSq2MtgJE5Tz0imSxFCLAES4HNo9JJ6OZEphFgIEuBzqL7IjVEpOZEphFgQEuBzyGY2Uh10yolMIcSCkACfY2tLvRxpkRG4EGL+SYDPsdUlHjoGInQORjJdihBikZMAn2OrilMnMo8twVG41lqmUAqxgCTA59iqsZkoSyvAtdZ8+Fv7eN+/vyYhLsQCkQCfY3kOC8Ve25KbSvjEwVZeOtXBG429fPu1hkyXI8SSIAE+D1aXeOZkJsqRpj66h7K/lz4UifP5J46yvMDF6hIP//D8Kdr75WImIeabBPg8uLHCR0PXMJ/+8UF2n+3kZNsAof4w8cTM1gq/2D3MEwdbePhbe/nAo7uv2JI41T5A73D0uupt6xvh754+QWyWa5n/3TMn6BqK8n/fu5a/ffdaBsNxPvezIzP+foUQs3PV9cDFtfu9W6p47WwXPznQxIm2Ad57YylWsxGDgnyXlUKPlUKPDZfVRDyhiSWTJJKa4WiCk239dA/FONTUS9dQlK6hKF99+Qx/eEftpNfZ19DFB7++lwq/gy88uIbNVX4Mhim3Jp1WNJ7kkz98iz3nu4kmkvzPd6ya8n4NnUO8eDLEh7ZUYjJdet8/3T7A93Y38s4bitlY6QfgnlWFPH+8nZ++0cRvba64pnqEEDOnFnIjnU2bNun9+/cv2Otlktaav/jpIX68v4mA28rvbKmgwG2b8WO/+vJZYokkXruZ5t4Rnv7kbZT7HWP36R6K8MBXfk3HQIRYIkmB28Yf37mc+9YW43daZvw6X3/lPH/7y+NYTAYU8NhHt7Kh0jfhfr1DUe7/l1do6Q1THXDyV+9YyZ0rC9Fa8+C/vcap9gFe+fM7CLisADT3DHPXl1+mwu/gs/evxGk1pV8PugYjGA2KqoADt82Mw2LCbTVd8xuPEEuJUuqA1nrT5cdlBD5PlFL8zbvWEHBZ+M5rF/i3l86yvjyPSr+DynwnPocZpaYOrYauYZp6RvjjO5dzW22A939tN5/72WG+9eGbMBoU0XiSzzx+mKaeEb7w4BpGogn+/tmTfPHpE7T1h9lQ4cNhMeK0mnBYjLhsJgJO66SQ3HO+m2+/1oDHbuI/fncTv/Mfe/j8k0f57ke24LWbARiOxvmTH75JS2+Y92wo5ekjbfz+d/dzz6pCbijL4+DFXj5z74qx8AYo9Tl4/8Zyvrv7Ai8cD1ETdHG0pY/9F3o43zkEgNmoCLisBFxWNlX6+Kt3rpIQF+IaSYDPI5vZyIdursJts/DEwRYOXuxl7/luAFxWE+vL87hvTdGkIH/ldAcOi5GHbqqgJM/OvWuKePpIGz99o4n3bSjjm78+x3NH27m1NsAHt1aitcZhMfJ3z5zkay+f4+5VhaA1g5EEQ5E40USSu1YWsLUmn3K/g2KPjVOhAf5r70Wae0f49Nvq2FKdz3s2lPKj/U08uussn7q7jkg8yT8+f4pdpzt517oSvvz+9fzJXUN89vHDPHO0nWeOtlOZ7+D3b62e9L3/yd21/CpdczypicST+J0W7l9bhM9h4ULXEB0DURq7hznc3EdFvoMPb5v8PEKI6UmAz7Nir50tNX68djNJrWnvD9PYPczp9kFePdOJ1WzgrhWFY/cPDYQ50TbA21YVUpJnB+B//cYqXjndyb/sPI3dbODfXz6Hz2nh7953A5Aa7X/gpgqsZgNffvYUvzzcCqQ2mXBZTUTjSU609RPqj7Cm1IvZqBgIx3nmWBtV+Q4e2Z4Kzr+8byUvnAjx2N6L3FCWR2vvCD/Y00hpnp3/8541AFTlO/neI1v44b5Gvvv6Bb7w4BpMxsnnwgMuKx/eVsW/vnSWVcVuNlb6uGV5PtuWB7CajCSTmv5wjNa+MO//2ut8f08jm6v8rCn1zuv/DyEWEwnwBbC+LI9Qf5juoRjFXjvFXjs3Vfn56RtN7DweIuiyckNZHgC/PtOJyaB4YH3J2OOLvHY+sr2Kf955hs8/cYy+4RhffO9air32sfsYDYoH1pViNxs51zGE02rCYzNRkmcnlkzyP392hB/sbeTtqwq5rS7Ic8faGYkm+IM7lmO3pH4NfE4Lf3D7cv7myWM8treRxu5hYokkf/vuNTit5rHXMhgUv72lkvdsKMNmNk77fb93Yxl5DgtKpdaIGR/OBoMiz2Ehz2HhA5sr+I9XzvHkoVYcFiM1QdfY/ZJJTVt/mHyXBatp+tcSYimSAF8ABoPi9voCWnpH6E7PLOkbjvHg+lK6BqP85EATfqcFr93Mm429bKjwUVfonvAcn9ixjCcOtnK+c4i3ry7kvRvKJr2OxWTgrpWFVOYPUuS1ke+0jLVn/u97b+CLT5/gmWPtNPaMcLKtn5uq/dy7pmjCczx0UwW/ONjMSyc7APjg1gp21AWn/L6uFN4AhR4bxXk2VhV7KPRMfwL34ztq+P6eC7x4IkRVvgO7JfW8jelzAZF4ku3LA1TkO6Z9DiGWIpkHvkBs5tTIclOVn7evLuJ9G8so9dn5na2VuG0m/nP3BZ471k4iqdm2PEDhZTNW7BYTn7t/BfeuLuIz966Ysm0x+jprSr0EXNYJvfUtNfl8/LYa7l5ZwPHWfqwmI797cyUem3nC4+0WI390Zy1Oi5F1ZV7+4PZl055snYk76guuGN6Qmlp535oiTrYPcLF7hBdPdPDiiQ7OdgwRSc9NDw2EZ12DEIuVjMAzxGBQ1BW6ae+P8KGbq/j3l8+y/0IPK4s9VOTb8TrMkx5zW10BDouJ6nEthpkyGhTb64IMRhNU+J1YjIrNVf4p77t9eYDP3LeC0jw7JXkLM+r9vVuqeOpwKy+cDPGhrZVjxyPxBE8dasVpNfGdj9y0ILUIkSskwDOoNM+O3WKgyGPjA5vL+e83m7m9LjjtfHGLycDNy/Jn/Xoem5nNVX7iCY3faaFgmpGxzWxkbVkeVQvYsqgv8rB9eYDnj4do7Ruh2GunvT/MD/Y20jEQwaCgYyBMcIZz6YVYCqSFkkEGg2JZejS9osjDX9y7gnK/44oth+tpZwBUB5xUB5ysLHZf8X7ryrzkOWZ2QdBcsJgMvHdDGVaTgRdPhHjrYi//9tIZhqMJ7lpZQFLD88dCC1aPELngqgGulPqmUiqklDoyxW2fVkpppVRgfspb/JYXuBjN5NFwLvRYr/CI67e5ykeF/8qj6+t9o5iNlcUebl6Wz5GWfn60/yKleXb++I7l7KgNYjYqdp3uWPCahMhmMxmBfxu49/KDSqly4B6gcY5rWlIcFhOleZemAzqtRty2yf3vuWQyGjIS0FdT5rOzozZIgdvKbbUBHtleg8dupsBjo7bAzRuNPZkuUYisctUA11rvArqnuOkfgD8HZPX+61RbeOmk5EzXS1mMTEYDtYVuPnV3HfeuKcZoUDgsRnbUBdla46e9P0JD52CmyxQia8yqB66UegBo1lofnMF9P6aU2q+U2t/RIX8CT6XYa8dlS51Pnu/2SbarHHfi1GRQ7KgLYrcYuWdV6mrVp4+0Z6o0IbLONQe4UsoBfA7465ncX2v9qNZ6k9Z6UzA49QUhApanT2Zebc70YlfstWEypto7Ny/Lx5deWXFLtR+3zcSrZzozWZ4QWWU2I/BlQDVwUCnVAJQBbyiliq74KHFFNUEnXrt5bOnVpcpkNFCWZ2dduXfC8rkGg4F1ZV7eutgre24KkXbNAa61Pqy1LtBaV2mtq4AmYIPWum3Oq1tCbGYjm6t8V7/jErC+Io/VJZMXtbq1NshgJM6hOdiuTojFYCbTCB8DXgfqlVJNSqlH5r+spWm6C2uWGodl6r9CRtdtefaojBWEgBlciam1fugqt1fNWTVCXEFlvpNir43XznZluhQhsoJciSlyyuYqP0db+gjHEpkuZU5F4gn+4blTXOgaynQpIodIgIuccvfKAmIJze5zi2sU/sTBFv5p52ne+9XX+K99jcQSyUyXJHKABLjIKXetLMSg4Pnji2s++BuNvZiNilhC89nHj/BnP3qL5t7hOXnuhs6hK74hDEXi9AxF5+S1xMKSABc5xWk1UV/o5tXTCzcfXOv5n7Z4pKmP2gI3j310C6tLPPziYCsf+sZenj3aRuI6pk2G+sN89eWzPP5GMx0DkUm3N3QO8eXnTvH3z55ckO9TzK2lPelY5KRtywN849XzvHgyxB31BfP6Wr3DUX55ODXrxaDAoBQum4mNlb45u+hKa83ZjkHuW1vMqhIv3/v9m/jSM6f4r30X+czjh/n026Lcv7ZoVqtD/v2zJ/nR/iZ+ebiVgxd7+a3NZawtzSOe1Ow6FeKrL5/jwIXUGjMf37Fswtx7kf0kwEXOefDGEr7x6nn+z1PHCbqs87oRclv/pZ2AIvEkh5r6aO8P0zUYZVmBkw0VvqtuLXc1zT0jDEUTrE1/Hx67hf/1G6uoLXDxhV8e5x+fP0U4FufmZQFWFntm/Lyn2gZ4+kgbJXk20PCDvY3sv9DNwzdX0dQzzA/2XqR/JMaKIjcn2gZo6BqSAM8xEuAi56wpzeP3tlXxrV838Bc/PcRXfvtGqgPXvkvRTLT1hekZirLnfBf7GnoYSc9+WVeWh9GgaOkNs67Mm14WePoVHpNJjcEw9e17zqdOyK4uuRTOJqOB372liqFonP/37Cm+/up5QNE5GOGWZQGM0zzXqFgiyX+8eo7+cJxP3V1LkdfOU4daee54O3/9i6Mkkpqgy8on767lttoA7/nq6zR0DXNr7TX+gERGSYCLnPTxHcvoGojyi0Mt/NmPDvLVD26c83VkkknNf+6+wAvHQyiVWq+8rsDNz95qpmMwTKnPTjSeZF9DDyfaBlhT6qUq3zEhyAcjcY619BMaCPOOtcVThvybjb0ArJhidP3hbdV0DUX51qsNfPu1Bj6yrZpwLMmOuiAW0/SnsA419bHzeIhyn50Pba3EbDKyttTL1mV+Hj/QjNdu5mO31bC52o9RKawmA2dDstJjrpEAFzmp0GPjc+9cSSSe4Jlj7fzpf73FZ+9fQXXANWfrybT2jfDKqU5qC108uL6UPIcFj83Izw82E7rshOBAOM7rZ7s42tLH2tLUbkbHWvq50DXE6DnIpp6RKVsUx9sGKPJYcU1Rt81s5JHt1QxHEjy2t5HvvN7AQzdVEI0nub0+OOX3OhCO8aN9jXQPRfnorfWYTakWT7nfwQe3VLJtWQCP3UzAdWnly9I8O+c6JMBzjQS4yFmFHht/867VhONJXj7VwReeOs471pZQ7LVRFXASdFvpH4nRPRSlezhK/0iMPIeFSr+DUp8ds/HKk7BeOtlBNJHkpio/eQ4LZT47tyzLp9h7YsoZHQD9I3F+fWbqOeon2wYmBXg8kaShc+iKve1ir533biwjnkzy0zea+eedp3nvhjJiiVSI5zksJJKaeDJJIqnZ19DNiyc7KHBb+cDmignPpZSiZopNsSvzHZzrkIuIco0EuMhphV47X3rfDXz6xwfZdbqT0ECEhzZXTBohR+IJjrb0U5Znp7lnBKMhFYwbK33TjthfPdOJQUFN0EV9kZsNFXkopajwOzk7i9FqaCBCz1B0bIlcgAvdQ3QPRa+6R+mN5XmE+sMUeez8aP9FvvN6Ayfb/fSNxLCYDIyfAXi0pY/QQITf31494bWuZFmBi1dOd5JI6qv210X2kHngIucVeGx8+bfW8/5NZTR2DfOvL52hpXcESAX3y6c6+NIzJ/nJgSb+5cUzvHwyRDSuaeoZ4URb/5TPGY0nOdTUS7nfwa21ATZW+sb611UBB11D0WnnZ0fjSXqGp74w5mT7wISv957vQcPYDJTpGAyKW5YHKPPZ+cTty9i+PMDuc9185YUzHGjoYSgSB1JTEl862YHfaeEDN5Vf8TnHqwm4iCc1rX0jM36MyDwZgYtFIeCy8kd31BJwWfn+nka+tussGyv9HGrqZTiaoK7QxbZlAfY1dPPMsXaOtPTzvo1lmIyKtaV5k04Inmzvp7k3zAPrSqgtnDg6Xl7gIpHU9A5HyXdN3kFp5/F29pzv5v97Wx2ey/Y3vdA1xPryvLGph4eaUicwb6y4+lLCXruZt68p4mhzHxaTgbpCNz97s4mfvNGEAiryHRR7bTT3jvCbG8uuaWZOVXonpAtdw5T5ZCphrpAAF4tGRb6Dt60uwms389jei+w+10VdoYu7VhRS7ndQnGdjZbGHNy/28vO3mvnKi2e4b00Ra0u9k3rQO4+HANhRN3kXqdqCVDB2DESmDPAL3cNEE0leOtnBA+tKJtyWSMKZ0CBrSr1E4gnOdgxhNxsp89knPc9UvHYztywPsGo4Spmvj2VBJy29YY639XO8tZ/d57rx2s28b1PZNbVCqgJOABq6hti2PDDjx4nMkgAXi8q6Mi+9w1Ee2V5N30gMv9OCUql526tKPLSnL8ypDjj5yYGL/PJwKxsq8lhR5J4wxe/1s13YzUa2104Os7rCVNh3DEZYcdltiaSmpXcEk0Gx73w3ty4PTOpDnw4NsKrYQ6g/QmvvCBWXTT2ciTyHhVtrg3SXRNl7votSn527VxbSOxzFYFDXdMEPQJHHhsVo4IxMJcwp0gMXi4pSiluWBchzmPE7LZiNitvrg6xKXyRT6LGxoz5Int3Mu28sA1Kj7Yvdl3q/Q5EYx1r7qSt0UeCePMIucKem/F1+ohQgNBAmntTcvbIQpWDnidCk+4xEkzR2D9PSO0J7f4RlQeesv1+/08LbVxexrtyL0ZAK9toC16TWzdUYDIqSPNusTs6KzJEAF4uOxWTgtrog+S4L964potg7sT0xGuL5Tgs3lOWx70IPbzR2j93++tkuBsJxtlT7pxwZGwyKAo91yqmEzT2pN4ItNX621uTzZmMPoYHwpPudbB/gSEsf0USSFUXXNlq+nFKK1SVe7ltbTNBtpbbgyjNaplOZ76Sxa25WQBQLQwJcLEpeu5m3ry7CPc1ItNBj4/b6ILfXBYnGkzx9pJ3OwVQgv3iyA4C7VxVO+/zFXhsdA5FJK/g1945gNRnYWOnjtrogZpOB549PHoV3DUY5E0rNu76hbG7WcvHYzNyzqpBy/8z66ZerSffTZdPo3CEBLpasAo+N2+qDLAs6ee1sJ0fTmyXva+imwG3lhrK8aR9bludgJJZgKDpxZ6Dm3hHKfHZK8uy4rCa2Lw9wpLmP5t7J0/Na+0YwKFhTcn0j8Mtdaz991PICF9FEcsICXiK7SYCLJW1FkZvbaoP0h+M8dbiV8x2DnOsYYk2p94qrDI6Ocse3UeLJJK19YarynfgdFkwGxfblAexmI88dm7wRc2tvmKDbOuVMlkyoyr80E0XkBglwsaQ5LCbuWVVIocfKrlOdPLavkXhSc+sUs0/GG51j3TkuwNv7IySSmmUFLgwGhd9pwWY2sqMuyKn2QY619E14jrb+MOW+a5+BMl8q03PBGzqlD54rJMDFkre6xMv25T2d2VYAABgfSURBVAHa+sM8dagNk0FxzxX63wAleTbMRkXH4KUAHz2BuSJ94U8wPYNla00+JXk2Htt7kSPpNs1wJE7fSIya65iBMtdKvHbMRsWZ0MDV7yyyggS4WPK8DjP3rinCbTXR3DtCdcBJad6VTwQ6LCYCLuuEGSbNvcPYzUYq8lOPHQ1wi8nAI9tqKPXZ+eG+Rt662ENrus9cf50zUOaSwaAo9tplUascIgEuBLCuPI+bl+UDsLlq6umD41lNBoLuiVMJm3tGKPXZsVtS18cFXFZGn8ZuMfLhbVVU5Tv58f4mdqY3ZZ7rE5jXqzLfsWR64PFEcmwNmVwlAS4EUOC2cf/aYm6q8vOeDaVXvb/VbCDostI7HCOWSBJLz94ozbNjT5/8tJgMeO2XpjFaTUYevqWKukI3DV3DuK0mKvKza92RmoCTlr6lMZXwTMcgR1umXswsV1z1Unql1DeBdwIhrfWa9LEvAb8BRIGzwIe11r3zWagQ821jpY/haGJGe2zaTEaCbisa6ByMEE9okjq1MYLdcmn2StCdCvlRZqOB39lawRMHW3FZjdPOU8+U5QUuovEkoYEIRd653eEomySTmicPttI3EmV1iWfONgGZTmvfyKQLyubCTEbg3wbuvezYc8AarfUNwCngL+e4LiEWXLnfQVXAMaNNiq1mw1iPu2MgMjbPu8x3aQQOTNj1ZpTJYODdN5by9tVFOC3XtyHyXBtd1Op8Z3a2UYYicd5o7OGlk6Fpl/OdibMdg/xwXyM/PtA0tiLkfGnvD3M2ND8/z6sGuNZ6F9B92bFntdajzaPdQNk81CbEgttc5Z/R/WwmI/lOK4rUolbNPSM4LUa8dvOEN4DgFGupjHLZTFkzhXBUts4Fb+8Ps+tUB7842MKJ1gFaesO8drZz0pWwM6G15tlj7XQORgnHkuw8HmI4On+98F8dbuX3vrV37LzHXJqLHvhHgF9Nd6NS6mNKqf1Kqf0dHR1z8HJCzJ+rbbM2ymBQOK1G8hzmsRF4qc+O0aAmBLjLasJumfo5p9oDM9NK8uyYDIrT7dkzlfBMaICdx0M09YygNZzrGOQXB1s43jrAG4091/x8F7tHeP1sF0alMBkUR1v7OXYdvfBwLDHtbW19YX51pA2lYMMM1ny/Vtf1G6SU+hwQB74/3X201o8CjwJs2rRp8Z8ZEUuG1Zzqg7f0hukajLCyuGDK9kvQZaOxe/LFMdnW/wYwGhRFXhvnsqSF0jMU5cCFnrHPf3WklSPpsD0TGuSR7dU4LKZrWj73SEsvh5v7WFHsxqDgeGs/Z0IDrC7xTjh/MVOn2gcwGlILil1uX0M3b17sZfsUywrPhVmPwJVSD5M6ufk7ejZ/xwiR46ym1EyUzsEImlT/e8oAn6aN4rFl3wgcoNLv4EIWrEoYSyR59UwnI9Ekzx1r5x+eP8XJ9gHuXlnAh2+pYiAc42u7zvL8sfYZr6LY2jfCm4199I3EuKO+gG3LA/QOx2juDXOstW/S/TsHp968erxQf4SDF/touOxNr7VvhOeOtRONJ3nH2pJpHn19ZhXgSql7gb8AHtBaZ/7/tBAZYDMbCbovzdS4fAbKqOkC3JWlAV4dcNLSO3LV/nJb37UtejUYibPrVAfHW/tnNE1xz7luOgYifG3XWV48GWJ1iYc/vbuOO1cUUlvo5pHt1UTjSR595Rw/e6uJvnGzfaZzrKWfgxd7MRsV71hbzD2rClGMjsIHGYkmCMcSHGvp58lDLTx7tJ3BK8wVTyQ1XUOpkN9zvmvChV2HLvay93w3JXk2dtTPzy5HVw1wpdRjwOtAvVKqSSn1CPAVwA08p5R6Syn17/NSnRBZbPRiHgC3zYTHbp4wA2VUnt2MaYrtzbKxhQJQW+gmEk/SOsUKiqOOtvTNuP+cTGqOtvTxy0OtnO8c4o0LPfzqSNvY7khTOd0+wLmOQb63+wLt/WF+d2slv7W5gjyHhaDbym11AVYUe/jorTUA/PtL5/jhvsYrzkzpGIjQ0hvmSEsfK4s9VAed1BW6KfPZOd46QCIJzx9v57/fbOati730j8TRWl/x59A5GCGRTH2eSMKuU530jcRo7RvhwIVe2vrD3FYXnPBGP5euOgTQWj80xeFvzEMtQuQUW7oHDoxdem8zTx4TGQyKfJeF9v7USM1jN7Es6Mq6KYSjqtNTCX/2VgsfvbVm0obPF7uHOdSUajdE48lJt4/XORhhz7lu+kZihAbCPLrrHMuCLt6/qZydx0NU+B3UFrpQCgxKoYCRWIL9F7r58YEmznUO8Zsby1hR7EEpWF3iYW2pF6UUBW4bu+1dmAyK/3jlHP+5+wIbK/PYVJU/qY6+kRivnO7gTGiA4WiCbcvysZmN2MxGbijz8tThNvpGJo7gY4kkX3v5LLvP+fiX394w5fcX6p/YYonGk7x0MoTVZGD3+S5sZgPvufHqF4bNVnb+DSdEDrCaDDgtRqoDTtakT2BNNQIHKPLasFuMLA+6KPBk9wUyo1MJT7cPsvN4O3esuHRytmcoyuvnuhjtrnQNRa54gcq+86nwHo7G+c/XLxBPaA4392E0KN63sYzG7uFJJ3i11jx1uJXDzX3ct6aIGyt82C0GblkWoHDcz25056UCj5XznUM8/mYzTx5qo9TnmFBTfzjGCyfaCceSHGzqw242ctfKS4uVba8N8tThNo639rO15lL4v3giREtfmERDN8mkxjDFX1FT7bY0FEnQ3h/haHM/N9X4qS+cv+US5FJ6IWbJZjailOKjt9awodI3dmwqq0u83LIskPXhDVDqs1PotvLssTaOtw7w3LF2hiJxwrEEu053EE9calNMta3cqHAsQc9wjERS84M9jfSOxPjwtiretqqQty728vO3mif12bXWvHK6k9fOdrFtWT7blwcIuq3ct6Z4QniPt6LIw5+9rQ6v3cwLJ0K8frZzbGrfQDjGC8dDjESTRONJjrX2s7rEQ4X/0hIGa0s95DstHG+9NJWwpXeEXac7sJoMtPdHON85ea/QZFLTNRidsqb9Dd0ktOaelYV4HfPXKpMAF2KWrFO0DmYzDS3bGA2Kv333GkwGxTdePceZ0CDPHWvnpZMdDEUmznm+0iyN9v4wWmueONjCuc4h3n1jKTvqgty7pojb64Psa+jhycOtaK0ZCKdaHP+08zRPH21jbWlqj89yv4M7V0w9PXO8Up+Dd6wtprF7mCPNA+w5350K7xMhhtO7Jp1o6ycaT7Kh0jfhCtkCt42VxR7OdQwRjiVIJDWPv9GEw2IaWxfnldOdk16zcyhCfIqee1Jr9jZ0UxN0sqVmZheGzZa0UISYpalCZboWSq6pL/LwyPYavv7KOb756nk+emsNgSlm03QORtFaT3lFaVtfmNfPdbG3oZvbaoNsqfazodJHx0CEkWiCWDzJr8920dg1TGvfCEkN5T47D64vZUNlHnWFbjZX+WZ8teoHt1bw5KEWXjgRYnmBi1B/mNi4vxYONfXhtpm4uSZ/QjvE77SwusTDq2c6OdU+QM9wjJa+ML99UwV3rgjyw70X2X+hh9/bVj3h9UL9EWKJJP+88zQJrSlwWwm6rCil6B2Ocd+a4rF21HyRABdilqYcgS+SAC/z2bmxIo+PbK/m66+c4+uvnuMj26rJd1kxjgu/eELTMxzDP8VFKrvPd/HUoVZWFnt42+pCVpektqkr9zuoDji5f20xSVJT+7YvD7ChwjfWYlpb6mXtNW72vLzAzR31Bfz8YAvnOgepSe+aBKm1T062D7Cl2k+Zb2LP3mQ0sK7Mi8Ni5PWzXTT3jrC6xMOaUi9ry/IozrNxqn2AcCwx4U07NBCmoXOIrqEoy4JOBsNxzncOEUtovHYzt9YG5n2RLAlwIWbp8gC3mgxTnujKRUopblmWTziWSI3EXz3HP+48DYBRKcwmhcNi4ndvrqRjIDIpwAfCMQ409GJQit/cWIbHbqa+yD12+8YqH+0DYX7jhhJ+44ZLF7kYDbCpys+yoItrZTGlFgl74USIF06EqNnuIqk1r5zq4Nlj7eS7rGxfHphylcUCj40VRW7eaOzFZjbwwLoSnFYjhR4bK4o8vHa2k5beEWrSdSWTms6BKKdDg5gMig9trcJiMpDUmr6RGGajgeUF1/49XCsJcCFmyWQ0YDKosT7oTFYxzCUmo4Ed9UGiiSSf2LGMY6396bXPNZF4gt3nujnROsDmKj/1uCc8tr0/zMWeYYrzbNjMRtaX5U0YuVtNRjZX+dl16lJv2WUzsX15YMrR/EzVF7u5tS7ILw+3cqK1n70N3ZxoG2BtqZf33FhKvts65fz7gMvKmhIvbzT28o61Jbht5rH2x7pyLy+cCHHgQs9YgHcNRYknNafaB6gKOMemUhqUwuewoBQTTpTOFwlwIa6D1Wwgnj6xN92iVbnMajJyR30BsUQb+ZctjXu6fZDG7uEpZ6I094Rp7hlhY6WPoNs65cYVZb5UK+V85xClPjs31+RfcU75TBR5bNxRH+TlUx18d/cFjErxzhuKubkmH6UUxdOscR5wW6kvcvPJu2rHZrtUp/cr3VKdD5zmwIUefnNTOZBqn/QORwkNRNhYOXmRqiKPbUHe0Bffb5wQC8hquvSPdLGNwEc5rSZuryvAbJzYHqrMd3Cha4ihSHzS1mSHmnqJJpKU+x3cWJE37XNvrPSxsdLHjrrgdYc3pFo/dYVu3r6qkAK3lY/eVsMtywJjJ0KLppmK6LKacKRbJgABlwVPeqS+rsyLzWzgbMcgPUOpaYOh/ghnQqmphbWF7knPV7lAOy1JgAtxHcZfeblYTmBOxee0TLjIBaDC72QomqB7KDphFN49FOVsemPkm2v8U25qMcpiMkzojc+F6qCTTVV+PnV33YQ2hkFxxV2G8p2X6qwJXpo9YreYqMp30tg9TEvfCMmkpmMwwqnQIB6bicLLZucUea0L0j4BCXAhrsv4EfhimAN+JeV+B6vGbcI8Osq80DU8YT54W1+Yi93DOCzGeZ8HPRWPzTzlAmJBt/WK672PvtEYDak3p/FWFLkJ9Uc43zFE93CUaDzJ2dAgtQXuCdMcawtd3F5XgGmG68pfLwlwIa6DdYmMwEetK/NS5E0FXdBtxWY2cKF7YoC394dp7Bmmwu/A75x+9D2fRtdzgdQof125lx11wSs+JuBOnTwt8zkmtXPWl+ehgTcv9tLSO0JTzwgjsQS1hamTmgYFm6t8bK7yL+hMJAlwIa6DbQn0wMdLTS8M4LQaMShFhT/VB+8ZjhFLJEkkNY1dqROb1QFnxn4mFX4HVpOB1SUeHlhXwuoS71VHxflOKwY1MfxHjW61d6FriJNtA5xuH0ABy4MuzEbF7fUFU/bC55sEuBDXYXwPfCkEOKS+z+3LA2OthtBAhOFIgq7BKJ2DERq6U/3v1SXzt4jT1VhMBt61voR15XkzPjlqNCiK8+xTzlQpz3dQ4LZysXuEWEJzOjRImc+Ow2qirtB9xd76fJIAF+I6WMeF9lJooYzKd1lZXeId64Nf7EmNulvT/W8F3DgPe0Bei9n0oTdU5E156b7baqIy30Fj9zDD0TgXu4fHRtyXX9m5kCTAhbgOo1djmgxqTqbB5ZIir40ynx2DSrUWOgcj6ROYIwTd1rE10nPJdJtsKKVYUeRhJJZgz/luNFBb4MJpNU6aH7+QltZvnBBzbLRtYlvkM1Cm4ndYcFiMFHltXEhf0NM9FOFizzDlfgc+x9xv4ptJ68tT89lfPd2JzWygzOfI6OgbJMCFuC6jI/Cl1D4ZZTAo/E4rFX4nTd0jROJJugajDEcTVOY78NgX14Xea0o9WE0GRmIJlgVdGA2KMt/CzPeejgS4ENfBbDRgNCzNAIfUFYuV+Q6iiSRt/eGx3XVWF3tnvAxsrvA5LZSnL9CpK3BjNRkomGbD6oUiAS7EdUrtrbg0/ykFXFYq06HW2DXExZ5hLCYDq4oXfkrdfPM5LGMnbWsLXZT67Bl/k1pcf+MIkQFWk2HJTCG8XNBtxWs347GZuNA9TNdglLI8O/4MntibL2ajgbetLqI64CTPcWk0nkkS4EJcJ6vJuOgvo5+OzWzEbTdTmZ9aVXAoEufW2iC+edwHMpOKPTYSCY3JqKZdGGshLc2/+4SYQ1azYcn2wCHVB6/wOxgIx9PbojnIW2QzUEaNzqwp8donrG+eKRLgQlwnq8m4pAM86LJOWD61vsi1aOfE56X/sij3Z8ccd2mhCHGdbGbDkm2hQKoPXuy1YzYqXFYTlfO8kW8m+ZwWDAqKvRLgQiwKdrNxyg2Olwqv3YzNbODGCh9Oi2lslLoYuawmyv2TVyvMlKsGuFLqm8A7gZDWek36mB/4L6AKaADer7Xumb8yhcheXrs549PJMkkpRcBl5cH1pQCL7grMy60p8Wa6hDEzeRv5NnDvZcc+A+zUWtcCO9NfC7Ekee2Ld8Q5U+N33VnMI3AAbxZ9f1cNcK31LqD7ssPvAr6T/vw7wINzXJcQOWOhdl/JZqObIZiMatoFocTcm+1vXqHWuhUg/bFgujsqpT6mlNqvlNrf0dExy5cTQmSzfKcVpRZ/+yTbzPvQQWv9qNZ6k9Z6UzB45S2NhBC5yWIy4LWbF337JNvMNsDblVLFAOmPobkrSQiRiwIuq4zAF9hsA/wXwMPpzx8Gfj435QghclXAZZER+AK7aoArpR4DXgfqlVJNSqlHgC8C9yilTgP3pL8WQixhQbeVPJmRs6CuOg9ca/3QNDfdNce1CCFymMw+WXgy/0kIIXKUBLgQQuQoCXAhhMhREuBCCJGjJMCFECJHSYALIUSOkgAXQogcJQEuhBA5SgJcCCFylNJaL9yLKdUBXJjlwwNA5xyWM9+k3vmXazVLvfNrMddbqbWetJzrggb49VBK7ddab8p0HTMl9c6/XKtZ6p1fS7FeaaEIIUSOkgAXQogclUsB/mimC7hGUu/8y7Wapd75teTqzZkeuBBCiIlyaQQuhBBiHAlwIYTIUTkR4Eqpe5VSJ5VSZ5RSn8l0PZdTSn1TKRVSSh0Zd8yvlHpOKXU6/dGXyRrHU0qVK6VeVEodV0odVUp9Mn08K2tWStmUUnuVUgfT9X4+fTwr6x2llDIqpd5USj2Z/jpr61VKNSilDiul3lJK7U8fy+Z685RSP1FKnUj/Ht+crfUqperTP9fR//qVUp+ai3qzPsCVUkbgX4H7gFXAQ0qpVZmtapJvA/deduwzwE6tdS2wM/11togDf6a1XglsBf4w/TPN1pojwJ1a63XAeuBepdRWsrfeUZ8Ejo/7OtvrvUNrvX7c3ORsrvefgKe11iuAdaR+zllZr9b6ZPrnuh7YCAwDP2Mu6tVaZ/V/wM3AM+O+/kvgLzNd1xR1VgFHxn19EihOf14MnMx0jVeo/eekNqfO+poBB/AGsCWb6wXK0v8o7wSezPbfCaABCFx2LCvrBTzAedKTMLK93stqfBvw67mqN+tH4EApcHHc103pY9muUGvdCpD+WJDheqaklKoCbgT2kMU1p9sRbwEh4DmtdVbXC/wj8OdActyxbK5XA88qpQ4opT6WPpat9dYAHcC30i2qryulnGRvveN9AHgs/fl115sLAa6mOCZzH+eAUsoF/BT4lNa6P9P1XInWOqFTf4KWATcppdZkuqbpKKXeCYS01gcyXcs12Ka13kCqVfmHSqnbMl3QFZiADcBXtdY3AkNkSbvkSpRSFuAB4Mdz9Zy5EOBNQPm4r8uAlgzVci3alVLFAOmPoQzXM4FSykwqvL+vtX48fTirawbQWvcCL5E655Ct9W4DHlBKNQA/BO5USn2P7K0XrXVL+mOIVH/2JrK33iagKf1XGMBPSAV6ttY76j7gDa11e/rr6643FwJ8H1CrlKpOv4N9APhFhmuaiV8AD6c/f5hUnzkrKKUU8A3guNb6y+NuysqalVJBpVRe+nM7cDdwgiytV2v9l1rrMq11Fanf1xe01h8kS+tVSjmVUu7Rz0n1aY+QpfVqrduAi0qp+vShu4BjZGm94zzEpfYJzEW9mW7qz7Dxfz9wCjgLfC7T9UxR32NAKxAjNTp4BMgndRLrdPqjP9N1jqt3O6k21CHgrfR/92drzcANwJvpeo8Af50+npX1Xlb77Vw6iZmV9ZLqKR9M/3d09N9Yttabrm09sD/9O/HfgC/L63UAXYB33LHrrlcupRdCiByVCy0UIYQQU5AAF0KIHCUBLoQQOUoCXAghcpQEuBBC5CgJcCGEyFES4EIIkaP+f8bsUDAEDyJwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1]\n",
    "# + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsd[3],\"4+4_data/g1.5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .27\n",
    "samples = sample_ar(resultsd[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2.0\n",
    "\n",
    "resultse = batch_train(resultsd[3], 4, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .27\n",
    "samples = sample_ar(resultse[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2.5\n",
    "\n",
    "resultsf = batch_train(resultse[3], 4, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0] + resultsf[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1] + resultsf[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .27\n",
    "samples = sample_ar(resultsf[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3\n",
    "\n",
    "resultsg = batch_train(resultsf[3], 4, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0] + resultsf[0] + resultsg[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1] + resultsf[1] + resultsg[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .27\n",
    "samples = sample_ar(resultsg[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "resultsh = batch_train(resultsg[3], 4, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0] + resultsf[0] + resultsg[0] + resultsh[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1] + resultsf[1] + resultsg[1] + resultsh[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .3\n",
    "samples = sample_ar(resultsh[3], 2500, 1000, 3, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "resultsi = batch_train(resultsh[3], 4, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0] + resultsf[0] + resultsg[0] + resultsh[0] + resultsi[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1] + resultsf[1] + resultsg[1] + resultsh[1] + resultsi[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .3\n",
    "samples = sample_ar(resultsi[3], 2500, 1000, 3, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4\n",
    "\n",
    "resultsj = batch_train(resultsi[3], 4, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0] + resultsf[0] + resultsg[0] + resultsh[0] + resultsi[0] + resultsj[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1] + resultsf[1] + resultsg[1] + resultsh[1] + resultsi[1] + resultsj[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = .3\n",
    "samples = sample_ar(resultsj[3], 2500, 1000, 3, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4.5\n",
    "\n",
    "resultsk = train(resultsj[3], 2, 200000, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0]  + resultse[0] + resultsf[0] + resultsg[0] + resultsh[0] + resultsi[0] + resultsj[0] + resultsk[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1] + resultsf[1] + resultsg[1] + resultsh[1] + resultsi[1] + resultsj[1] + resultsk[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
