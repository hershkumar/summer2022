{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"false\"\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "# jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 3\n",
    "N_down = 4\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up] / SYM_DEN\n",
    "    sym_piece2 = reordered[N_up:] / SYM_DEN\n",
    "\n",
    "    new1 = [jnp.sum(sym_piece1 ** i) for i in range(1, N_up)]\n",
    "    new2 = [jnp.sum(sym_piece2 ** i) for i in range(1, N_down + 1)]\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1] / SYM_DEN\n",
    "    sym_piece2 = reordered[N_up + 1:] / SYM_DEN\n",
    "    \n",
    "    new1 = [jnp.sum(sym_piece1 ** i) for i in range(1, N_up + 1)]\n",
    "    new2 = [jnp.sum(sym_piece2 ** i) for i in range(1, N_down)]\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    rng = np.random.default_rng(int(time.time()))\n",
    "    randoms = rng.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = rng.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved:\n",
    "                counter += 1\n",
    "        \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = jnp.array(sq.copy())\n",
    "    for i in range(len(sq)):\n",
    "        a = jnp.array(sq[i])\n",
    "        a = a.at[N_up].set(a[0])\n",
    "        sq_prime = sq_prime.at[i].set(jnp.array(a))\n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        print(gr[0])\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "#TODO: stop precomputing all the random numbers and storing them, that takes too much memory\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "#     subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "#     randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "#     randoms = jnp.transpose(randoms)\n",
    "#     subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "#     limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev, stepkey = val\n",
    "        # get a random number between -stepsize and stepsize\n",
    "        rng_keys = jax.random.split(stepkey, 3)\n",
    "        random_1 = jax.random.uniform(rng_keys[0],(N,), jnp.float32, -stepsize, stepsize)\n",
    "        random_2 = jax.random.uniform(rng_keys[1], (), jnp.float32, 0.0, 1.0)\n",
    "#         new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        new, moved = mcstep_E(random_1, random_2, positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev, rng_keys[2]\n",
    "    \n",
    "    sq, positions_prev, key = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev, key))\n",
    "    del positions_prev\n",
    "    del key\n",
    "    \n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[N_up].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def batch_gradient(samples, samples_prime, params):\n",
    "    num_samples = len(samples)\n",
    "    ys = jnp.array(samples_prime[:, N_up])\n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "    \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def batch_step(params_arg, step_num, N, N_batches, thermal, skip, variation_size, g, start_key):\n",
    "    # compute the gradient for each batch\n",
    "    samples_per_batch = N//N_batches\n",
    "    grads = []\n",
    "    energies = []\n",
    "    uncerts = []\n",
    "    \n",
    "    def grad_wrapper(key):\n",
    "        samples, samples_prime = sample_pmap(params_arg, samples_per_batch, thermal, skip, variation_size, key)\n",
    "        return batch_gradient(samples, samples_prime, params_arg)\n",
    "\n",
    "    grad_pmap = jax.pmap(grad_wrapper, backend=\"cpu\")\n",
    "\n",
    "    inputs = jax.random.split(start_key, N_batches)\n",
    "    out = grad_pmap(inputs)\n",
    "    \n",
    "    # average the gradients\n",
    "    gradient_avg = jnp.mean(out[0], axis=0)\n",
    "\n",
    "    # average the averages\n",
    "    energy_calc = jnp.mean(out[1])\n",
    "    uncert_calc = jnp.sqrt(jnp.sum(jnp.square(out[2])))/N_batches\n",
    "    \n",
    "    \n",
    "    opt_state = opt_init(params_arg)\n",
    "    new = opt_update(step_num, gradient_avg, opt_state)\n",
    "    return get_params(new), energy_calc, uncert_calc\n",
    "\n",
    "\n",
    "def batch_train(params, iterations, N, N_batches, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = batch_step(old_params, step_num, N, N_batches, thermal, skip, variation_size, g, jax.random.key(int(time.time())))\n",
    "\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_ar(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "\n",
    "    sq = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    rng = np.random.default_rng(int(time.time()))\n",
    "    randoms = rng.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = rng.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved:\n",
    "                counter += 1\n",
    "        \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "\n",
    "\n",
    "    return jnp.array(sq), counter/num_total\n",
    "\n",
    "\n",
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(jax.devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.650851788756388\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168007\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2620.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5064155974004333\n"
     ]
    }
   ],
   "source": [
    "step_size = .4\n",
    "samples = sample_ar(params, 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])\n",
    "# print(samples[0].shape)\n",
    "# print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 12.557576: 100%|██████████| 15/15 [21:54<00:00, 87.62s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "\n",
    "resultsa = batch_train(params, 15, 100000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0] \n",
    "# + resultsb[0] \n",
    "# + resultsc[0]  + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] \n",
    "\n",
    "# + resultsb[1]  \n",
    "# + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsa[3],\"3+3_data/g0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.557576 0.0029357118\n"
     ]
    }
   ],
   "source": [
    "print(resultsa[0][-1], resultsa[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2468.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5084152641226463\n"
     ]
    }
   ],
   "source": [
    "step_size = .4\n",
    "samples = sample_ar(resultsa[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 11.401656: 100%|██████████| 15/15 [34:41<00:00, 138.75s/it]\n"
     ]
    }
   ],
   "source": [
    "g = -.5\n",
    "\n",
    "resultsb = batch_train(resultsa[3], 15, 200000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] \n",
    "# + resultsc[0]  + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  \n",
    "# + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsb[3],\"3+3_data/g0.5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.401656 0.029904462\n"
     ]
    }
   ],
   "source": [
    "print(resultsb[0][-1], resultsb[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2502.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.507248791868022\n"
     ]
    }
   ],
   "source": [
    "step_size = .38\n",
    "samples = sample_ar(resultsb[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 10.058859: 100%|██████████| 10/10 [30:23<00:00, 182.30s/it]\n"
     ]
    }
   ],
   "source": [
    "g=-1\n",
    "\n",
    "resultsc = batch_train(resultsb[3], 10, 300000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] \n",
    "# + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1] \n",
    "# + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultsc[3],\"3+3_data/g1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.058859 0.071164034\n"
     ]
    }
   ],
   "source": [
    "print(resultsc[0][-1], resultsc[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 6001/6001 [00:02<00:00, 2492.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5164139310114981\n"
     ]
    }
   ],
   "source": [
    "step_size = .37\n",
    "samples = sample_ar(resultsc[3], 1000, 1000, 5, step_size, progress=True)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 9.033905: 100%|██████████| 10/10 [19:04<00:00, 114.42s/it]\n"
     ]
    }
   ],
   "source": [
    "g=-1.5\n",
    "\n",
    "resultsd = batch_train(resultsc[3], 10, 150000, 64, 2500, 10, step_size, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-5))\n",
    "resultse = batch_train(resultsd[3], 5, 350000, 64, 5000, 10, step_size, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0] + resultsd[0] + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(resultse[3],\"3+3_data/g1.5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultse[0][-1], resultse[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
