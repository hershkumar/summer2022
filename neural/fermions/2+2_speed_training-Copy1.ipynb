{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 2\n",
    "N_down = 3\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [100,100]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"3+3/large_g_150_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.622913117546848\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54005\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:01<00:00, 4441.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5267594589296216\n"
     ]
    }
   ],
   "source": [
    "step_size = .6\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 6.512808970718052: 100%|██████████| 100/100 [25:02<00:00, 15.02s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "# first find the step size\n",
    "step_size = .6\n",
    "resultsa = train(params, 40, 2000, 1000, 10, step_size, g)\n",
    "resultsb = train(resultsa[3], 100,5000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 6.5034117109682725: 100%|██████████| 50/50 [24:10<00:00, 29.02s/it]\n"
     ]
    }
   ],
   "source": [
    "resultsc = train(resultsb[3], 50,10000,1000,10, find_step_size(resultsb[3],step_size), g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resultsd = train(resultsc[3], 15,30000,1000,10, find_step_size(resultsc[3],step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0]+ resultsc[0] + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1]  + resultsc[1] + resultsd[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = .5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1\n",
    "resultsa = train(results_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_1 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.5\n",
    "resultsa = train(results_1, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_15 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2\n",
    "resultsa = train(results_15, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_2 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=2.5\n",
    "resultsa = train(results_2, 1000, 800, 100, 10, find_step_size(results_2,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_25 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -.5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1\n",
    "resultsa = train(results_neg_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# load the g=2.5 results from the checkpoint file \n",
    "params = load_params(\"5+5/large_g_150_params_g_2.5.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "params = load_params(\"5+5/large_g_150_params_g_3.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_35 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_4 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_45 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_55 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_6 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_65 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_7 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_75 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_8 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_85 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_9 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "g = 10\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# params = load_params(\"5+5/large_g_150_params_g_9.5.pkl\")\n",
    "params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "\n",
    "resultsa = train(params, 10, 30000, 1000, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 15,50000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = acc_train(resultsb[3], 10, 300000,1000,10, find_step_size(resultsb[3],step_size), g)\n",
    "resultsd = acc_train(resultsc[3], 10, 1000000, 10000,10, find_step_size(resultsc[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "g = 10\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10.5_extrapolated.pkl\")\n",
    "g = 10.5\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_11_extrapolated.pkl\")\n",
    "g = 11\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_11 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
