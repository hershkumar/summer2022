{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 4\n",
    "N_down = 5\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 5\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "# PARAM_PREFIX = \"5+5/large_g_150_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "        save_energies(hs, us, \"energies.pkl\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.675383304940375\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "save_energies([], [], \"energies.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218709\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:12<00:00, 409.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499509900019604\n"
     ]
    }
   ],
   "source": [
    "step_size = .3\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 21.241361321044447:   8%|▊         | 21/250 [01:50<05:29,  1.44s/it] "
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "# first find the step size\n",
    "step_size = .3\n",
    "resultsa = train(params, 250, 100, 100, 5, step_size, g)\n",
    "resultsb = train(resultsa[3], 1000,400,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "save_params(resultsd[3], \"4+5_g_0.pkl\")\n",
    "results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -.5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "save_params(resultsd[3], \"4+5_g_-05.pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1\n",
    "resultsa = train(results_neg_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "save_params(resultsd[3], \"4+5_g_-1.pkl\")\n",
    "\n",
    "\n",
    "results_neg_1 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1.5\n",
    "resultsa = train(results_neg_1, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "save_params(resultsd[3], \"4+5_g_-15.pkl\")\n",
    "\n",
    "results_neg_15 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density profiles for the 4+4 cases\n",
    "def local_density(samples):\n",
    "    all_xs = samples[0][:,0]\n",
    "    x_min = np.min(all_xs)\n",
    "    x_max = np.max(all_xs)\n",
    "    \n",
    "    x_bins = np.linspace(x_min - 3, x_max + 3, 100)\n",
    "    dx = x_bins[1] - x_bins[0]  # Bin width\n",
    "    n_x = np.zeros_like(x_bins)\n",
    "\n",
    "    # bin the x_1s\n",
    "    for x in samples[0][:,0]:\n",
    "        n_x[np.digitize(x, x_bins)] += 1\n",
    "\n",
    "    # Normalize\n",
    "    n_x /= (dx * np.sum(n_x))\n",
    "\n",
    "    return x_bins, n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parameters\n",
    "params_0 = load_params(\"4+5_g_0_PRECISE.pkl\")\n",
    "params_neg_05 = load_params(\"4+5_g_-0.5_PRECISE.pkl\")\n",
    "params_neg_1 = load_params(\"4+5_g_-1_PRECISE.pkl\")\n",
    "params_neg_15 = load_params(\"4+5_g_-1.5_PRECISE.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 500101/500101 [09:16<00:00, 898.96it/s] \n"
     ]
    }
   ],
   "source": [
    "samples_0 = sample(params_0, 50000, 100, 10, find_step_size(params_0, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 500101/500101 [09:51<00:00, 845.51it/s] \n"
     ]
    }
   ],
   "source": [
    "samples_neg_05 = sample(params_neg_05, 50000, 100, 10, find_step_size(params_neg_05, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 500101/500101 [13:28<00:00, 618.57it/s] \n"
     ]
    }
   ],
   "source": [
    "samples_neg_1 = sample(params_neg_1, 50000, 100, 10, find_step_size(params_neg_1, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 500101/500101 [11:01<00:00, 756.31it/s] \n"
     ]
    }
   ],
   "source": [
    "samples_neg_15 = sample(params_neg_15, 50000, 100, 10, find_step_size(params_neg_15, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bins_0, n_x_0 = local_density(samples_0)\n",
    "x_bins_05, n_x_05 = local_density(samples_neg_05)\n",
    "x_bins_1, n_x_1 = local_density(samples_neg_1)\n",
    "x_bins_15, n_x_15 = local_density(samples_neg_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_bins_0, n_x_0,'-o', markersize=2,label=r\"$g=0$\")\n",
    "plt.plot(x_bins_05, n_x_05,'-o', markersize=2,label=r\"$g=-.5$\")\n",
    "plt.plot(x_bins_1, n_x_1,'-o', markersize=2,label=r\"$g=-1$\")\n",
    "plt.plot(x_bins_15, n_x_15,'-o', markersize=2,label=r\"$g=-1.5$\")\n",
    "plt.title(r\"4+5 Local Density Profile\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.ylabel(\"$n(x)/\\int dx n(x)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
