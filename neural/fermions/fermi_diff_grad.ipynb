{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a 1D harmonic trap, no delta function interactions\n",
    "# %env XLA_PYTHON_CLIENT_PREALLOCATE=False\n",
    "# %env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "# %env JAX_ENABLE_X64=False\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = N_up**2 + N_down**2\n",
    "    return ret/2\n",
    "\n",
    "##### Constants\n",
    "N_up = 9\n",
    "N_down = 9\n",
    "N = N_up + N_down\n",
    "\n",
    "\n",
    "# FACT_UP = 1/np.sqrt(factorial(N_up))\n",
    "FACT_UP = 1/5\n",
    "# FACT_DOWN = 1/np.sqrt(factorial(N_down))\n",
    "FACT_DOWN = 1/5\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2.5\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [50,50]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return  Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=jnp.array(np.random.uniform(-1, 1, N)), progress=False):\n",
    "    sq = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "\n",
    "    return jnp.array(sq), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "@jit\n",
    "def Hpsi(coords, params):\n",
    "    return jnp.sum((m * .5 * harmonic_omega**2 * coords**2)) - hbar**2 / (2 * m) * jnp.sum(ddpsi(coords, params))/psi(coords, params)\n",
    "\n",
    "vhpsi = jit(vmap(Hpsi, in_axes=(0, None), out_axes=0)) \n",
    "\n",
    "@jit\n",
    "def grad_helper(coords, params):\n",
    "    return jnp.sum((m*.5*omega**2*coords**2))*psi(coords, params) - hbar**2 / (2*m) * jnp.sum(ddpsi(coords, params))\n",
    "\n",
    "vgrad_helper = jit(vmap(grad_helper, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def grad_comp(s, params, psiHpsi, energy_calc):\n",
    "    return (1/psi(s, params) * dnn_dtheta(s, params)) * (psiHpsi - energy_calc) \n",
    "\n",
    "vgrad_comp = vmap(grad_comp, in_axes=(0, None, 0, None), out_axes = 0)\n",
    "\n",
    "def gradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples,_= sample(params, num_samples, thermal, skip, variation_size)\n",
    "\n",
    "#     samples = jax.device_put(samples, device=jax.devices(\"gpu\")[GPU_INDEX])\n",
    "#     params = jax.device_put(params, device=jax.devices(\"gpu\")[GPU_INDEX])\n",
    "    \n",
    "    # compute the energy \n",
    "    psiHpsi = vhpsi(samples, params) \n",
    "    energy_calc = 1/num_samples * jnp.sum(psiHpsi)\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(psiHpsi)/jnp.sqrt(num_samples) \n",
    "\n",
    "    # gradient computation\n",
    "    grads = vgrad_comp(samples, params, psiHpsi, energy_calc)\n",
    "    gradient_calc = 2/num_samples * jnp.sum(grads, axis=0)\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size):\n",
    "        gr = gradient(params_arg, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "        save_energies(hs, us, \"energies.pkl\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "        # # check if the energy is oscillating around a certain value\n",
    "        # if step_num > 20 and is_oscillating(hs, 20, 0.01):\n",
    "        #     print(\"Energy is oscillating, stopping...\")\n",
    "        #     break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "save_energies([], [], \"energies.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63918\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_size(params, start):\n",
    "    print(\"Searching for step size...\")\n",
    "    lr = .5\n",
    "    target = 0.5\n",
    "    last_acc = 0  # Store the last acceptance rate\n",
    "    # sample at the starting value\n",
    "    _, acc = sample(params, 800, 100, 10, start)\n",
    "    # we accept the step size if the acceptance rate is within 0.05 of the target\n",
    "    while acc < target - 0.05 or acc > target + 0.05:\n",
    "        # If we have a last_acc and the direction of update changes, reduce lr\n",
    "        if last_acc is not None:\n",
    "            if (last_acc < target and acc > target) or (last_acc > target and acc < target):\n",
    "                lr *= 0.5  # Reduce learning rate by half when it overshoots\n",
    "        # move in the direction of the target acceptance rate\n",
    "        if last_acc > acc:\n",
    "            start -= lr\n",
    "        else:\n",
    "            start += lr\n",
    "        last_acc = acc  # Update last_acc with the current acc before the next sample\n",
    "        print(start, acc)\n",
    "        _, acc = sample(params, 800, 100, 10, start)\n",
    "    return start\n",
    "\n",
    "\n",
    "\n",
    "def is_oscillating(values, N, tolerance=0.1):\n",
    "    # Extract the last N values\n",
    "    last_values = values[-N:]\n",
    "    mean_value = sum(last_values) / N\n",
    "    \n",
    "    # Determine if values are oscillating around the mean\n",
    "    signs = []\n",
    "    for value in last_values:\n",
    "        if abs(value - mean_value) > tolerance:  # Only consider significant deviations\n",
    "            signs.append(value > mean_value)\n",
    "    \n",
    "    # Check if the sign alternates, indicating oscillation\n",
    "    for i in range(1, len(signs)):\n",
    "        if signs[i] == signs[i-1]:  # No oscillation if two consecutive signs are the same\n",
    "            return False\n",
    "    \n",
    "    return True if len(signs) > 1 else False  # Requires at least one oscillation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 10501/10501 [00:02<00:00, 3740.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00095229025807066\n"
     ]
    }
   ],
   "source": [
    "_, ratio = sample(params, 10**3, 500, 10, 7, progress=True)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 10501/10501 [00:02<00:00, 3780.60it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram the first coordinate of the samples\n",
    "samples, _ = sample(params, 10**3, 500, 10, 10, progress=True)\n",
    "plt.hist(samples[:,0], bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-2))\n",
    "resultsa = train(params, 400, 1000, 500, 10, step_size(params, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ratio = sample(params, 10**3, 500, 1, 2.3, progress=True)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "resultsb = train(resultsa[3], 2000, 1000, 500, 10, step_size(resultsa[3], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsc = train(resultsb[3], 500, 1400, 500, 1, .03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsd = train(resultsc[3], 10, 5000, 500, 1, .03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = resultsa[3] \n",
    "num_final_samples = 15000\n",
    "params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "samples, _= sample(params, num_final_samples, 1000, 1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psiHpsi = vhpsi(samples, params)\n",
    "mean_energy = 1/num_final_samples * jnp.sum(psiHpsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_energy)\n",
    "print(np.std(psiHpsi)/np.sqrt(num_final_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "energies = psiHpsi\n",
    "\n",
    "# bins = np.linspace(1, 100, 100, dtype=int)\n",
    "bins = np.array([1,2,5,10,20,50,100,150,200,250,300,360,450,500,550,600,660,750,900,990,1100])\n",
    "# now plot the average energy as a function of the number of bins\n",
    "us = []\n",
    "for b_size in bins:\n",
    "    us.append(bin_samples(energies, b_size))\n",
    "plt.scatter(bins, us)\n",
    "plt.title(\"Bin size vs. Uncertainty\")\n",
    "plt.xlabel(\"Bin size\")\n",
    "plt.ylabel(\"Uncertainty\")\n",
    "print(max(us))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = gv.gvar(mean_energy, max(us))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_energy = compute_true_energy()\n",
    "\n",
    "total_hists =  resultsa[0] \n",
    "# + resultsb[0] + resultsc[0]  + resultsd[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] \n",
    "# + resultsb[1] + resultsc[1] + resultsd[1]\n",
    "#+ resultsd[1] \n",
    "# + resultse[1]\n",
    "# + resultsd[1]\n",
    "\n",
    "# total_hists = jax.device_put(total_hists, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "\n",
    "# get index of minimum value\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists, label=\"Adam: \" + str(final))\n",
    "# plt.xlim(1000, 1050)\n",
    "# plt.ylim(30, 50)\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# get the network structure\n",
    "plt.plot(np.arange(0, len(total_hists)), [true_energy for x in np.arange(0, len(total_hists))], label=r\"True Energy, \" + str(round(true_energy,3)))\n",
    "pdiff = (final - true_energy)/true_energy*100\n",
    "# plt.annotate(\" Final Percent Diff = \" + str(round(pdiff,3)) + \"%\", xy=(.1, .9), xycoords= 'axes fraction')\n",
    "plt.legend()\n",
    "plt.title(str(N) + \" Fermions, \"+ str(N_up) + \" Up, \"+str(N_down)+\" Down\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
