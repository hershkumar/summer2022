{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=False\n",
      "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
      "env: JAX_ENABLE_X64=True\n"
     ]
    }
   ],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=False\n",
    "%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "%env JAX_ENABLE_X64=True\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 1\n",
    "N_down = 1\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 1/4 #increase this when N goes up\n",
    "FACT_DOWN = 1/4 # increase this when N goes up\n",
    "SYM_DEN = 4\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2.5\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [100,100]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"1+1/1+1_100_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "        save_energies(hs, us, \"energies.pkl\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .05\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        it_num += 1\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "        \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0854344122657582\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "save_energies([], [], \"energies.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2102\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hists = []\n",
    "total_uncerts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5500000000000005"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_step_size(params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 10101/10101 [00:00<00:00, 30945.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4552024552024552\n"
     ]
    }
   ],
   "source": [
    "s, sp, ratio = sample(params, 10**3, 100, 10, 2, progress=True)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.06452178480736: 100%|██████████| 250/250 [01:22<00:00,  3.04it/s]  \n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "resultsa = train(params, 250, 500, 100, 10, find_step_size(params,2), g)\n",
    "total_hists += resultsa[0]\n",
    "total_uncerts += resultsa[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.0050262700872474: 100%|██████████| 500/500 [10:25<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-4))\n",
    "resultsb = train(resultsa[3], 500, 2000, 100, 10, find_step_size(resultsa[3], 1.5), g)\n",
    "\n",
    "total_hists += resultsb[0]\n",
    "total_uncerts += resultsb[1]\n",
    "# save the parameters to a file\n",
    "save_params(resultsb[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.2072954982422388: 100%|██████████| 200/200 [04:08<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "g = .5\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "resultsc = train(resultsb[3], 200, 2000, 100, 10, find_step_size(resultsb[3], 1), g)\n",
    "total_hists += resultsc[0]\n",
    "total_uncerts += resultsc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.1886074147887262: 100%|██████████| 800/800 [16:41<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-5))\n",
    "resultsd = train(resultsc[3], 800, 2000, 100, 10, find_step_size(resultsc[3], 1), g)\n",
    "total_hists += resultsd[0]\n",
    "total_uncerts += resultsd[1]\n",
    "save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.35401643399711: 100%|██████████| 800/800 [16:49<00:00,  1.26s/it]  \n"
     ]
    }
   ],
   "source": [
    "g = 1\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "resultse = train(resultsd[3], 200, 2000, 100, 10, find_step_size(resultsd[3], 1), g)\n",
    "total_hists += resultse[0]\n",
    "total_uncerts += resultse[1]\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-5))\n",
    "resultsf = train(resultse[3], 800, 2000, 100, 10, find_step_size(resultse[3], 1), g)\n",
    "total_hists += resultsf[0]\n",
    "total_uncerts += resultsf[1]\n",
    "\n",
    "save_params(resultsf[3], PARAM_PREFIX + str(g) + \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.4615877379572553: 100%|██████████| 800/800 [34:03<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "g = 1.5\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "resultsg = train(resultsf[3], 200, 3000, 100, 10, find_step_size(resultsf[3], 1), g)\n",
    "\n",
    "total_hists += resultsg[0]\n",
    "total_uncerts += resultsg[1]\n",
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-5))\n",
    "resultsh = train(resultsg[3], 800, 4000, 100, 10, find_step_size(resultsg[3], 1), g)\n",
    "\n",
    "total_hists += resultsh[0]\n",
    "total_uncerts += resultsh[1]\n",
    "\n",
    "save_params(resultsh[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.53718822945363:  39%|███▉      | 310/800 [16:17<25:31,  3.13s/it]  "
     ]
    }
   ],
   "source": [
    "g = 2\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "resultsi = train(resultsh[3], 200, 4000, 100, 10, find_step_size(resultsh[3], 1), g)\n",
    "\n",
    "total_hists += resultsi[0]\n",
    "total_uncerts += resultsi[1]\n",
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-5))\n",
    "resultsj = train(resultsi[3], 800, 5000, 100, 10, find_step_size(resultsi[3], 1), g)\n",
    "\n",
    "total_hists += resultsj[0]\n",
    "total_uncerts += resultsj[1]\n",
    "\n",
    "save_params(resultsj[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = resultsj[3]\n",
    "num_final_samples = 20000\n",
    "params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "samples, samples_prime, _ = sample(params, num_final_samples, 1000, 1, find_step_size(params,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = jnp.array(samples_prime[:, N_up]) \n",
    "alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "e_term = vEs_nodelta(samples, params) + vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "energy_calc = 1/num_final_samples * jnp.sum(e_term)\n",
    "mean_energy = 1 / num_final_samples * jnp.sum(e_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_energy)\n",
    "print(np.std(e_term) / np.sqrt(num_final_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages) / np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "energies = e_term\n",
    "\n",
    "# bins = np.linspace(1, 100, 100, dtype=int)\n",
    "bins = np.array(\n",
    "    [\n",
    "        1,\n",
    "        2,\n",
    "        5,\n",
    "        10,\n",
    "        20,\n",
    "        50,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        250,\n",
    "        300,\n",
    "        360,\n",
    "        450,\n",
    "        500,\n",
    "        550,\n",
    "        600,\n",
    "        660,\n",
    "        750,\n",
    "        900,\n",
    "        990,\n",
    "        1100,\n",
    "    ]\n",
    ")\n",
    "# now plot the average energy as a function of the number of bins\n",
    "us = []\n",
    "for b_size in bins:\n",
    "    us.append(bin_samples(energies, b_size))\n",
    "plt.scatter(bins, us)\n",
    "plt.title(\"Bin size vs. Uncertainty\")\n",
    "plt.xlabel(\"Bin size\")\n",
    "plt.ylabel(\"Uncertainty\")\n",
    "print(max(us))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.523(11)\n"
     ]
    }
   ],
   "source": [
    "final = gv.gvar(mean_energy, max(us))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true_energy = compute_true_energy()\n",
    "# total_hists = resultsa[0]  + resultsb[0]  + resultsc[0] + resultsd[0] + resultse[0] + resultsf[0] + resultsg[0] + resultsh[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "# total_uncerts = resultsa[1] + resultsb[1]  + resultsc[1] + resultsd[1] + resultse[1] + resultsf[1] + resultsg[1] + resultsh[1]\n",
    "# + resultsd[1]\n",
    "# + resultse[1]\n",
    "# + resultsd[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists, label=\"Adam: \" + str(final))\n",
    "# plt.xlim(1000, 1500)\n",
    "# plt.ylim(30, 50)\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(\n",
    "    np.arange(0, len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=0.4\n",
    ")\n",
    "# get the network structure\n",
    "# plt.plot(\n",
    "#     np.arange(0, len(total_hists)),\n",
    "#     [true_energy for x in np.arange(0, len(total_hists))],\n",
    "#     label=r\"True Energy, \" + str(round(true_energy, 3)),\n",
    "# )\n",
    "# pdiff = (final - true_energy) / true_energy * 100\n",
    "# plt.annotate(\" Final Percent Diff = \" + str(round(pdiff,3)) + \"%\", xy=(.1, .9), xycoords= 'axes fraction')\n",
    "plt.legend()\n",
    "plt.title(str(N) + \" Fermions, \" + str(N_up) + \" Up, \" + str(N_down) + \" Down\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 200)\n",
    "y = np.linspace(-5, 5, 200)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "# now, calculate the wavefunction at each point\n",
    "Z = np.zeros_like(X)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        Z[i, j] = psi(jnp.array([X[i, j], Y[i, j]]), params)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.contourf(X, Y, Z, levels=50)\n",
    "# add a line along x=y\n",
    "plt.plot(x, -x, color=\"blue\")\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.title(r\"$N = 2$, $g = \" + str(g) + \"$: $\\psi^2$ Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz_samples = sample(params, 20000, 500, 10, find_step_size(params, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def local_density(samples):\n",
    "    x_bins = np.linspace(-5, 5, 70)\n",
    "    dx = x_bins[1] - x_bins[0]  # Bin width\n",
    "    n_x = np.zeros_like(x_bins)\n",
    "\n",
    "    # bin the x_1s\n",
    "    for x in samples[0][:,0]:\n",
    "        n_x[np.digitize(x, x_bins)] += 1\n",
    "\n",
    "    # Normalize\n",
    "    n_x /= (dx * np.sum(n_x))\n",
    "\n",
    "    return x_bins, n_x\n",
    "\n",
    "x_bins, n_x = local_density(ansatz_samples)\n",
    "plt.plot(x_bins, n_x,'-o' ,label=\"Ansatz\", markersize=2)\n",
    "plt.title(r\"$N = 4$ Local Density Profile\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.xlim(-6,6)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.ylabel(\"$n(x)/\\int dx n(x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
