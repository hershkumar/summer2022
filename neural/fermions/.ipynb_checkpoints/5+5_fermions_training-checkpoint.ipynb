{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 5\n",
    "N_down = 5\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 4\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"5+5/large_g_150_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.196507666098807\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244510\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:17<00:00, 290.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4320721427171143\n"
     ]
    }
   ],
   "source": [
    "step_size = .3\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=1.5\n",
    "# first find the step size\n",
    "step_size = .3\n",
    "resultsa = train(params, 50, 10000, 1000, 10, step_size, g)\n",
    "# resultsb = train(resultsa[3], 1000,400,100,10, find_step_size(params,step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "resultsb = train(resultsa[3], 20,50000,1000,10, find_step_size(resultsa[3],step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxb133n/c/BSoCkuJMiRVK7ZEmWJVuyLcv7Gm+JnaRO0zYZN5PE05lOn7RPZ5q0k5n0aZt5mtd00qZJmmmWJs4eO4kdZ/MmybYsedFiWbtEkSLFneBOgtjuvWf+wCKQIkVQwqUE6Pd+vfQCcQkS54rElwe/s1yltUYIIUTucVzqBgghhLgwEuBCCJGjJMCFECJHSYALIUSOkgAXQogc5ZrPJ6usrNRLliyZz6cUQoict2/fvn6tddXU4/Ma4EuWLGHv3r3z+ZRCCJHzlFJt0x2XEooQQuQoCXAhhMhREuBCCJGjMgpwpdSfKaWOKKUOK6V+pJQqUEqVK6VeUko1JW7L7G6sEEKIs2YNcKXUIuD/ATZrra8GnMCHgc8A27TWK4FtiftCCCHmSaYlFBfgU0q5AD/QBTwCPJn4/JPAo9lvnhBCiJnMGuBa607gH4AzQDcworV+EajRWncnHtMNVE/39UqpJ5RSe5VSewOBQPZaLoQQV7hMSihlxHvbS4E6oFAp9ZFMn0Br/XWt9Wat9eaqqnPmoQshhLhAmZRQ7gFOa60DWusY8HNgK9CrlKoFSNz22ddMIXKTZcl++8I+mQT4GWCLUsqvlFLA3cAx4Dng8cRjHgd+YU8ThchdEcO61E0QeWzWpfRa67eUUj8F9gMG8A7wdaAIeEop9XHiIf+YnQ0VItdorYmaFj6cl7opIk9ltBeK1vpzwOemHI4Q740LIaZhWBpTSijCRrISUwibmJbGsKSEIuwjAS6ETaQHLuwmAS6ETUxTAlzYSwJcCJvELAupoAg7SYALYROpgQu7SYALYROpgQu7SYALYRPT1JhaAlzYRwJcCJsYloVhSoAL+0iAC2ET09JY0gMXNpIAF8ImMVNjSA1c2EgCXAibmJaW3QiFrSTAhbCJYVnSAxe2kgAXwibSAxd2kwAXwiZSAxd2kwAXwiamLOQRNpMAF8ImhmVJgAtbSYALYZP4XigS4MI+EuBC2MSQhTzCZhLgQthEeuDCbhldE1MIMXcx00I64MJOEuBC2CS+F8qlboXIZxLgQtjEsDRIgAsbSYALYRPT0lJCEbaSQUwhbJAe3jIXXNhFAlwIG8TMs9fClOtiCrtIgAthg/Ret+S3sIsEuBA2SJ//LT1wYRcJcCFsID1wMR8kwIWwQXqvW3rgwi4S4ELYIL0HbspcQmGTWQNcKbVaKXUg7d+oUupPlVLlSqmXlFJNiduy+WiwELnAMNMCXKYRCpvMGuBa6xNa641a643AJmACeAb4DLBNa70S2Ja4L4RgyiCmKQEu7DHXEsrdQLPWug14BHgycfxJ4NFsNkyIXGam1b1lS1lhl7kG+IeBHyU+rtFadwMkbqun+wKl1BNKqb1Kqb2BQODCWypEDknvgUsJRdgl4wBXSnmA9wFPz+UJtNZf11pv1lpvrqqqmmv7hMhJUgMX82EuPfAHgP1a697E/V6lVC1A4rYv240TIldNXsgjAS7sMZcA/z3Olk8AngMeT3z8OPCLbDVKiFyXXgOXHriwS0YBrpTyA/cCP087/PfAvUqppsTn/j77zRMiN0kJRcyHjPYD11pPABVTjg0Qn5UihJhCFvKI+SArMYWwgcxCEfNBAlwIGxhSAxfzQAJcCBtIDVzMBwlwIWxgSglFzAMJcCFsIDVwMR8kwIWwweT9wCXAhT0kwIWwgdTAxXyQABfCBpMuqSbzwIVNJMCFyDLL0qR3uqWEIuwiAS5Elk0NbFOuiSlsIgEuRJZNrXmbkt/CJhLgQmTZ1KvQSw9c2EUCXIgsm3oNTOmBC7tIgAuRZdMNWhqS4sIGEuBCZNl0875lS1lhBwlwIbJsag0cQMrgwg4S4EJk2dQaOEwf6kJcLAlwIbJsuhq4LKcXdpAAFyLLpq2BS4ALG0iAC5Fl05VLJMCFHSTAhcgymYUi5osEuBBZNv08cAlwkX0S4EJk2XRhLVvKCjtIgAuRZdPVwGVLWWEHCXAhsmy6GrglAS5sIAEuRJZNWwOXABc2kAAXIsumq4HLNEJhBwlwIbJsuv2/JcCFHSTAhcgyKaGI+SIBLkSWTTuIKdMIhQ0yCnClVKlS6qdKqeNKqWNKqZuUUuVKqZeUUk2J2zK7GytELph2N0JZyCNskGkP/EvA81rrq4ANwDHgM8A2rfVKYFvivhBXPOmBi/kya4ArpRYAtwHfAtBaR7XWw8AjwJOJhz0JPGpXI4XIFVprqYGLeZNJD3wZEAC+rZR6Ryn1TaVUIVCjte4GSNxWT/fFSqknlFJ7lVJ7A4FA1houxOVopqCWhTzCDpkEuAu4Dvia1vpaIMgcyiVa669rrTdrrTdXVVVdYDOFyA0zTReUHriwQyYB3gF0aK3fStz/KfFA71VK1QIkbvvsaaIQuWOmoJ5ubrgQF2vWANda9wDtSqnViUN3A0eB54DHE8ceB35hSwuFyCHmDLNNTMlvYQNXho/7E+AHSikP0AJ8jHj4P6WU+jhwBnjMniYKkTtiM/S05YIOwg4ZBbjW+gCweZpP3Z3d5giR22aqgUsJRdhBVmIKkUUz1cBlIY+wgwS4EFk0Uw1cFvIIO0iAC5FF012NB+KDmFpCXGSZBLgQWXS+bWNlS1mRbRLgQmRR7Dy1blnMI7JNAlyILDpfL1vq4CLbJMCFyKKZauAgJRSRfRLgQmSR1MDFfJIAFyKLpAYu5pMEuBBZlN7LPtQ5wmsnz26hLFvK5r/YPG96IwEuRBal18D3tw3xZstA2uckwPNdMGLM6/NJgAuRRek98PGIQShmTvs5kZ/GJcCFyF3pvexg1CBiWKnglgDPf8GIOfuDskgCXIgsSg/p5NvpZC9ctpTNf8Go9MCFyFnJQayoYaVmpISiiQCXHnhe01ozIT1wIXJXMqTTa6GhRK9MAjy/xUxNxJAAFyJnJWvg6bMRUiUUCfC8FjMtmUYoRC4zpwnwiUQJRaYR5reYaRExJMCFyEmmpUmOU6YPZkkP/MoQNS2iEuBC5Kb0t8/jaYNZyUFM2Y0wv8VMTczU83rhDglwIbJk6hRCt1PhdTlSPXC5LmZ+S/a+z7cfTrZldFV6IcTsjCkBXuiNv7xkGuGVITWF1LTwuOanbywBLkSWmFNWYRZ6XGitZSHPFSLZA48aFnjn5zklwIXIkvSNrMYjBsVeN4ZlpWahmOe52IPIfemLuOaL1MCFyJLJNXCTQq8Ln9uZVkK5VC0T8yFZ+57PueDSAxciS5KDlFrrRA3cidOhCMUmAOmB57tkcM/nXHAJcCGyJDmIGTEsDEtT5HWhMAlFTbTWspAnz0UvQQlFAlyILEn2sJOrMOODmPHBy5ipZRZKnosZZ2ehzBepgQuRJVP3QUnWwAEmooYs5Mlzl20NXCnVCowBJmBorTcrpcqBnwBLgFbgQ1rrIXuaKcTlL1kDDyYGLQu9ztSLORQzZSFPnrvcZ6HcqbXeqLXenLj/GWCb1nolsC1xX4grljFlK9kirwufJ94DD0VNKaHkuUnzwOfJxZRQHgGeTHz8JPDoxTdHiNx1Tg08rYQSiplYmnndJ0PMH8s6O0h9OdbANfCiUmqfUuqJxLEarXU3QOK22o4GCpErUiWUiIHH5cDtdEzqgYMsp89XsbQpopfjLJSbtdZdSqlq4CWl1PFMnyAR+E8ANDY2XkAThcgNqb3AoyaFieD2p/XAIV5mcTkvTfuEfdI3sLrsSiha667EbR/wDHAD0KuUqgVI3PbN8LVf11pv1lpvrqqqyk6rhbgMpdfAixIbWXlcDhzq7EUdZCZKfoqlhfZ8zkKZNcCVUoVKqeLkx8B9wGHgOeDxxMMeB35hVyOFyAVGWg08uROhUmrScnpZzJOf0uvelp6/EM+khFIDPKOUSj7+h1rr55VSe4CnlFIfB84Aj9nXTCEuf+k18LpSX+q4z+NKlVAsCfC8NLVsEjMt3E77l9nMGuBa6xZgwzTHB4C77WiUELkofkk1Hd/IynP2peVzO6QHnuem9rijhoXfY//zykpMIbLEsDThmIWpNUXesyOV/rQeuMxCyU9Tr8IzXwOZEuBCZIlhWamLGSdr4AA+j5OJxHEJ8Pw0tQc+XzsSSoALkSWGqSct4knyuZ3SA89zUxfvzNcgpgS4EFliWjMEuMdJOGZhadmRMF/FpvS452s1pgS4EFlgWRpLw3gk3tMumtIDBwjHTBnEzFNSAxcih6W2kk3WwD3pg5hnl9PLQp78NLVkIiUUIXKImbYK0+ty4EqbA3x2T3DZUjZfTS2ZyCCmEDlkulWYSakNrWLSA89X080Dnw8S4EJkQfoqzKKpAe4+W0KRGnh+OreEMj8/ZwlwIbLg7OXUzEn1b5jcA5cr0+enmCGDmELkLDPtepgzlVAmoibzuFGdmCfpF3NIiprmvDy3BLgQWWBY8Xnewei5Ae5yOPA4HYRjclm1fDTdnO+pPXK7SIALkQWGqQknLps2tQYOyeX0EuD5KFn/Pt0f5Js7WzAsC8Oan0VbEuBCZIFhxXchhPjV6KdKLqc3pAaed5IDls2BcVr6gwwFY8D81MElwIXIAtPSqavRTy2hQLwHHooaMo0wDyV74GPh+M9/JJQI8HkY8JAAFyILDMs6uw+KZ5oAdztlIU+eSva0x8Lx4B4JRScdt5MEuBBZYFo6tYx+uhq43+NM1MglwPNNdEoPfFh64ELkFiNtJ0L/DDXwCVnIk5fOllASPfCJ+O3UHQrtIAEuRBYYpmY8YlLgduBynPuy8nmcGJZOXVpN5I+YobH02TEQqYELkWOSNfDp6t9wdjFP8kUu8kfUtJiIxqeQQlqASw9ciNyQvJjDdPVvOLsfynhYAjzfxEwrVT4pLnBJD1yIXGNY06/CTJIeeP6KB3j851pf5idiWIRjpvTAhcgVyRr4TAHud8ePT0RNtMxEySvpAd5Q5gPiM1EkwIXIETHTZCJiTLsKEyZvaCUzUfJL1NCpEsqiRICPTMTm5ao8EuBCZMFoyEAz/RxwSNsTXDa0yjvJHrjX5aCqyAvEBzKlBy5EjkgOXM00C8XrdqCAUNSQAM8zMdNiLGJQXOCmuMCNIr4aUwYxhcgRqQCfoQfuUIqCxGIeU2rgeSU5C6W4wIXToVIzUaQHLkSOGE0E+EwlFIgvpw/FTEzZDyVvmJbGtOLL6IsL4j/7Ep+b4VCMmKltH7CWABfiImmtGQ0ndyKcfhATkjsSSg88n8RMC63jg5jFiT/eJX5Pajm93VenlwAX4iJN2gdlhho4nN0TXGrg+SNqWkQMi5ipKS5wA1DqczMSiqG1tn0mSsYBrpRyKqXeUUr9KnG/XCn1klKqKXFbZl8zhbh8JfcC97mdOB1qxscle+AyjTB/xIyzc8DTSyiGpZmI2r+YZy498E8Bx9LufwbYprVeCWxL3BfiihOJWQSj5nnr33C2B25JgOeN6KRl9PEeeIkvfjsSitk+EyWjAFdK1QMPAd9MO/wI8GTi4yeBR7PbNCFyQ99YOHE1+pnr35AYxIya87LAQ8yPmKEZi5zbA4d4gNt9ceNMe+D/BPwFkP6bV6O17gZI3FZP94VKqSeUUnuVUnsDgcBFNVaIy1HvaCQR4LP3wDWkBjxF7oua05RQ/PEAHw7FiJr2bh88a4ArpR4G+rTW+y7kCbTWX9dab9Zab66qqrqQbyHEZa1vLMx4JgGeGOAcmYjOR7PEPEjOAXc5VGq1bZHXhVMpRiZits9COf9vXNzNwPuUUg8CBcACpdT3gV6lVK3WulspVQv02dlQIS5HwxNRJqImoQxr4HD2klsi9yWX0RcVuFAqPoDtUIoFPhcjoWjqivV2mbUHrrX+S611vdZ6CfBhYLvW+iPAc8DjiYc9DvzCtlYKcZnqHY3EdxgECj3nr4EnN7QaDUkJJV+kVmFO+eNdkphKeDnNQpnq74F7lVJNwL2J+0JcUXpHw6k9vmcvocQDfER64HkjvhOhkZqBkjRfAZ5JCSVFa/0K8Eri4wHg7uw3SYjcoLWmbyySWsQzW4D7EyWU5LQzkfuSJZSllYWTjpf4PIyGRokYl3gQUwgxveGJeA8rGeCz1sClB553JqIGoZh5bg/c78bUmv4xewesJcCFuEC9Y2GAjHvgbqcDl0PJZdXyyMB4BIAFBZN/9qWJueB942Fbn18CXIgL1Dsaf/GOR0wU8YU6s/F5nKl5wyL39QcTu1AWnDuICRAYi9j6/BLgQlwArTV9o4keeNTA53HiUDPvg5LkczulB55HhoLxEsl0g5gAA0EpoQhx2RkMnp3jG4wYs9a/k/weCfB8cjbAJ//8/R4nLkd8MY+dM1EkwIW4AMnyCZDRMvokn9uZqpmL3GaYFqPhGIpzB7CVUmkXdpAAF+KykhzAhPjVWGZbxJPk87gkwPNEzIzPAS/yuqYtn5X43YxMRKUHLsTlxLJ0anCqczjEQDBKY0XhLF8V53M7CEbtnRss5kdyI6up5ZOk5IUd7NxSVgJciDkaCEYxEvXv3af68bgcbF6c2fVMfB4XUcOalwveCnvFr0YfO2cAM6nE52YsbDARte8dV04EeDBi8GbLwKVuhhBAfPk8xFdUHuwY4brGMgrcmZZQZDFPvojN0gMv8XnQQPeIfXPBcyLAP/vsYT755F5CNr/1tPsK0iI/9CXq32+dHsTUmq3LKzL+2uRyegnw3BeOWowndiKcTnIqYddwyLY25ESAf/j6BsYiBj96u8225+gbC7P/zNCcvsaQK6tccSwrvjw6Zlq8dXqQqxYWU1nkzfjrz/bAZU/wXBcYj6A5dw54UvLCDj1Xeg/8hqXlLK0o5N92tdrWS24JBDnRM05zYDyjx3ePhHj1pFxh6ErTPx7BsDQHO0YIRgy2Lq+c09cn9wQfCkoPPNf1JoJ56layScnl9MmSmx1yIsCVUnzs5iV0DIV4+djs143QWrOndTDj72+YFmcGJwDYc3pw1uWvfWNhdp7sp3c0ktoLQVwZekcjaK3Z3dxPdbGX5VWZzT5JSi63H5Kr8uS8ZClt6j4oSQVuJ16Xg75R+zIiJwIc4EPXN1DkdfGvrzbP+tgTvWM09Y5n/JfvzOBEalaBpWFnU2DGkeOhYJRXTwQwElcWP94zluEZiHzQOxrm9ECQ7pEwNy+vTF2FJVOpHrgEeM7rT3TeZiqhQLwOHrCxk5czAV7gdvK+jXXsaxvieM/ojI8bDcd4s3mAZ9/p5LUMSxzNgeCk++GYxWsnA+fUuEfDMXac6Jt0maT2wQlZmHGFMC3NQDDC7lMD+D1ONjaWzvl7FCR64MMTUkLJdcl9TtIHMV3OyX/QS3xuBsbt+2OdMwEO8Ee3LUMp+Or2U9N+XmvNG6f6+dn+Tt5uHeS7b7TNunn+WDg2bclkMBjjrdNnyzATUYMdx/sIxyxipsULR3r4wvPH6R4Jc7L34nrho+EYnTaOVIvs6B+PEBiLcqx7lBuWlON2zv3l41CKAreDIQnwnDcQjOJzOyf9HlzXOHk9QInPzaCN77ZyKsAbKwq5cVkFLx3rpX+afXaP94yx7XiAQ50jVBR6ONw5wrZjvef9ni1Tet/p2gYmONI1Qjhmsv14H8GIyZmBIF/ZfopXTwYIRgx+ebCLpt6xi9rvYH/bEG+1DBCO5cYKvcOdI5e6CZdEx9AEbzT3oxTcuCzzqYNT+dxORmUaYc4bCkYn9b7L/G6WVxVS6D27JqDEH1/MY9eVeXIqwAE+eesywjGLb7x2etLxkVCM104GeO7dThrL/Txx2zLcTgff2d0246o3rTWn++MB3jE0wYH24XPm5x7sGOHFo730j0X5zaFu/vW1FqKmxR9uXcKD62tpCQR5p33kvH8IzqdrOETXcJhwzMqJxUpj4RiHOkeuuHnMWmtO9o6xt22IqxeVpOb4Xgifx8mw1MAvymg4xu7m/ks6lXd4IjZpEU9NSQFKKVZWF6eOJWei2DWVcE7XxLwc3Lm6ioZyH8++08mf3rMSn8eVmhXw9N4OLAse21TPLSsr2XWqn51N/exsCnD3mppzvlfPaJiJqMlYOMa3d7USSvSAKwo9LK0sZGllIcuqimgJBPn5/g4GglFuXFrOe9YtpMDtxErMdvntoW42LS5jVU3RnAa1LEtPmnveNRzmVN8YK9J+AS43J3vH0RpaAuNc25jZ8vF80DcWYdepASKGxc1znDo4ld/tYlQu6nBRWgJBWvsnGA3FuHVlVca7QWbTcChGY7k/dX/hggIAllcXcrhzBMPSlPg8QHysbHGG++XMRc71wJVS/O7mBnrHIjy1tx2AY91j/PpgN6cC4zywfiFbV1Swrq6E37+xEZdT8a+vtUw7f7wlEERrzS8OdBEzLT66ZTEPrq+lutjL4a4Rnt7XwReeP843draggY/fspRHNi5KLZt2KMXD19QxHIrxm0PddAzNrY59oneM0dDkF/L+tmFGL9OL3hqmRUtinnzrQBDLunJWrrYOBHmjeYCGMh8NaS/aC1HgcTIYjDIUjNq61Wi+ir9zjv8eDgZjPH+4x9a51jO1YTQUS80BdyioLo4v6PK6nDRWxH9Hku/U5poNmcq5HjjAv7tpMV97tZkf72nngfW1bDvWw/OHe1hdU8x9a2vY2BDvGd6+qpobl1awu7mft1sHuXHp2bpl1LDoGJrgYOcIR7tHuX/dQtbULgDglhWVWFrTMxLmdH8Qw9LctKwCj+vs3zuXQ+FxOVhaWcg19SW8djLAzqZ+fv/GxozOIRwzp60lG5bmjeYB7l1Tg8MxtylqdjvdH0zNwAlFLbpHwywq9V3iVtlPa83LR3sZCEa5Z03DOZ+vLSkgYlgMZnj1Fb/byelQjN8e7gGgwO2guMBNkddFbUkBSyqz31PLJ10jYULRs3/4IobFjuN9XNtYxuqF8/PudTRkYFg6VUKpKvbiShvMXFVTTEsgmArwTpsCPOd64AALfB7uXVPD8e4xntrTzo/3dOBxOfidTYu4ZUUVzkTw+TxOPnnrUhxK8ZUpM1faBoIMT8T45btd1Jf5uGXl5LfFDqWoK/Vx84pKbl9Vhd/rpLa0gA0NJdyztprf2VTPA+sXUlzg4oGra3EoxfffbMt4Yc+77cOTpiOmGxiPcqRr5qmSl0pT3+RVqi0ZrlrNdb2jEXY29VPodbFu0YLUcY/LwZZl5dx5VTX3X72QW1dWZlQb93mchKJG6l1hOGYRGItwuj/IGy0D896bnE1zYPyymio73e+dpWFf2xBvNA9gzsM7w66ReCAn54DXJMonSeWFHiqLPHhcDnxuJ50jEuCT/PtblqIUfGPnaTqHQzy6cRG3r65O7T+QdPOKSrYsq2D3qQGOdp3t8TYHgvzy3S4ihsUHr6uf8XqGlUUe7ltXw2Ob6rlzdTXr6kqoLi7A4VB4XU7uWF1FdbGXO1ZXcbR7lJ/u7Zi17YPBKC395x/0PNI1klooYKfW/iAHO4ZnfVzvaPicucudQ6GcmTlzMfa1DXKiZ4zrF5fhcsRfMvVlPh5aX8uyqqLU4xrK/Ty4fiE3La+YcYMjiF+9xdLwxZdO8uuDXTQHxlOhozXsbu6/bP5fR0Ix9rYOsrOp39ZgzHRQPBwz6RwKcWZwgoMdw1hTSqOn+4O8eKTH9kH27lSAx3/OC0sKznnMqpr4u4FSv9u2QcycDfBr6kvZ2FDKSCjGtQ2l3LeuJvUfls7ldPCf71wOwD++3ATAyESMV08GONw1yt1XVZ/z1xNAKVhXt4B71tRQWeSdcXCyuMDN7auruGNVFeWFHr616/SsGxXtaxsi/feuOTDOO2eGJv0yWhp2Nw/YOsreNxrmzZYBjnSNztrrS5/rnmynpeO14XxmWZpn3ukE4Pql5XhdDm5eUcFtq6pSG1OlU0qxtLKQh9fXcv2Ssml75NcvKed9G+qoKPLw5ulBvvX6aT7/m6P86O0zvNsxTDBisru5/5Lvjqm15s2WAUwr3umYy/YUcxE1LLYd683oCu6tA0FCUZPvvdnGj/e085Xtp2jqm7wOY2gixguHezLe1+hC9IycXYXpdioqCj3nPKax3I/P46DE56bHpndVORvgAP/h9uVcv6ScxzbXs+U883K3LK9k6/IKth/vo20gyP72IZ470MmiUh+3rqw65/F+j5O7rqpmQ0NpRnXoyiIvt66q4uFraukbi/C/Xzg549a3rf3BSb+oB9qH+Pau0zy9r4NvvX56Uh11PGywq3nAlsHCkVCM15r6sXS81/dG88zz0IMRIzUI09Q7xud/fSxVv7/Q6ZO5omN4gjdbBlm9sJjVNcU8dE1tRrMJHA7FysTjH9lYxw1Ly1hU5kuNnWxZVsEfbl3KZx9aw0dubGRdXQkt/UF+sqedp/e20zkU5nDnpS2jHe0enbSKsCUQ5FRf9reOONQ5TDhmsa9t9t1AWwJBXmvqJxgxuHdtDRHD5Nu7Wvn2rtOpXjHEx5Leahlk96l+WwaKk4FcXOCiZkHBtB08h0OxvKqIEp/btv1QcnIQM+mWFZUMBqPcsbpq1g31//y+Vez62m7+4YUTtA+FCMcsPripPlUvT6ov83HD0vKMN+hPaij383s3NPJWyyA/2dvOwpICahYUUOp3J/55KPG5OdB+tlzx1ukBnjvQxdLKQq5eVMILR3r40raTvGfdQrYsq8ChFJ1DId5oGWDr8oo577sxk3DM5JUTfQQjBs8f6WE0FON3NtXz1ulBbl917h+0pr741MHe0TA/fPsMEcPi5+90UF8WH8AcDEYpn6YHkjQSimGYFhVz2Hb1cvGzfZ2MRwxuXFbO5iWZX7ghXaHXxYrqYlZUF2NZmr6xCGcGJ2jtD4LLydq6EtbWlWBpzasnA7x0tBdLx98FVi/wTvsO8XwsS3O0e5TukTCraopoKPPPeUB8eCLKoY4RYma8d7yozM/6RSXsbR2i1O+Z0xa6sz3PiZ4xmvrGWVxeSEtgfFJZKt3AeIQzAxO8firA+kUl3DktImsAABVESURBVLm6mltXVPJmywA7TgT4yvZTXNdYxj1ra1LvfFoHJugPRrl5eUVWf//6RsO4nQqvy0HtNOWTpBXVRZT63YxH4lfm8XuyG7k5HeCFXhe3rKiktmT2mRAbG8u4eUUlvz7UjaXhnjU1qXmbEB+Q2lBfwsppyjCZWlO7gD++czl//vS7fGlbE/esqWHLsopJVzBPeu1kgOePxGfO/P6NjbidDq5aWMyzBzr51cFuDneO8sHrFlFR5KVtYAKnQ533XUamDNPilRMBmvuC/HjPGfrGIijgO5FW/vCmJdSVFEz6PzAtTXPfOOMRg+++0YrH6eCjWxbz3TfbeGpvB5+4dSktgXHKC8unfb5gxODFIz2EYyabl5SnZvqcT9dwiHcTf+gcDoXLoXA4FE4V/1gphUPFP+dQJO4rirxOSv0eSn3uSTMCLpRlaX51sIsyv5t7r6qh1D/zH6lMORyKhSUFLCwp4Jr6Ek4mNl6LGBYOpbhzdTUuh+K3h3swLY3XpXjvhkUZ/+EYCcXYdaqfl4720jsaZl1dCWvrillVU8yK6iK8rtm/j2XFSyehqMn33mpLvctqWlzGw9fU8XpTP/dfvXDGNk1EDUxLn3eTp6S9rUPsbOrnt4d7WFu7gAU+Jw3l/mm3KWjpD/LysV4sC96zbiEQL5HesrKK6xaX8cqJAG80D7D/zBBVxV4WV/hpLC+ksdxPMBxjTV0JtSUFlPk9k2aUXYjAWITiAjdKKWrOE+B+j4ullUVAL13DYVZUT//H6ULldIADc5qT++n7r+K9X36dupKCVE9zYYmXZZVFNJT7z+mNX4j3bqgjFLP45s4Wfn2om/1nhnjfhrrU226tNS8f62PHiT7WLyrhsc31qYGxUr+Hx29awv4zQ/z6UDf/vL2Je9fUsGV5BS2BIG6nYtPi6YMyE1prXj/Vz68PdfPbQ90UuJ18bOsSwobFT/ac4Tu7W3E64lOikmHVNhAkGDH4wZttjIUNPnnrMhrK/bxvQx0/3dfBaycDFLidXNtYds7/X8Qw+fGeM3x5+ylMU/PwhjruW1vNTcsrp33xh6ImO4738a3XT/NuxzBVxV4ayv00lvlpKPdTWeQ5512I1pqoYTERNfG4HPg9ThwORaHXRZnfTZnfQ0OZ/5zB7UzsbhmgORDk/nU1bLiAjatmU+B2ck19KWtrF9AcCHK8Z5RgxOTWlfGZVL862M03d7ayoMDNfesWnvcdmNaa4z1jvHCkh5/t66B9KIRDxcdRSn1urqkvZdPiUrauqGRVTfF5Z8sc7hrhzGCIJ3e30j0S4oPX1dM/HuG1kwHODE7w4esb2XWqnztXV6d69pal6RwO0RwYp3skTIHbwd1ralhwnhBvGwiyq7mf5w/3UF7o4Wj3KC8d7WNZVTEbGyb/fxumxZvNA+xrG2Lr8opz3vH5PS4eXF/LlmUVHGgf4szgBIc6R9jTOpT4vJOGMj+LynzUlfhYvbCI5VVFVBZ7qSryUnaed5DT6R+PUOx1Ueh1nvccATbWlwDxgU8J8Itw9aIS/u7RdVgaNjaUsqyqMOsruJRS8Z5zoZvtxwP8OrH8flNjGe+5eiGvnOhjd/MAmxeX8ei1i86Z/aJUPKRXVBfz7Dud/OZwD7tbBrhrdTWmpXE5HGxouLAw2XG8j//1wgmO9YyxuqaYD26qpyh1/o38ZM8Zvvl6K36vm0c31uFyOjjRM8rP3+mkbXCCD1/fkPqDeW1DKSd7x3j5WC/Lq4roHAqlFi9A/AX3vTfa4gPHWrPA5+ZHb59hf9sQv3v9BA9fU0t14h1QMny+sbOF3x7qIWKYbGwoZTRs8G77MG8nNhXzuZ0sKvNhac1ExGQiahCMmpNmR7idigUFbkr8bkp9bkp8bhrK/dy9ppprFpXO6YX6vTfacDoUH9zUkFFv8kK5nA5WLyxmVU0RrQMTHGgfYuvySpwOxS8OdPEPL56ktNDD2toFeF3Oc3qPY+H4oPxTezp4/VT8D+pjm+pZW7eAY91jvNs+zOunArzWFOBHb7ezsaGU96yrYdPicurLfJPKK4PBKLtP9fOt11sZmojykRsXc1XiXdPyqiKe3tvOv7xyigfX11Lqd7OyppjmvnFO9wfpGg7T1Bd/RwHxudIfuG7RtP93hmnx8tFefvx2O9ULvPzRbct5el8HLxzpYUmFn+VVhZO+rmMoxC8PduF1O7hzdfWM/5flhR7uuiq+6trSmkCiXJX8d7J3jORvi9/jpK40Huj3X13DwxvqZg3jpIFglFKfO6Py1g3LKviTu1awxIaVmGq2kW6lVAHwGuAlHvg/1Vp/TilVDvwEWAK0Ah/SWp93FGLz5s167969WWj2hTMtnZWe9mwM02LHiQCdQyG2H+/j9VMBlFKYlubm5RU8uL521pq21pqmvnFePtZLx1CIikIPd6+p5iNbFnNN/dkQH56I0hIIsqd1kKPdo0QNC2ei5BAvPYCpYduxXoJRk/vXLUzV1F0OBQoMU3O4c4Qf7zlDfZmfv310HWtrS/irZw7x0tFe7llTw11XTX7hhKImX97RhEMp/u79V/Pg1bVAvDf2jZ0tfPGlkxS443PxKwq97GwK8FJic7F719bwxK3LqS/38bN9HXzvzTY6hkIsrSzko1sauW1VFe2DITqHQwTGIrQnXoDdI2FcDoXf66LQ48TvceH3OPF7nEQMi5FQbNK/0VAMDVQVebllZSUPra/lusVl563ZQzwUr/+7l7mqtpgffnJL1muX5xM1LA52DNPUN86e04M8804nS6sKeeDqWvweJ0VeJ8UFLgrcLrwuB7ubB/j5/g6GJmJsaizjvRtquXFZBQsXFNAzGqZnJExLYJwD7cMcaB+mfSiEUynWLVrAbSsruXdtDStrivG6nDy5u5UvbWsiHDP5dzctYemURUXjEYOn97bT1DfOuroFbGwopTkwTlPveGp71VKfm4moSYHbwX+4fRmPb12a1lGIe6tlgD/9yQGGJqL88R0rqCjyEoqafPWVUximxf98/3oe3lCXevyXtzfxv188yf3rFnLbqioKvU4WLiigayQ0aVHPTAq9TioKvQwEI5zsGaN9KJTYhygUv0gHms2Ly3ni9mXctrJq1hLL2v/xPBvqS/n/P7A+o4VXlqUvamGeUmqf1nrzOcczCHAFFGqtx5VSbuB14FPAB4BBrfXfK6U+A5RprT99vu91OQT4fIqZFtuP9zEwHqVvNMwLR3tpKPNx+6qqOQ1IJnuoLx/rpXskTHWxlw9uqmdoIsrx7jHaBydSL57zqSzy8uHrG1heXcii0vjbyZpiLzFT886ZIVoHJlIhvqjUx62rqvjhW2fY2FDKY5vqp21za3+Qb+xsYWNjKT/4xI34PS7+ZccpvvjSSUr9Hj519wreu6GOAreTI12j7Dk9wLMHujjeM0ZtSQH1ZX72tg5S6HXxvg11/OHWxaysKU4911g4RlPfOKcDQSIzbErmcipKfG6cSmFYFoalMUxNzLSIGCaHOkbZ2RSgayRMkdfF1uUVPLKxjpuWV84Y5F975RRfeP4En3//1fzBjYsz/lll08B4hD2tg2w71sdP93WQ/kp1OhR+jxOvy0n/eITKIi/vv7aO+9YtZP2iknNKVKal6RsL0z0SZl/rEDtO9LH/zBDhmEVVsZctS8tZVlXEN3a2xK+AtXUJdTOssrW0Ztepfl440oOl4+96llUWsbKmiJXVxVQWeegeCfO9N9uYiBp89KbF/Pm9q1PvdkdDUT76rbc52DHC41uXsLZ2AevrSzjRM8apvnH+z6vNLK0s5Dsfu4FFZT5GQzHu/6fXmIiZ/Nk9q1jgc3HPmppUD71/PELXcIiOoVBqrYLTAdXFBdSWFlBb4ptUMtJaMx4xGJ6I/5Fv7Q/yw7fP8FbLIA4H3LG6mj+5awXrF5VM+zsfjplc9d+f5761Nfzz7117QQPbc3XBAT7lm/iJB/h/BL4L3KG17lZK1QKvaK1Xn+/rr7QAh3hvavvxXgazcA1ES2uOdI3y8tHe1FU+SnxuFpX6WFLpZ3VNMWvqFlDocRIzNYZpETM1ZiLQllQW0ljhnzG0ekfD7Gkd5I3mAX709hksHZ/L+vFblp537+uXj/Wy/Xgf//U9qzEsiy+93MTCkgL+x0NruXttzaSvnYgaHOoY4bl3u3ju3S7GwwZbllXwyVuXsnXF9LVxiAdQ++AEpweCeJ0OFvjOzu6Z2rubamA8womeMXac6OOVEwGa+sbxOB1cv6SMP9iymDtWV03qYWutufMfXiEcs9jxX27HN4+976niuyCO89KxHnqGI0xEDSaiZuJf/OP6Mh8f3LSIG5dWZDzQ2jca5kjXCL8+1MNbLQO0J6aJlvrd/Publ1JZ5KXU72ZZVSFLKgrRGgYn4vu3DAajDE1EOd0fZDxssLyqkIoiLwt87lT5KhQ1efVkH9/e1UrHUIj3bqjlCx+4Br/Xxad/dpCf7GnnvrU1PHRNLbetrKKs0EMwYrDjRB8vH+3j2QOdPLS+lq/8/rX887Ym/vHlJj60uZ6bllect7YejBiMhQ0qizxzGsgeC8d4+Vgv397VysGOEQo9Th7eUMv/e+/qc8okZwYmuO1/7eCjWxbzt49enfFzXIyLCnCllBPYB6wAvqq1/rRSalhrXZr2mCGt9Tnb0ymlngCeAGhsbNzU1mbfleUvVxHDZNuxvoyuwuJQ8cEtn8eJz+2kwO3E6Tg708KpFJbWtA1MsLTST2NFIcVeV9b2TbEszbGeUZ7e08FbrYO8/9pFswakmSiZdI+EMEzN0spCvvihDWw8z26FY+EYe04P0T0S4v6rF87LFMNwzKQ5MB6fqnekl3c7hnEoxU3LK/jErUu5eXklLqeD/W1DfOBru/mj25fxmQfW2N6uTIRjJqOhGBHDImJYRA2LqBm/rS0puOANtsIxk9P9QXYc72Nf2xA3r6hkQ0MJyyqLZh0vSK4bmOmPbihqsutUP/+8vYmDHSPcsLScRzbU8dlnD7O2bgF/ds9Kblk5eQpwxDB59USAf3mlmXfbh/nr963jH18+SaHHxZ/du5J71y68qK18ZzMSivGLA518e1crp/uD1Czw8pcPrOGRjXWp3vje1kF+5/+8wWcfXsMnbllmW1vSZasHXgo8A/wJ8HomAZ7uSuyBJ4Vj8RAfCcVQKr6cuiTRiyzxuSkucCcC25G1+d4XIxgxON4zhtYalZiqpyDVtvGwwWg4xlg4llqp99Udp1hRXcS/fnTTjG+/LwdaazqGQrx2MsDP9nfwzplhXE7FLSsr+c93ruCbO0+z/Xgfb3zmLspzcO76hRoKRinxubO+iVpr/zj/8zfHefFofPyjutjLF393A1uXVU77XIYZ35zqvz17mMBYBA38x9uX80e3L7+g2UQXYigY4btvtPGt108zHjF4z7qF/O2jV1NZ5OU3h7r5Tz/Yz5Mfu57bzzOgmk1ZCfDEN/ocEAQ+iZRQ5iQcMwlFTRb43PMykDoftNYEo/He4WAwwsrqYrzzUBPMlsFglB3He/n+m2c40D6M2+nA1Jr3rKvhX/5g06VuXt4Ix0y+sv0UvzrYxd88so7bVp0/+LTWPHugk0//9BAra4r4wSduzMo8/Lk60TPKf3/2MG+3DrFwQQGffWgN/eMR/vqXR3nrL++iJoM1KNlwMYOYVUBMaz2slPIBLwJfAG4HBtIGMcu11n9xvu91pQe4uHwFIwbbjvfyb6+3crxnlGf+01bW1JZc6mblnXDMnNOg3+tN/SyvLsxosZ5dYqbFt3ed5svbTxGMGNQsKKBvNELT5x+Yty2fLybArwGeBJzE9055Smv9N0qpCuApoBE4AzymtT7vbjcS4OJyFzMtxsLGrNMMxZXnVN8Yf/XMYd4+PUhlkYe9n7133p57pgCfdXhda30QuHaa4wPA3dlpnhCXB7fTIeEtprWiupgffXIL33+z7bL5HbmiVmIKIcTFcDoUj29dcqmbkZLT28kKIcSVTAJcCCFylAS4EELkKAlwIYTIURLgQgiRoyTAhRAiR0mACyFEjpIAF0KIHCUBLoQQOWrOuxFe1JMpFQAudEPwSqA/i83JFXLeV54r9dzlvGe2WGtdNfXgvAb4xVBK7Z1uM5d8J+d95blSz13Oe+6khCKEEDlKAlwIIXJULgX41y91Ay4ROe8rz5V67nLec5QzNXAhhBCT5VIPXAghRBoJcCGEyFE5EeBKqfuVUieUUqcSF1DOS0qpf1NK9SmlDqcdK1dKvaSUakrcll3KNtpBKdWglNqhlDqmlDqilPpU4nhen7tSqkAp9bZS6t3Eef9/ieN5fd5JSimnUuodpdSvEvfz/ryVUq1KqUNKqQNKqb2JYxd83pd9gCulnMBXgQeAtcDvKaXWXtpW2eY7wP1Tjn0G2Ka1XglsS9zPNwbw51rrNcAW4I8TP+N8P/cIcJfWegOwEbhfKbWF/D/vpE8Bx9LuXynnfafWemPa3O8LPu/LPsCBG4BTWusWrXUU+DHwyCVuky201q8Bg1MOPwI8mfj4SeDReW3UPNBad2ut9yc+HiP+ol5Enp+7jhtP3HUn/mny/LwBlFL1wEPAN9MO5/15z+CCzzsXAnwR0J52vyNx7EpRo7XuhnjQAdWXuD22UkotAa4F3uIKOPdEGeEA0Ae8pLW+Is4b+CfgLwAr7diVcN4aeFEptU8p9UTi2AWfdy5clV5Nc0zmPuYhpVQR8DPgT7XWo0pN96PPL1prE9iolCoFnlFKXX2p22Q3pdTDQJ/Wep9S6o5L3Z55drPWukspVQ28pJQ6fjHfLBd64B1AQ9r9eqDrErXlUuhVStUCJG77LnF7bKGUchMP7x9orX+eOHxFnDuA1noYeIX4GEi+n/fNwPuUUq3ES6J3KaW+T/6fN1rrrsRtH/AM8RLxBZ93LgT4HmClUmqpUsoDfBh47hK3aT49Bzye+Phx4BeXsC22UPGu9reAY1rrL6Z9Kq/PXSlVleh5o5TyAfcAx8nz89Za/6XWul5rvYT463m71voj5Pl5K6UKlVLFyY+B+4DDXMR558RKTKXUg8RrZk7g37TWn7/ETbKFUupHwB3Et5fsBT4HPAs8BTQCZ4DHtNZTBzpzmlLqFmAncIizNdG/Il4Hz9tzV0pdQ3zQykm8M/WU1vpvlFIV5PF5p0uUUP6L1vrhfD9vpdQy4r1uiJevf6i1/vzFnHdOBLgQQohz5UIJRQghxDQkwIUQIkdJgAshRI6SABdCiBwlAS6EEDlKAlwIIXKUBLgQQuSo/wuyknWyEHiZbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] \n",
    "# + resultsc[0] \n",
    "#  + resultsd[0] + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1]\n",
    "# + resultsc[1] \n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = .5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1\n",
    "resultsa = train(results_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_1 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.5\n",
    "resultsa = train(results_1, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_15 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2\n",
    "resultsa = train(results_15, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_2 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=2.5\n",
    "resultsa = train(results_2, 1000, 800, 100, 10, find_step_size(results_2,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_25 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -.5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1\n",
    "resultsa = train(results_neg_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# load the g=2.5 results from the checkpoint file \n",
    "params = load_params(\"5+5/large_g_150_params_g_2.5.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "params = load_params(\"5+5/large_g_150_params_g_3.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_35 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_4 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_45 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_55 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_6 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_65 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_7 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_75 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_8 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_85 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_9 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "g = 10\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# params = load_params(\"5+5/large_g_150_params_g_9.5.pkl\")\n",
    "params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "\n",
    "resultsa = train(params, 10, 30000, 1000, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 15,50000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = acc_train(resultsb[3], 10, 300000,1000,10, find_step_size(resultsb[3],step_size), g)\n",
    "resultsd = acc_train(resultsc[3], 10, 1000000, 10000,10, find_step_size(resultsc[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "g = 10\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10.5_extrapolated.pkl\")\n",
    "g = 10.5\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_11_extrapolated.pkl\")\n",
    "g = 11\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_11 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
