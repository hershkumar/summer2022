{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 3\n",
    "N_down = 3\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"3+3/large_g_150_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.150851788756388\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143106\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:02<00:00, 1978.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5400901783963928\n"
     ]
    }
   ],
   "source": [
    "step_size = .4\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 22.32392974218153: 100%|██████████| 100/100 [54:27<00:00, 32.67s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=10\n",
    "# first find the step size\n",
    "step_size = .4\n",
    "resultsa = train(params, 40, 2000, 1000, 10, step_size, g)\n",
    "resultsb = train(resultsa[3], 100,5000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 21.046131709791016: 100%|██████████| 50/50 [52:35<00:00, 63.11s/it] \n"
     ]
    }
   ],
   "source": [
    "resultsc = train(resultsb[3], 50,10000,1000,10, find_step_size(resultsb[3],step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "resultsd = train(resultsc[3], 15,30000,1000,10, find_step_size(resultsc[3],step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0]+ resultsc[0] + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1]  + resultsc[1] + resultsd[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = .5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1\n",
    "resultsa = train(results_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_1 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.5\n",
    "resultsa = train(results_1, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_15 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2\n",
    "resultsa = train(results_15, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_2 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=2.5\n",
    "resultsa = train(results_2, 1000, 800, 100, 10, find_step_size(results_2,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_25 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -.5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1\n",
    "resultsa = train(results_neg_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# load the g=2.5 results from the checkpoint file \n",
    "params = load_params(\"5+5/large_g_150_params_g_2.5.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "params = load_params(\"5+5/large_g_150_params_g_3.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_35 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_4 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_45 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_55 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_6 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_65 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_7 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_75 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_8 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_85 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_9 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "g = 10\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# params = load_params(\"5+5/large_g_150_params_g_9.5.pkl\")\n",
    "params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "\n",
    "resultsa = train(params, 10, 30000, 1000, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 15,50000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = acc_train(resultsb[3], 10, 300000,1000,10, find_step_size(resultsb[3],step_size), g)\n",
    "resultsd = acc_train(resultsc[3], 10, 1000000, 10000,10, find_step_size(resultsc[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "g = 10\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10.5_extrapolated.pkl\")\n",
    "g = 10.5\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_11_extrapolated.pkl\")\n",
    "g = 11\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_11 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
