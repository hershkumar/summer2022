{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "# jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 2\n",
    "N_down = 2\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [100,100]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"2+2/\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    rng = np.random.default_rng(int(time.time()))\n",
    "    randoms = rng.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = rng.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved:\n",
    "                counter += 1\n",
    "        \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = jnp.array(sq.copy())\n",
    "    for i in range(len(sq)):\n",
    "        a = jnp.array(sq[i])\n",
    "        a = a.at[N_up].set(a[0])\n",
    "        sq_prime = sq_prime.at[i].set(jnp.array(a))\n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "    subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "    randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "    randoms = jnp.transpose(randoms)\n",
    "    subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "    limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev = val\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev\n",
    "    \n",
    "    sq, _ = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev))\n",
    "\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "#     sq_prime = jnp.array(sq.copy())\n",
    "#     for i in range(len(sq)):\n",
    "#         a = jnp.array(sq[i])\n",
    "#         a = a.at[N_up].set(a[0])\n",
    "#         sq_prime = sq_prime.at[i].set(jnp.array(a))\n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[N_up].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        print(gr[0])\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "@jit\n",
    "def batch_gradient(samples, samples_prime, params):\n",
    "    num_samples = len(samples)\n",
    "    ys = jnp.array(samples_prime[:, N_up])\n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "    \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def batch_step(params_arg, step_num, N, N_batches, thermal, skip, variation_size, g, start_key):\n",
    "    # compute the gradient for each batch\n",
    "    samples_per_batch = N//N_batches\n",
    "    grads = []\n",
    "    energies = []\n",
    "    uncerts = []\n",
    "    \n",
    "    def grad_wrapper(key):\n",
    "        return sample_pmap(params, samples_per_batch, thermal, skip, variation_size, key)\n",
    "\n",
    "    grad_pmap = jax.pmap(grad_wrapper, backend=\"cpu\")\n",
    "\n",
    "\n",
    "    inputs = jax.random.split(start_key, N_batches)\n",
    "    out = jnp.array(grad_pmap(inputs))\n",
    "    \n",
    "    # put all of the samples together\n",
    "    samples = jnp.concatenate(out[0])\n",
    "    samples_prime = jnp.concatenate(out[1])\n",
    "    #TODO: for some reason this is spitting out the same gradient every step\n",
    "    # Maybe the parameters arent updating correctly based on the gradient? \n",
    "    # they seem to be changing a little bit, which is confusing\n",
    "    \n",
    "    gr = batch_gradient(samples, samples_prime, params_arg)\n",
    "    print(gr[0])\n",
    "    opt_state = opt_init(params_arg)\n",
    "    new = opt_update(step_num, gr[0], opt_state)\n",
    "    return get_params(new), gr[1], gr[2]\n",
    "\n",
    "\n",
    "def batch_train(params, iterations, N, N_batches, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = batch_step(old_params, step_num, N, N_batches, thermal, skip, variation_size, g, jax.random.key(int(time.time())))\n",
    "\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(jax.devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.122913117546848\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42804\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 21001/21001 [00:03<00:00, 5638.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46416837293462215\n"
     ]
    }
   ],
   "source": [
    "g=2\n",
    "step_size = .9\n",
    "samples = sample(params, 2000, 1000, 10, step_size, progress=True)\n",
    "print(samples[2])\n",
    "# print(samples[0].shape)\n",
    "# print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute one extraneous gradient \n",
    "# grad_temp = gradient(params, g, 2000, 1000, 10, step_size)\n",
    "\n",
    "samples1 = sample_pmap(params, 10000, 1000, 10, step_size, jax.random.key(int(time.time())))\n",
    "samples2 = sample_pmap(params, 10000, 1000, 10, step_size, jax.random.key(int(time.time())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram the samples x1 coord\n",
    "x_real = samples[0][:,0]\n",
    "x11 = samples1[0][:,0]\n",
    "x12 = samples2[0][:,0]\n",
    "# plt.hist(x_real, bins=20, histtype='step', stacked=True, fill=False)\n",
    "plt.hist(x11, bins=20, histtype='step', stacked=True, fill=False)\n",
    "plt.hist(x12, bins=20,histtype='step', stacked=True, fill=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7579718   1.56682728  0.27471944 -1.37480054]\n",
      " [-0.95284282  2.64915783  0.30705547 -2.041355  ]\n",
      " [-1.84641989  2.43876732  0.42914634 -2.86409013]\n",
      " ...\n",
      " [ 4.09339225 -0.36108814  0.45942672 -1.10459304]\n",
      " [ 2.54811906 -1.64647215 -0.84033438 -2.01832208]\n",
      " [ 2.89533424 -2.08331772 -0.14321926 -2.2994223 ]]\n",
      "[[ 2.12139611  0.24459603 -0.97462703  1.06986163]\n",
      " [ 1.96328786  0.56285986 -1.79799116  0.4891136 ]\n",
      " [ 2.70357557  0.65717599 -0.57942841  0.30290673]\n",
      " ...\n",
      " [ 2.37667753 -0.32556834  0.49776251 -1.44168353]\n",
      " [ 1.42267441 -0.82921626  1.36207499 -0.69619077]\n",
      " [ 2.26557827 -0.91606151  1.10387289 -0.53062939]]\n"
     ]
    }
   ],
   "source": [
    "print(samples1[0])\n",
    "print(samples2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# samples_reg = sample(params, 50000, 1000, 10, step_size, progress=False)\n",
    "# print(time.time() - start)\n",
    "# start = time.time()\n",
    "# samples1 = sample_pmap(params, 50000, 1000, 10, step_size, jax.random.key(int(time.time())))\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 4.408053269303348: 100%|██████████| 5/5 [00:40<00:00,  8.05s/it] \n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "# first find the step size\n",
    "step_size = .9\n",
    "# resultsa = batch_train(params, 20, 96000,2, 1000, 10, step_size, g)\n",
    "resultsa = batch_train(params, 5, 160000, 16, 1000, 10, step_size, g)\n",
    "resultsa = train(params, 5, 1600, 1000, 10, step_size, g)\n",
    "# resultsb = train(resultsa[3], 40,5000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = 5\n",
    "resultsc = train(resultsb[3], 10, 20000, 1000, 10, find_step_size(resultsb[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultsd = train(resultsc[3], 30, 70000, 1000, 10, find_step_size(resultsc[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g=10\n",
    "resultse = train(resultsd[3], 50, 70000, 1000, 10, find_step_size(resultsd[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# resultsf = train(resultse[3], 20, 20000, 1000, 10, find_step_size(resultse[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_params = [resultsa[3], resultsb[3], resultsc[3], resultsd[3]] #resultse[3]\n",
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0]  + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1]  + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save the results to a file\n",
    "with open('2+2_params.pkl', 'wb') as handle:\n",
    "    pickle.dump(list_of_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('2+2_hist.pkl', 'wb') as handle:\n",
    "    pickle.dump(total_hists, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('2+2_uncerts.pkl', 'wb') as handle:\n",
    "    pickle.dump(total_uncerts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
