{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "# jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 2\n",
    "N_down = 2\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [100,100]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"2+2/\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    rng = np.random.default_rng(int(time.time()))\n",
    "    randoms = rng.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = rng.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved:\n",
    "                counter += 1\n",
    "        \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = jnp.array(sq.copy())\n",
    "    for i in range(len(sq)):\n",
    "        a = jnp.array(sq[i])\n",
    "        a = a.at[N_up].set(a[0])\n",
    "        sq_prime = sq_prime.at[i].set(jnp.array(a))\n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "    subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "    randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "    randoms = jnp.transpose(randoms)\n",
    "    subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "    limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev = val\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev\n",
    "    \n",
    "    sq, _ = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev))\n",
    "\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "#     sq_prime = jnp.array(sq.copy())\n",
    "#     for i in range(len(sq)):\n",
    "#         a = jnp.array(sq[i])\n",
    "#         a = a.at[N_up].set(a[0])\n",
    "#         sq_prime = sq_prime.at[i].set(jnp.array(a))\n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[N_up].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "#     params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        print(gr[0])\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "@jit\n",
    "def batch_gradient(samples, samples_prime, params):\n",
    "    num_samples = len(samples)\n",
    "    ys = jnp.array(samples_prime[:, N_up])\n",
    "    alpha = jnp.sqrt(jnp.max(abs(jnp.array(ys)))**2/(-jnp.log(jnp.sqrt(jnp.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "    \n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0)\n",
    "    \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def batch_step(params_arg, step_num, N, N_batches, thermal, skip, variation_size, g, start_key):\n",
    "    # compute the gradient for each batch\n",
    "    samples_per_batch = N//N_batches\n",
    "    grads = []\n",
    "    energies = []\n",
    "    uncerts = []\n",
    "    \n",
    "    def grad_wrapper(key):\n",
    "        return sample_pmap(params_arg, samples_per_batch, thermal, skip, variation_size, key)\n",
    "\n",
    "    grad_pmap = jax.pmap(grad_wrapper, backend=\"cpu\")\n",
    "\n",
    "\n",
    "    inputs = jax.random.split(start_key, N_batches)\n",
    "    out = jnp.array(grad_pmap(inputs))\n",
    "    \n",
    "    # put all of the samples together\n",
    "    samples = jnp.concatenate(out[0])\n",
    "    samples_prime = jnp.concatenate(out[1])\n",
    "    # something is wrong here\n",
    "    gr = batch_gradient(samples, samples_prime, params_arg)\n",
    "    opt_state = opt_init(params_arg)\n",
    "    new = opt_update(step_num, gr[0], opt_state)\n",
    "    return get_params(new), gr[1], gr[2]\n",
    "\n",
    "\n",
    "def batch_train(params, iterations, N, N_batches, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = batch_step(old_params, step_num, N, N_batches, thermal, skip, variation_size, g, jax.random.key(int(time.time())))\n",
    "\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(jax.devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.122913117546848\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42804\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 51001/51001 [00:07<00:00, 6430.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4384619909413541\n"
     ]
    }
   ],
   "source": [
    "g=2\n",
    "step_size = .9\n",
    "samples = sample(params, 5000, 1000, 10, step_size, progress=True)\n",
    "print(samples[2])\n",
    "# print(samples[0].shape)\n",
    "# print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute one extraneous gradient \n",
    "# grad_temp = gradient(params, g, 2000, 1000, 10, step_size)\n",
    "\n",
    "samples1 = sample_pmap(params, 10000, 1000, 10, step_size, jax.random.key(int(time.time())))\n",
    "samples2 = sample_pmap(params, 10000, 1000, 10, step_size, jax.random.key(int(time.time())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram the samples x1 coord\n",
    "x_real = samples[0][:,0]\n",
    "x11 = samples1[0][:,0]\n",
    "x12 = samples2[0][:,0]\n",
    "# plt.hist(x_real, bins=20, histtype='step', stacked=True, fill=False)\n",
    "plt.hist(x11, bins=40, histtype='step', stacked=True, fill=False)\n",
    "plt.hist(x12, bins=40,histtype='step', stacked=True, fill=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the gradient for both samples and samples1\n",
    "# gr1 = gradient(params, g, 5000, 1000, 10, step_size)\n",
    "# gr2 = batch_gradient(samples1[0], samples1[1], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 4.096141581252261: 100%|██████████| 10/10 [04:26<00:00, 26.67s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "# first find the step size\n",
    "step_size = .9\n",
    "# resultsa = batch_train(params, 20, 96000,2, 1000, 10, step_size, g)\n",
    "resultsa = batch_train(params, 10, 160000, 16, 1000, 10, step_size, g)\n",
    "# resultsa = batch_train(resultsa[3], 50, 480000, 48, 1000, 10, step_size, g)\n",
    "# resultsa = train(params, 10, 1600, 1000, 10, step_size, g)\n",
    "# resultsb = train(resultsa[3], 40,5000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = 5\n",
    "resultsc = train(resultsb[3], 10, 20000, 1000, 10, find_step_size(resultsb[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultsd = train(resultsc[3], 30, 70000, 1000, 10, find_step_size(resultsc[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g=10\n",
    "resultse = train(resultsd[3], 50, 70000, 1000, 10, find_step_size(resultsd[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# resultsf = train(resultse[3], 20, 20000, 1000, 10, find_step_size(resultse[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list_of_params = [resultsa[3], resultsb[3], resultsc[3], resultsd[3]] #resultse[3]\n",
    "total_hists =  resultsa[0]  \n",
    "# + resultsb[0] \n",
    "# + resultsc[0]  + resultsd[0]  + resultse[0]\n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]\n",
    "# + resultsb[1]  \n",
    "# + resultsc[1]  + resultsd[1] + resultse[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save the results to a file\n",
    "with open('2+2_params.pkl', 'wb') as handle:\n",
    "    pickle.dump(list_of_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('2+2_hist.pkl', 'wb') as handle:\n",
    "    pickle.dump(total_hists, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('2+2_uncerts.pkl', 'wb') as handle:\n",
    "    pickle.dump(total_uncerts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
