{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 2\n",
    "N_down = 2\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 3\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [100,100]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"2+2/\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.122913117546848\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42804\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:00<00:00, 6070.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5079396196824152\n"
     ]
    }
   ],
   "source": [
    "step_size = .9\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 4.013342224944543: 100%|██████████| 40/40 [07:10<00:00, 10.76s/it] \n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "g=0\n",
    "# first find the step size\n",
    "step_size = .9\n",
    "resultsa = train(params, 20, 1600, 1000, 10, step_size, g)\n",
    "resultsb = train(resultsa[3], 40,5000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "# resultsc = train(resultsb[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "# resultsd = train(resultsc[3], 20,40000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "# save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "# results_0 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 8.42878950546071: 100%|██████████| 10/10 [07:10<00:00, 43.06s/it]\n"
     ]
    }
   ],
   "source": [
    "g = 5\n",
    "resultsc = train(resultsb[3], 10, 20000, 1000, 10, find_step_size(resultsb[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 8.101344926105256: 100%|██████████| 30/30 [50:07<00:00, 100.27s/it]\n"
     ]
    }
   ],
   "source": [
    "resultsd = train(resultsc[3], 30, 70000, 1000, 10, find_step_size(resultsc[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=10\n",
    "resultse = train(resultsd[3], 30, 30000, 1000, 10, find_step_size(resultsd[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultsf = train(resultse[3], 20, 20000, 1000, 10, find_step_size(resultse[3], step_size), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hists =  resultsa[0]  + resultsb[0] + resultsc[0]  + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1]  + resultsc[1]  + resultsd[1]\n",
    "# + resultse[1]\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists)# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = .5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1\n",
    "resultsa = train(results_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_1 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.5\n",
    "resultsa = train(results_1, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_15 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2\n",
    "resultsa = train(results_15, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_2 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=2.5\n",
    "resultsa = train(results_2, 1000, 800, 100, 10, find_step_size(results_2,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_25 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -.5\n",
    "resultsa = train(results_0, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1\n",
    "resultsa = train(results_neg_05, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 250,1600,100,7, find_step_size(params,step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(params,step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_neg_05 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# load the g=2.5 results from the checkpoint file \n",
    "params = load_params(\"5+5/large_g_150_params_g_2.5.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 3.5\n",
    "\n",
    "params = load_params(\"5+5/large_g_150_params_g_3.pkl\")\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_35 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_4 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 4.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_45 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 5.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_55 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 20, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_6 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 6.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_65 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_7 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 7.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_75 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_8 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 8.5\n",
    "\n",
    "resultsa = train(resultsc[3], 1000, 800, 100, 10, find_step_size(resultsc[3],step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_85 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9\n",
    "\n",
    "resultsa = train(params, 1000, 800, 100, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 500,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_9 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "g = 10\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "\n",
    "# params = load_params(\"5+5/large_g_150_params_g_9.5.pkl\")\n",
    "params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "\n",
    "resultsa = train(params, 10, 30000, 1000, 10, find_step_size(params,step_size), g)\n",
    "resultsb = train(resultsa[3], 15,50000,1000,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = acc_train(resultsb[3], 10, 300000,1000,10, find_step_size(resultsb[3],step_size), g)\n",
    "resultsd = acc_train(resultsc[3], 10, 1000000, 10000,10, find_step_size(resultsc[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsd[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsd[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10_extrapolated.pkl\")\n",
    "g = 10\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_10.5_extrapolated.pkl\")\n",
    "g = 10.5\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_10_5 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extrapolated parameters\n",
    "extrapolated_params = load_params(\"5+5/5+5_g_11_extrapolated.pkl\")\n",
    "g = 11\n",
    "\n",
    "resultsa = train(extrapolated_params, 500, 800, 100, 5, find_step_size(extrapolated_params,step_size), g)\n",
    "resultsb = train(resultsa[3], 100,1600,100,10, find_step_size(resultsa[3],step_size), g)\n",
    "resultsc = train(resultsb[3], 40, 50000,100,10, find_step_size(resultsb[3],step_size), g)\n",
    "\n",
    "# save the parameters to a file\n",
    "save_params(resultsc[3], PARAM_PREFIX + str(g) + \".pkl\")\n",
    "\n",
    "results_11 = resultsc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
