{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#must set these before loading numpy:\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '8'\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = '8'\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "#os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".1\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#wavefunction preparation \n",
    "def init_params_SAMPLE(layer_widths):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for n_in, n_out in zip(layer_widths[:-1], layer_widths[1:]):\n",
    "        weights.append(jnp.array(np.random.normal(size=(n_in, n_out)) * np.sqrt(2/n_in)))\n",
    "        biases.append(jnp.array(np.random.normal(size=(n_out,))))\n",
    "        \n",
    "    return [weights, biases]\n",
    "\n",
    "#initializes a set of NN parameters\n",
    "def init_params(layer_widths):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for n_in, n_out in zip(layer_widths[:-1], layer_widths[1:]):\n",
    "        weights.append(jnp.array(np.random.normal(size=(n_in, n_out)) * np.sqrt(2/n_in)))\n",
    "        biases.append(jnp.array(np.random.normal(size=(n_out,))))\n",
    "        \n",
    "    return flatten_params([weights, biases])\n",
    "\n",
    "def get_phi_params(layer_widths):\n",
    "    tot_params = []\n",
    "    for i in range(N_UP + N_DOWN):\n",
    "        tot_params.append(init_params(layer_widths))\n",
    "    \n",
    "    return jnp.array(tot_params)\n",
    "\n",
    "@jit\n",
    "def flatten_params(ps):\n",
    "    weights, biases = ps\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(SAMPLE_W)):\n",
    "        end = start + SAMPLE_W[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), SAMPLE_W[i].shape))\n",
    "        start = end\n",
    "        end = start + SAMPLE_B[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), SAMPLE_B[i].shape))\n",
    "        start = end\n",
    "    return [weights, biases]\n",
    "\n",
    "@jit\n",
    "def NN(positions, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = jnp.array(positions)\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = jax.nn.celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0]\n",
    "\n",
    "@partial(jit, static_argnums=(1, ))\n",
    "def inputs_up(positions, j):\n",
    "    \n",
    "    reordered = jnp.concatenate([jnp.array([positions[j]]), jnp.array(positions[:j]), jnp.array(positions[j+1:])])\n",
    "    \n",
    "    \n",
    "    sym_piece1 = reordered[1:N_UP]\n",
    "    sym_piece2 = reordered[N_UP:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_UP):\n",
    "        new1.append(jnp.sum((jnp.array(sym_piece1)/SYMNUM)**i))\n",
    "    for i in range(1, N_DOWN+1):\n",
    "        new2.append(jnp.sum((jnp.array(sym_piece2)/SYMNUM)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1, ))\n",
    "def inputs_down(positions, j):\n",
    "    reordered = jnp.concatenate([jnp.array([positions[j+N_UP]]), jnp.array(positions[:j+N_UP]), \n",
    "                                 jnp.array(positions[j+N_UP+1:])])\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_UP+1]\n",
    "    sym_piece2 = reordered[N_UP+1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_UP+1):\n",
    "        new1.append(jnp.sum((jnp.array(sym_piece1)/SYMNUM)**i))\n",
    "    for i in range(1, N_DOWN):\n",
    "        new2.append(jnp.sum((jnp.array(sym_piece2)/SYMNUM)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "    \n",
    "\n",
    "@jit\n",
    "def PHI_up(positions, params):\n",
    "    \n",
    "    #params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    mat = jnp.zeros((N_UP, N_UP))\n",
    "    for i in range(N_UP):\n",
    "        for j in range(N_UP):\n",
    "            mat = mat.at[i, j].set(NN(inputs_up(positions, j), params[i]))\n",
    "    \n",
    "    return jnp.linalg.det(mat)/jnp.sqrt(NUMFACTUP)\n",
    "\n",
    "@jit\n",
    "def PHI_down(positions, params):\n",
    "    \n",
    "    #params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    mat = jnp.zeros((N_DOWN, N_DOWN))\n",
    "    for i in range(N_DOWN):\n",
    "        for j in range(N_DOWN):\n",
    "            mat = mat.at[i, j].set(NN(inputs_down(positions, j), params[i+N_UP]))\n",
    "    \n",
    "    return jnp.linalg.det(mat)/jnp.sqrt(NUMFACTDOWN)\n",
    "\n",
    "@jit\n",
    "def Psi(positions, params):\n",
    "    \n",
    "    #params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    return PHI_up(positions, params)*PHI_down(positions, params)*jnp.e**(-omeg*jnp.sum(jnp.array(positions)**2.))\n",
    "\n",
    "\n",
    "#sampling \n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = Psi(newpositions, params)**2./Psi(positions, params)**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def get_sequence(stepsize, Nsweeps, keep, Ntherm, positions_initial, params, progress):\n",
    "    sq = []\n",
    "    counter = 0\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (Nsweeps, N_UP+N_DOWN))\n",
    "    limits = np.random.uniform(0, 1, size = Nsweeps)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress == True:\n",
    "        for i in tqdm(range(0, Nsweeps), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(Nsweeps):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "\n",
    "    return [sq, counter/Nsweeps]\n",
    "\n",
    "#gradients and energies\n",
    "@jit\n",
    "def potential_minus_delta(positions):\n",
    "    \n",
    "    harmonic_piece = 0.5*MASS*(OMEGA**2)*(jnp.sum(jnp.array(positions)**2.))\n",
    "    \n",
    "    return harmonic_piece \n",
    "\n",
    "\n",
    "@jit\n",
    "def dpsi_dtheta(positions, params):\n",
    "    \n",
    "    #params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    deriv = jax.grad(Psi, argnums = 1)\n",
    "    \n",
    "    return deriv(jnp.array(positions), params)\n",
    "\n",
    "\n",
    "@jit\n",
    "def dpsi2_dx2(positions, params):\n",
    "    \n",
    "    #params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    deriv = jax.grad(Psi, argnums = 0)\n",
    "    hess = jax.jacfwd(deriv, argnums = 0)\n",
    "    \n",
    "    dA = deriv(jnp.array(positions), params)\n",
    "    Hessian = hess(jnp.array(positions), params)\n",
    "    \n",
    "    return jnp.diag(Hessian)\n",
    "\n",
    "\n",
    "@jit\n",
    "@partial(jax.vmap, in_axes=(0, None))\n",
    "def Esv(pos, params):\n",
    "    return (-1/(2*MASS))*(1/Psi(pos, params))*jnp.sum(dpsi2_dx2(pos, params)) + potential_minus_delta(pos)\n",
    "\n",
    "\n",
    "@jit\n",
    "@partial(jax.vmap, in_axes=(0, 0, None, None))\n",
    "def gradv(pos, ens, params, E):\n",
    "    return (2.0/Psi(pos, params))*dpsi_dtheta(pos, params)*(ens - E)\n",
    "\n",
    "\n",
    "#mc observables vectorized\n",
    "def get_expectsv_progress(sequence, params):\n",
    "    \n",
    "    Numseqs = len(sequence)\n",
    "\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "  \n",
    "    for i in tqdm(range(0, 1), position = 0, leave = True, desc = \"energy calc\"): \n",
    "        ens = Esv(sequence, params)\n",
    "        E = jnp.mean(ens)\n",
    "        err = jnp.std(ens)/jnp.sqrt(Numseqs)\n",
    "    \n",
    "    for i in tqdm(range(0, 1), position = 0, leave = True, desc = \"grad calc\"):\n",
    "        grads = gradv(sequence, ens, params, E)\n",
    "        \n",
    "    for i in tqdm(range(1), position = 0, leave = True, desc=\"means\"):\n",
    "        res = [E, jnp.sum(grads, axis=0)/Numseqs, err]\n",
    "    \n",
    "    return res\n",
    "\n",
    "@jit\n",
    "def get_expectsv_noprogress(sequence, params):\n",
    "    \n",
    "    Numseqs = len(sequence)\n",
    "\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    ens = Esv(sequence, params)\n",
    "    E = jnp.mean(ens)\n",
    "    err = jnp.std(ens)/jnp.sqrt(Numseqs)\n",
    "    \n",
    "    grads = gradv(sequence, ens, params, E)\n",
    "    \n",
    "    return [E, jnp.sum(grads, axis=0)/Numseqs, err]\n",
    "\n",
    "#computes gradients and energies\n",
    "def dEdt(stepsize, Nsweeps, keep, Ntherm, params, progress):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    sequence, rate = get_sequence(stepsize, Nsweeps, keep, Ntherm, \n",
    "                                  jnp.array(np.random.uniform(-1, 1, N_UP+N_DOWN)), params, progress)\n",
    "\n",
    "    if progress == True:\n",
    "        dEdtheta, E, err = get_expectsv_progress(jnp.array(sequence), params)\n",
    "        print(\"Accept rate: \", rate)\n",
    "        print(\"Energy: \", E)\n",
    "        print(\"Error: \", err)\n",
    "        \n",
    "    elif progress == False:\n",
    "        dEdtheta, E, err = get_expectsv_noprogress(jnp.array(sequence), params)\n",
    "\n",
    "    return dEdtheta, E, err\n",
    "    \n",
    "\n",
    "#performs a training step\n",
    "def trainstep(stepsize, Nsweeps, keep, Ntherm, initial_params, step_i):\n",
    "    \n",
    "    grad, energy, err = dEdt(stepsize, Nsweeps, keep, Ntherm, initial_params, False)\n",
    "    \n",
    "    opt_state = opt_init(initial_params)\n",
    "    new = opt_update(step_i, grad, opt_state)\n",
    "    \n",
    "    return get_params(new), energy, err\n",
    "\n",
    "def train(Ntrains, stepsize, Nsweeps, keep, Ntherm, initial_params):\n",
    "    old_params = initial_params\n",
    "    \n",
    "    energies = []\n",
    "    errs = []\n",
    "    ns = np.arange(Ntrains)\n",
    "\n",
    "    for n in tqdm(range(0, Ntrains), position = 0, leave = True, desc = \"Training\"):\n",
    "        new_params, energy, err = trainstep(stepsize, Nsweeps, keep, Ntherm, old_params, n)\n",
    "        energies.append(energy)\n",
    "        errs.append(err)\n",
    "        old_params = new_params\n",
    "\n",
    "        \n",
    "    return [ns, energies, errs, old_params]\n",
    "\n",
    "def binning(arr, binsize):\n",
    "    vals = []\n",
    "    i = 0\n",
    "    while i < len(arr)/binsize:\n",
    "        vals.append(np.mean(arr[i*binsize:(i+1)*binsize]))\n",
    "        i += 1\n",
    "    \n",
    "    return np.mean(vals), np.std(vals)/np.sqrt(len(vals))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMEGA = 1.0\n",
    "MASS = 1.0\n",
    "omeg = 1.0\n",
    "\n",
    "\n",
    "N_UP = 5\n",
    "N_DOWN = 5\n",
    "\n",
    "SYMNUM = 4.0\n",
    "#NUMFACTUP = np.math.factorial(N_UP)\n",
    "#NUMFACTDOWN = np.math.factorial(N_DOWN)\n",
    "NUMFACTUP = 3.0\n",
    "NUMFACTDOWN = 3.0\n",
    "\n",
    "lss = [N_UP+N_DOWN, 25, 50, 50, 25, 1]\n",
    "\n",
    "SAMPLE_W, SAMPLE_B = init_params_SAMPLE(lss)\n",
    "\n",
    "NNvars_init = get_phi_params(lss)\n",
    "\n",
    "len(NNvars_init[0])*(N_UP+N_DOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**-4)\n",
    "\n",
    "resultsa = train(1000, 0.27, 1000, 1, 0, NNvars_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
