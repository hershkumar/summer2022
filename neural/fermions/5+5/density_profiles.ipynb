{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = N_up + N_down fermions in a harmonic trap, with delta function interaction\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import tqdm, trange\n",
    "from math import factorial\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#use pickle to save the parameters to a file \n",
    "def save_params(params, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "# use pickle to dump the energies and uncertainties to a file\n",
    "def save_energies(hs, us, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((hs, us), f)\n",
    "\n",
    "def save_energies(h, u, filename):\n",
    "    with open(filename,'a') as file:\n",
    "        file.write(str(h)+\",\"+str(u))\n",
    "        file.write('\\n')\n",
    "\n",
    "# use pickle to load the parameters from a file\n",
    "def load_params(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# use pickle to load the energies and uncertainties from a file\n",
    "def load_energies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# using this data:\n",
    "# 1, 0.0854344122657581\n",
    "# 2, 0.12291311754684836\n",
    "# 3, 0.15085178875638838\n",
    "# 4, 0.1753833049403748\n",
    "# 5, 0.1965076660988075\n",
    "# 6, 0.21626916524701872\n",
    "# 7, 0.23330494037478702\n",
    "# 8, 0.2503407155025553\n",
    "# 9, 0.2656729131175468\n",
    "\n",
    "def compute_true_energy():\n",
    "    ret = (N_up**2 + N_down**2)/2 \n",
    "    if N_up == 1: \n",
    "        ret += 0.0854344122657581\n",
    "    elif N_up == 2:\n",
    "        ret += 0.12291311754684836\n",
    "    elif N_up == 3:\n",
    "        ret += 0.15085178875638838\n",
    "    elif N_up == 4:\n",
    "        ret += 0.1753833049403748\n",
    "    elif N_up == 5:\n",
    "        ret += 0.1965076660988075\n",
    "    elif N_up == 6:\n",
    "        ret += 0.21626916524701872\n",
    "    elif N_up == 7:\n",
    "        ret += 0.23330494037478702\n",
    "    elif N_up == 8:\n",
    "        ret += 0.2503407155025553\n",
    "    elif N_up == 9:\n",
    "        ret += 0.2656729131175468\n",
    "    return ret\n",
    "\n",
    "\n",
    "##### Constants\n",
    "N_up = 5\n",
    "N_down = 5\n",
    "N = N_up + N_down\n",
    "\n",
    "FACT_UP = 2 #increase this when N goes up\n",
    "FACT_DOWN = 2 # increase this when N goes up\n",
    "SYM_DEN = 5\n",
    "GPU_INDEX = 1\n",
    "# division factor in the ansatz\n",
    "DIV = 2\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "phi_structure = [150,150]\n",
    "\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 0\n",
    "\n",
    "PARAM_PREFIX = \"5+5/large_g_150_params_g_\"\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# this just gets the shapes of the weights and biases for a neural network with the given structure\n",
    "def gen_weight_shapes(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "        w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "        b = np.random.randn(1, sizes[i+1]) \n",
    "        weights.append(w)\n",
    "        biases.append(b) \n",
    "    return weights, biases\n",
    "\n",
    "# get the shapes\n",
    "weight_shapes, bias_shapes = gen_weight_shapes(N, phi_structure, 1)\n",
    "\n",
    "# generates a set of weights and biases for a neural network with the given structure\n",
    "# returns a flattened array of the parameters\n",
    "\n",
    "def gen_params(input_size, hidden_sizes, output_size):\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    if hidden_sizes != [0]:\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    else:\n",
    "        sizes = [input_size, output_size]\n",
    "    for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "    return flatten_params(weights, biases) \n",
    "\n",
    "# calls the neural network with the given parameters and input\n",
    "@jit\n",
    "def nn(x, params):\n",
    "    weights, biases = unflatten_params(params) \n",
    "    a = x\n",
    "    for i in range(len(weights) - 1):\n",
    "        z = jnp.dot(a, weights[i]) + biases[i]\n",
    "        a = celu(z)\n",
    "    a = jnp.dot(a, weights[-1]) + biases[-1]\n",
    "    return a[0][0] \n",
    "\n",
    "# takes the weights and biases of a network and returns a flattened array of the parameters\n",
    "@jit\n",
    "def flatten_params(weights, biases):\n",
    "    params = jnp.array([])\n",
    "    for i in range(len(weights)):\n",
    "        params = jnp.concatenate((params, weights[i].flatten()))\n",
    "        params = jnp.concatenate((params, biases[i].flatten()))\n",
    "    return jnp.array(params)\n",
    "\n",
    "# takes a flattened array of parameters and returns the weights and biases of the network\n",
    "@jit\n",
    "def unflatten_params(params):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    start = 0\n",
    "    for i in range(len(weight_shapes)):\n",
    "        end = start + weight_shapes[i].size \n",
    "        weights.append(jnp.reshape(jnp.array(params[start:end]), weight_shapes[i].shape))\n",
    "        start = end\n",
    "        end = start + bias_shapes[i].size\n",
    "        biases.append(jnp.reshape(jnp.array(params[start:end]), bias_shapes[i].shape))\n",
    "        start = end\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "\n",
    "network = gen_params(N, phi_structure, 1)\n",
    "# the length of the flattened parameters of a single particle neural network\n",
    "phi_params_length = len(network)\n",
    "\n",
    "# function that takes the coords, and moves coords[index] to the front of the list\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def shift_coords(coords, index):\n",
    "    return jnp.concatenate([jnp.array([coords[index]]), jnp.array(coords[:index]), jnp.array(coords[index + 1:])])\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_up(coords, j):\n",
    "    reordered = shift_coords(coords, j)\n",
    "    sym_piece1 = reordered[1:N_up]\n",
    "    sym_piece2 = reordered[N_up:]\n",
    "\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down+1):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "    \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@partial(jit, static_argnums=(1,))\n",
    "def inputs_down(coords, j):\n",
    "    reordered = shift_coords(coords, j + N_up)\n",
    "    \n",
    "    sym_piece1 = reordered[1:N_up+1]\n",
    "    sym_piece2 = reordered[N_up + 1:]\n",
    "    \n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    for i in range(1, N_up+1):\n",
    "        new1.append(sum((jnp.array(sym_piece1)/SYM_DEN)**i))\n",
    "    for i in range(1, N_down):\n",
    "        new2.append(sum((jnp.array(sym_piece2)/SYM_DEN)**i))\n",
    "        \n",
    "    return jnp.array([reordered[0]] + new1 + new2)\n",
    "\n",
    "@jit\n",
    "def Phi_up(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_up, N_up))\n",
    "    for i in range(N_up):\n",
    "        ith_params = params[i * phi_params_length : (i + 1) * phi_params_length]\n",
    "        for j in range(N_up): \n",
    "            mat = mat.at[i,j].set(nn(inputs_up(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat) * FACT_UP \n",
    "\n",
    "@jit\n",
    "def Phi_down(coords, params):\n",
    "    # construct the matrix of outputs of the neural networks\n",
    "    # take only the up spin coordinates\n",
    "    mat = jnp.zeros((N_down, N_down))\n",
    "    for i in range(N_down):\n",
    "        temp = i + N_up\n",
    "        ith_params = params[temp * phi_params_length : (temp + 1) * phi_params_length]\n",
    "        for j in range(N_down): \n",
    "            mat = mat.at[i,j].set(nn(inputs_down(coords, j), ith_params))\n",
    "    return jnp.linalg.det(mat)* FACT_DOWN\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return Phi_up(coords, params) * Phi_down(coords, params) * jnp.exp(-omega * jnp.sum((coords/DIV)**2))\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    # prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    prob = (psi(newpositions, params)/psi(positions, params))**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[N_up] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total\n",
    "\n",
    "\n",
    "psi_hessian = jax.jacfwd(jit(grad(psi, 0)), 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def ddpsi(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(psi_hessian(coords, params))\n",
    "\n",
    "\n",
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1)) \n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "\n",
    "vEs_nodelta = jit(vmap(Es_nodelta, in_axes=(0,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return N_up * N_down * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(np.sqrt(np.pi)*alpha))*np.e**(-(coords[N_up]/alpha)**2)\n",
    "\n",
    "vEs_delta = jit(vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return 2/(psi(coords,params)) * dnn_dtheta(coords, params) * (es_nodelta - energy_calc) + 2/(psi(coords_prime, params)) * dnn_dtheta(coords_prime, params) * es_delta\n",
    "\n",
    "vgradient_comp = jit(vmap(gradient_comp, in_axes=(0,0,None,0, None, 0), out_axes=0))\n",
    "\n",
    "def accumulator_sample(params, Nsweeps, Ntherm, keep, stepsize, g, positions_initial=INITIAL_SAMPLE, progress=True):\n",
    "    num_total = Nsweeps * keep + Ntherm + 1\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size=(num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "    accept_counter = 0\n",
    "    es = 0\n",
    "    grads = 0\n",
    "    mean = 0\n",
    "    m2 = 0\n",
    "    alpha = 1\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "\n",
    "    for i in range(num_total):\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "        if i >= Ntherm and i % keep == 0:\n",
    "            accept_counter += 1\n",
    "            new_prime = np.copy(new)\n",
    "            new_prime[N_up] = new_prime[0]\n",
    "\n",
    "            temp_nodeltas = Es_nodelta(new, params)\n",
    "            temp_deltas = Es_delta(new, new_prime, params, alpha, g)\n",
    "            temp_sum = temp_nodeltas + temp_deltas\n",
    "\n",
    "            es += temp_sum\n",
    "            curr_e_avg = es / accept_counter\n",
    "            grads += gradient_comp(new, new_prime, params, temp_nodeltas, curr_e_avg, temp_deltas)\n",
    "\n",
    "            temp = temp_sum - mean\n",
    "            mean += temp / accept_counter\n",
    "            m2 += temp * (temp_sum - mean)\n",
    "\n",
    "        positions_prev = new\n",
    "\n",
    "    stddev = np.sqrt(m2 / (accept_counter - 1)) / jnp.sqrt(accept_counter)\n",
    "    return es, grads, stddev\n",
    "\n",
    "def accumulator_gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # sample\n",
    "    es, grads, uncert = accumulator_sample(params, num_samples, thermal, skip, variation_size, g)\n",
    "    energy_calc = es/num_samples\n",
    "    gradient_calc = grads/num_samples\n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=50, variation_size=1.0):\n",
    "    # first sample\n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    ys = jnp.array(samples_prime[:, N_up]) \n",
    "    alpha = np.sqrt(np.max(abs(np.array(ys)))**2/(-np.log(np.sqrt(np.pi)*(10**-10))))\n",
    "\n",
    "    e_nodeltas = vEs_nodelta(samples, params)\n",
    "    e_deltas = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "\n",
    "    e_term = e_nodeltas + e_deltas\n",
    "    energy_calc = jnp.mean(e_term)\n",
    "\n",
    "    # compute the uncertainty in the energy\n",
    "    uncert = jnp.std(e_term)/jnp.sqrt(num_samples) \n",
    "    # gradient computation\n",
    "    grads = vgradient_comp(samples, samples_prime, params, e_nodeltas, energy_calc, e_deltas)\n",
    "    gradient_calc = jnp.mean(grads, axis=0) \n",
    "    return gradient_calc, energy_calc, uncert\n",
    "\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "def acc_step(params_arg, step_num, N, thermal, skip, variation_size, g):\n",
    "        gr = accumulator_gradient(params_arg, g, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "def acc_train(params, iterations, N, thermal, skip, variation_size, g):\n",
    "    hs = []\n",
    "    us = [] \n",
    "    ns = np.arange(iterations) \n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:   \n",
    "        new_params, energy, uncert = acc_step(old_params, step_num, N, thermal, skip, variation_size, g)\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params.copy()\n",
    "        # save the energies and uncertainties to a file\n",
    "#         save_energies(hs, us, \"energies.pkl\")\n",
    "        save_energies(energy, uncert, \"energies.csv\")\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .1\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    last = start\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        print(best_step)\n",
    "        it_num += 1\n",
    "        last = step\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "\n",
    "        if last == step:\n",
    "            break \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 5, step)\n",
    "    print(best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.196507666098807\n"
     ]
    }
   ],
   "source": [
    "print(compute_true_energy())\n",
    "# clear the energies.pkl file\n",
    "# save_energies([], [], \"energies.pkl\")\n",
    "open(\"energies.csv\", 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244510\n"
     ]
    }
   ],
   "source": [
    "# make N sets of parameters\n",
    "params = gen_params(N, phi_structure, 1)\n",
    "for i in range(N - 1):\n",
    "    params = jnp.concatenate((params, gen_params(N, phi_structure, 1)))\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 5101/5101 [00:16<00:00, 316.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5057831797686728\n"
     ]
    }
   ],
   "source": [
    "step_size = .3\n",
    "samples = sample(params, 1000, 100, 5, step_size, progress=True)\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a ton of samples from the final set of parameters\n",
    "\n",
    "params_4 = load_params(\"5+5_g_4_PRECISE.pkl\")\n",
    "params_5 = load_params(\"5+5_g_5_PRECISE.pkl\")\n",
    "params_6 = load_params(\"5+5_g_6_PRECISE.pkl\")\n",
    "params_7 = load_params(\"5+5_g_7_PRECISE.pkl\")\n",
    "params_8 = load_params(\"5+5_g_8_PRECISE.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC: 100%|██████████| 500101/500101 [09:45<00:00, 853.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samples_4 = sample(params_4, 50000, 100, 10, find_step_size(params_4, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC:   9%|▉         | 47390/500101 [01:08<08:36, 877.07it/s]"
     ]
    }
   ],
   "source": [
    "samples_5 = sample(params_5, 50000, 100, 10, find_step_size(params_5, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_6 = sample(params_6, 50000, 100, 10, find_step_size(params_6, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_7 = sample(params_7, 50000, 100, 10, find_step_size(params_7, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_8 = sample(params_8, 50000, 100, 10, find_step_size(params_8, .3), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_density(samples):\n",
    "    x_bins = np.linspace(-10, 10, 100)\n",
    "    dx = x_bins[1] - x_bins[0]  # Bin width\n",
    "    n_x = np.zeros_like(x_bins)\n",
    "\n",
    "    # bin the x_1s\n",
    "    for x in samples[0][:,0]:\n",
    "        n_x[np.digitize(x, x_bins)] += 1\n",
    "\n",
    "    # Normalize\n",
    "    n_x /= (dx * np.sum(n_x))\n",
    "\n",
    "    return x_bins, n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bins_4, n_x_4 = local_density(samples_4)\n",
    "x_bins_5, n_x_5 = local_density(samples_5)\n",
    "x_bins_6, n_x_6 = local_density(samples_6)\n",
    "x_bins_7, n_x_7 = local_density(samples_7)\n",
    "x_bins_8, n_x_8 = local_density(samples_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3xUZdbA8d9JI4EkRDqEDtJFmgIqiI3FshYWRBDsou6yrqu7rwXbLqvoKmvZ1Vf3tTewKyoWREAFqQoYeofQQgvpJDNz3j/uTQwxmWQmk0xIzvfzmU/m3vvc5565Se6Z55bnEVXFGGOMKUtEuAMwxhhTs1miMMYY45clCmOMMX5ZojDGGOOXJQpjjDF+WaIwxhjjlyUKYypARLaJyLnhjqMkEckSkY7hjqMkcbwsIodFZImIDBGR9cWW18j9aUpnicJUmojME5E896CVVfyAEEAd7UVEi9WRJSL3lbPNGyoXeWiIyCsiki8ime4rRUSmikjDqt62qsar6pZicfwj2Lrcg3euu+/3uQf6+CCrOwM4D2itqqeq6neq2jXY2Ex4WaIwoTLJPWjF+zsguAej9n7qSSpWz5SQR1l1/qmqCUBT4FpgELBARBqEN6yA/VZV44F+wCnAvSULuK2F8o4d7YBtqppdBTGaamaJwtQ6InKxiKwWkXS35dG92LI2IvKBiOwXkYMi8h93ficR+cadd0BE3hSRpEC3rap5qroUuBhojJM0Crd9nYisdU/HfCki7YotUxG5WUQ2usufERFxl3UWkfkicsSN7e0S63UWkYnAlcD/uC2CT0TkryLyfol9828RebICn2MX8DnQy11vnog8JCILgBygo4i0EpGZInJIRDaJyI1u2euBF4DBbix/E5FhIpJa2rZEJEJE7hKRze7+f0dEGlVoh5tqYYnChMpU9yC2QESGVaKe7SKS6p72aBLoyiLSBZgO3Ibz7X4W8ImIxIhIJPApsB1oDyQDMwpXBaYCrYDuQBvgwWA/hKpmArOBIW5clwL3ACPduL5z4yzuIpxv8ScDlwO/cedPAb4CTgBaA/8uZXv/Bd7EadnEq+pvgTeAEYUJT0SigDHA6+XFLyJtgAuAn4rNngBMBBJw9uF0IBVnn40CHhaRc1T1ReBm4Ac3lgfK2dytwKXAmW5dh4FnyovRVB9LFCYU7gQ64hx4/4tzYO4UYB0HcA6S7YD+OAejN4OIZQzwmarOVtUC4HEgDjgNOBXnQPRXVc12v/1/D6Cqm9x1jqrqfuBfOAeuytgNFH4zvgmYqqprVdUDPAz0Kd6qAB5R1XRV3QHMBfq48wtw9kur4jGXR1X3AN8Co91ZI4ADqrrcz2ofiUg68D0w342z0CuqutqNvwXOdYg73ZhW4LQiJlQkthJuAiaraqqqHsVJ0KPcxGZqAEsUptJUdbGqZroH2VeBBTjfRhGRtu4poHT3ANQWWFVs3ji3jixVXaaqHlXdB0wChotIYoDhtML5tlsYmw/YiZPE2gDb3QPdMUSkmYjMEJFdIpKB82084BZNCcnAIfd9O+CpYvvhEE4rJrlY+b3F3ucAhReS/8ctu8Q9pXZdADG8Cox334+n/NbEpaqapKrtVPX3qppbbNnOYu9bAYfcllOh7Rz7eSqqHfBhsX2zFvACzYOoy1QBSxSmKijOgQ1V3eEeeJJUNQnYAfQuNu8tP3VQWE8AduMceJyVnfP8bYBdOAe6tmV8U53qbrO3qibiHFQD3XYR926hc3FOMeFu+6bi+0JV41R1YXl1qepeVb1RVVvhfPt+VkQ6l1a0lHkfAb1FpBfOqa1gWmml1b8baCQiCcXmtcXZz4HaCZxfYt/EutdJTA1gicJUiogkichvRCRWRKJE5EpgKPBlgPUMFJGu7oXNxsDTwDxVPeJntSh3u4WvaOAd4EIROcedvgM4CiwElgB7gEdEpIG7zuluXQlAFpAuIsnAXwOJv9jnqCci/XEO0IeBl91FzwF3i0hPt1xDERldRjUl6xwtIq3dycM4B2xvKUX34ZwCLKKqecB7wFvAEve0VqWp6k6cfTrV3Y+9gesJLhE9BzxUeBpORJqKyCWhiNOEhiUKU1nRwD+A/TjXGf6Ic/oi0GcpOgJfAJlACs7BfWw56/wvkFvs9bK73fE4F3wPAL/FueUzX1W97nRnnJZNKs41DYC/4dwSegT4DPggwPj/R0QycU4pvQYsB04rvD1UVT8EHgVmuKe2UoDzK1j3KcBiEckCZgJ/UtWtpZR7EejhnsL5qNj8V4GTqMBF7ACNxbkpYDfwIfCAqs4Oop6ncD7XV+4+XAQMDFWQpvLEBi4ypnYTkbbAOqCFqmaEOx5z/LEWhTG1mDgPxt0OzLAkYYIVtkQhIi+JSJqIpJSxXETkafdBnlUi0q+6YzTmeCbOU+EZOF1plPcsgzFlCmeL4hWc+7rLcj5wovuaiHM+2hhTQe6zIvGq2tO9+GxMUMKWKFT1W365x7w0lwCvqWMRkCQiLasnOmOMMYVq8pOPyRz7gE+qO29PyYJuPzcTAeLi4vq3adMmqA36fD4iImreZZuaGhfU3NgsrsBYXIGpjXFt2LDhgKo2LXWhqobthXNrXUoZyz4Dzig2PQfoX16d/fv312DNnTs36HWrUk2NS7XmxmZxBcbiCkxtjAtYpmUcV2teSvxFKs4TtYVa49yvbYwxphrV5EQxE7jKvftpEHBEnU7OjDHGVKOwXaMQkenAMKCJ20/9AzhP+aKqz+F0D30BsAmng7RrS6/JGGNMVQpbolBVv90zuOfM/lBN4Rhj6qCCggJSU1PJy8sLaL2GDRuydu3aKooqeBWJKzY2ltatWxMdHV3hemvyXU/GGFOlUlNTSUhIoH379jgdDVdMZmYmCQkJ5ResZuXFpaocPHiQ1NRUOnToUOF6a/I1CmOMqVJ5eXk0btw4oCRxPBMRGjduHHALyhKFMaZOqytJolAwn9cShTHGGL8sURhjjPHLEoUxxhi/LFEYY0wt4vV66du3LxdddFHI6rREYYwxtchTTz1F9+7dQ1qnJQpjjAmztWvXMnToUHr37s1jjz1G586dg6pn165dfPbZZ9xwww0hjc8euDPGGOBvn6xmze7yR4vdeiCbtMyjNEuoR4cmDfyW7dEqkQd+29NvGY/Hw5VXXsmLL75I3759ueWWW+jVq9cxZYYMGUJmZuav1n388cc599xzi6bvuusu/vnPf5ZatjIsURhjTADSMo8W/SwvUVTEBx98wMknn0zfvn0B6NGjB82aNTumzHfffVduPZ9++ilNmjShf//+zJs3r9JxFWeJwhhjoNxv/oXu+yiFtxZvZ9zAdky5tFf5K5Rj1apV9OnTp2g6JSWFESOOHSW6Ii2KBQsW8Pnnn9O+fXvy8vLIyMhg/PjxvPHGG5WO0RKFMcYEYMqlvfifc9qFrK+nxo0bs2HDBgBWrFjBG2+8wZ133nlMmYq0KKZOnco999xDQkIC8+bN4/HHHw9JkgBLFMYYE1YTJkzgwgsv5JRTTmHw4MG0b9+ejh07hjusY9hdT8YYE0axsbEsXryYpUuX0qZNGy677LJK1zls2DA+/fTTEETnsERhjDFh9MQTT9CzZ0/69OnDtm3buO+++8Id0q/YqSdjjAmj++67r0Ymh+KsRWGMMcYvSxTGGGP8skRhjDHGL0sUxhhj/LJEYYwxxi9LFMYYY/yyRGGMMcYvSxTGGGP8sgfujDGmlujVqxeJiYlERkYSFRXFsmXLQlKvJQpjjKlF5s6dS5MmTUJap516MsaYMAvVUKhVxVoUxhgD8PldsPfn8ssd3ER81l6IbwGNyzmgtzgJzn/Eb5FQDoUqIgwfPhwR4aabbmLixInlf54KsERhjDGByNqLuD/LTRQVEKqhUAG++uorunTpQlpaGueddx7dunVj6NChlY7REoUxxkC53/yLfHYHuuxlZMC1cOG0Sm82VEOhArRs2RKAZs2acdlll7FkyRJLFMYYU+0unEbW0Adr3FCo2dnZZGZmkpCQQHZ2Nl999RX3339/SGK0RGGMMWEUqqFQ9+3bxyWXXEJERAQej4dx48b9qmUSLEsUxhgTRoVDoQI89thjQQ+F2rFjRxYuXBiylk5xdnusMcaEkQ2FWg4RGQE8BUQCL6jqIyWWNwTeANrixPq4qr5c7YEaY0wVsaFQ/RCRSOAZ4HygBzBWRHqUKPYHYI2qngwMA6aJSEy1BmqMMXVcOE89nQpsUtUtqpoPzAAuKVFGgQQRESAeOAR4qjdMY4yp20RVw7NhkVHACFW9wZ2eAAxU1UnFyiQAM4FuQAIwRlU/K6WuicBEgObNm/efMWNGUDFlZWURHx8f1LpVqabGBTU3NosrMHU1roYNGwbVXYbX6yUyMrIKIqqcisa1adMmjhw5csy8s846a7mqDih1BVUNywsYjXNdonB6AvDvEmVGAU8AAnQGtgKJ/urt37+/Bmvu3LlBr1uVampcqjU3NosrMHU1rjVr1gS1XkZGRogjCY2KxlXa5waWaRnH1XCeekoF2hSbbg3sLlHmWuAD93NswkkU3aopPmOMMYT3GsVS4EQR6eBeoL4C5zRTcTuAcwBEpDnQFdhSrVEaY0wdF7bbY1XVIyKTgC9xbo99SVVXi8jN7vLngCnAKyLyM87ppztV9UC4YjbGmLoorM9RqOosYFaJec8Ve78bGF7dcRljjPmFPZltjDG1RHp6OqNGjaJbt250796dH374IST1Wl9PxhhTS9x5552MGDGC9957j/z8fHJyckJSr7UojDEmzEIxFGpGRgYLFy7k+uuvByAmJoakpKSQxGctCmOMAR5d8ijrDq0rt9z2jO3sz91P07imtEts57dst0bduPPUO/2WCdVQqFu2bKFx48Zce+21rFy5kv79+/PUU0/RoEGDcj9TeSxRGGNMAPbn7i/6WV6iqIhQDYXq8XhYuXIlzz77LAMHDuRPf/oTjzzyCFOmTKl0jJYojDEGyv3mX+ihRQ/xzoZ3uLzL5UweNLnS2w3VUKitW7cmOTmZgQMHAjBq1CgeeaSCw7uWwxKFMcYEYPKgydza89YaNxRqixYtSE5OZv369XTt2pU5c+bQo0fJDrmDY4nCGGPCKFRDoYIzQt6VV15Jfn4+HTt25OWXQzN8jyUKY4wJo1ANhQrQu3dvli1bFqrQitjtscYYE0Y2FKoxxhi/bChUY4wxxz1LFMYYY/yyRGGMMcYvSxTGGGP8skRhjDHGL0sUxhhj/LJEYYwxxi9LFMYYY/yyRGGMMbXA+vXrOf300+nTpw99+vQhMTGRJ598MiR125PZxhhTC3Tt2pUFCxaQkJCA1+slOTm5Uv1GFWctCmOMCbNQDIVa3Jw5c+jUqRPt2lV+YCWwFoUxxgCw9+GHObq2/KFQ87dvx5OWRlSzZsSUcyCu170bLe65x2+ZUA2FWtyMGTMYO3ZsuZ+loixRGGNMADxpaUU/y0sUFRGqoVAL5efnM3PmTKZOnVrp2ApZojDGGCj3m3+hPX/7O+lvv03SmDG0fOD+Sm83VEOhFvr888/p168fzZs3r3RshSxRGGNMAFo+cD/xt/+5xg2FWmj69OkhPe0EdjHbGGPCasKECSxbtoxTTjmFl156qVJDoebk5DB79mxGjhwZ0hgtURhjTBgVDoW6dOlS2rRpU6lbWuvXr8/Bgwdp2LBhCCO0RGGMMWFV64dCFZEGQJ6qekMUjzHG1Cm1bihUEYkQkXEi8pmIpAHrgD0islpEHhORE6smTGOMMeES6KmnuUAn4G6ghaq2UdVmwBBgEfCIiIwPcYzGGGPCKNBTT+eqakHJmap6CHgfeF9EokMSmTHGmBohoBZFYZIQkSdFRPyVMcYYUzsEe9dTFjDTvZiNiAwXkQWBViIiI0RkvYhsEpG7yigzTERWuNdB5gcZrzHGmCAFddeTqt4rIuOAeSJyFMgGSj3Ql0VEIoFngPOAVGCpiMxU1TXFyiQBzwIjVHWHiDQrvTZjjDFVJagWhYicA9yIkyCaAreqasWfMXecCmxS1S2qmg/MAC4pUWYc8IGq7gBQ1bRg4jXGGBM8UdXAVxL5BrhfVb8XkZOA14HbVfWbAOoYhdNSuMGdngAMVNVJxco8CUQDPYEE4ClVfa2UuiYCEwGaN2/ef8aMGQF/JoCsrCzi4+ODWrcq1dS4oObGZnEFpq7G1bBhw6DGfvB6vURGRlZBRJVT0bg2bdrEkSNHjpl31llnLVfVAaWuoKqVfgEtgYUBrjMaeKHY9ATg3yXK/AfnttsGQBNgI9DFX739+/fXYM2dOzfodatSTY1LtebGZnEFpq7GtWbNmqDWy8jICHEkofHwww9rjx49tGfPnnrFFVdobm5uqeVK+9zAMi3juBroA3dl3em0BzjHX5lSpAJtik23BnaXUuYLVc1W1QPAt8DJgcRsjDF1wa5du3j++edZtmwZKSkpeL1egj27UlLAD9yJyB9FpG3xmSISAwwWkVeBqytY11LgRBHp4K5/BTCzRJmPgSEiEiUi9YGBwNoAYzbGmBotVEOhejwecnNz8Xg85OTk0KpVq5DEF+hdTyOA64DpItIROAzE4SScr4AnVHVFRSpSVY+ITAK+BCKBl1R1tYjc7C5/TlXXisgXwCrAh3OqKiXAmI0xplzfvbOBAzuzyi2XnpZDzpF86jeMIalZfb9lm7SJZ8jlXfyWCdVQqMnJyfzxj3+kbdu2xMXFMXz4cIYPH17u56mIgBKFqubh3K76rPsEdhMgV1XTg9m4qs4CZpWY91yJ6ceAx4Kp3xhjQi3nSH7Rz/ISRUWEaijUw4cPM2vWLLZu3UpSUhKjR4/mjTfeYPz4yveqFNRzFCJyNnAlkA6kiMgqIEVVj1Y6ImOMCYPyvvkXmj99Pau/20XPIcmcObZrpbcbqqFQv/76a9q1a0fTpk0BGDlyJAsXLgxfogDeAP7grt8buBTnFtbgTqwZY8xx4syxXel3UasaNxRq27ZtWbp0KTk5OcTFxTFnzhwGDCj9btdABZsoNqnqh+77d0MSiTHG1EETJkzgwgsv5JRTTmHw4MFBD4U6cOBALrnkEvr160dUVBR9+/Zl4sSJIYkx2L6e5ovInwO4FdYYY0wpQjkU6uTJk1m3bh0pKSm8/vrr1KtXLyQxBpsoegK34Axa9JmIPCQio0MSkTHG1CG1dihUVR0JICJxOEmjFzAIOw1ljDEBOR6GQg32rqcnVfU2Vc0FlrkvY4wxtVDQ41GIyCeVHY/CGGNMzRe28SiMMaYmUFXq0n05GkSP4eEcj8IYY8IqNjaWgwcPBnXwPB6pKgcPHiQ2Njag9YJ9jmIycJ/+Mh7F2yIS0HgUxhgTbq1btyY1NZX9+/cHtF5eXl7AB9vqUJG4YmNjad26dUD1Bnvq6exi738WkfOB94HTgqnPGGPCITo6mg4dOgS83rx584r6ZqpJqiquQMejOF9EftVvbfHxKIwxxtQugbYofgdMEZHmwDpgBbDS/WnjRBhjTC0UUItCVW9QZ0zVacAGYCtwFrAE2B768IwxxoRbsBezr1XVoiFJReRZ4K+hCckYY0xNEuwDdxki0r9wQlWXAxXrzN0YY8xxJdgWxXXAGyKyBlgOnAQUhCwqY4wxNUZQLQpV3YhzK+wsoDnOhewLQhiXMcaYGqLcFoWINAUuUdUXis9XVS9Ob7HWY6wxxtRiFWlRzANq3pMlxhhjqkVFrlH4gEQRuRPIKvHKLDlPVXOqKFZjjDFhUJFEcQFwKzAASADiS3nVBxRARA4Af1HV16siYGOMMdWr3EShqjsp5xkJd+zswqQxGPg/wBKFMcbUAsHeHnsMdfrozQQyReRR4O1Q1GuMMSb8AkoUIjIYWKT+O28fqKqHKheWMcaYmiLQ5yiuBpaLyAwRuUZEWpQsYEnCGGNql4BaFKp6M4CIdAPOB14RkYbAXOALYIH7fIUxxphaItgns9ep6hOqOgI4G/geGA0sDmVwxhhjwq9SF7NFpAGQp6qzcLrzMMYYU8sEOsJdhIiME5HPRCQNWA/sFZHVIvKYiJxYNWEaY4wJl0BPPc0FOgF3Ay1UtbWqNgWGAIuAR0RkfIhjNMYYE0aBnno6V1V/1Z24e6fT+8D7IhIdksiMMcbUCIEOhVoAICJPuk9jl1nGGGNM7RDsCHdZwEz3YjYiMlxEFoQuLGOMMTVFsLfH3gtMB+aJyPfAHcBdgdYjIiNEZL2IbBKRMtcXkVNExCsio4KJ1xhjTPCCuj1WRM4BbgSygZbA9aq6PsA6IoFngPOAVGCpiMxU1TWllHsU+DKYWI0xxlROsKeeJgP3qeowYBTwtoicHWAdpwKbVHWLquYDM4BLSin3R5wL5WlBxmqMMaYSxH//fhWsRKQl8L6qnhbAOqOAEap6gzs9AadDwUnFyiQDb+E8/f0i8KmqvldKXROBiQDNmzfvP2PGjKA+R1ZWFvHx8UGtW5VqalxQc2OzuAJjcQWmNsZ11llnLVfVAaUuVNUKv3ATSxnL4sorU6L8aOCFYtMTgH+XKPMuMMh9/wowqrx6+/fvr8GaO3du0OtWpZoal2rNjc3iCozFFZjaGBewTMs4rgZ6jWKuiLwPfKyqOwpnikgMMFhErsZ5KO+VCtSVCrQpNt0a2F2izABghnsnbhPgAhHxqOpHAcZtjDEmSIEmihHAdcB0EekIHAbicK51fAU8oaorKljXUuBEEekA7AKuAMYVL6CqHQrfi8grOKeeLEkYY0w1CrSb8TzgWeBZ9wnsJkCuqqYHumFV9YjIJJy7mSKBl1R1tYjc7C5/LtA6jTHGhF6wt8eeDVwJpAMpIrIKSFHVo4HUo6X0OltWglDVa4KJ1RhjTOUE2834G8Af3PV7A5cCPYHOIYrLGGNMDRFsotikqh+6798NVTDGGGNqnmAfuJsvIn8uq2NAY4wxtUewLYqeQC/gThFZDqwAVqiqtS6MMaaWCSpRqOpIABGJ45ekMRA7DWWMMbVOpcbMVtVcYJn7MsYYUwsFe43CGGNMHWGJwhhjjF+WKIwxxvhlicIYY4xfliiMMcb4ZYnCGGOMX5YojDHG+GWJwhhjjF+WKIwxxvhlicIYY4xfliiMMcb4ZYnCGGOMX5YojDHG+GWJwhhjjF+WKIwxxvhlicIYY4xfliiMMcb4ZYnCGGOMX5YojDHG+FWpMbONMcenz5//ma0r9tNzaDJnju0a7nBMDWctCmPqmMN7s9ny035UIeXbXfh8Gu6QTA1nicKYOsTr9fH1y2uIiBJnhsInT6/Ak2fJwpTNTj0ZU4cs+2wbadsz+c2NvejUrylrF+xh7pvrYB3ontWcd23PcIdoaiBrURhTR+zdcoTln2+j66AWdO7fDBGhxxmtcNsWbFi8jyP7c8Mao6mZLFEYUwcUHPUy8+kVqEJEpByzrOfQZBCIiBI++tePpKflhClKU1NZojCmDvjhg00U5HkBWPfDnmOWnTm2Kz3HRDD6rgHkZubz5v2LePWeBaxZsJu87IJwhGtqGEsUxtRyO9cd4uf5u2ic3ACJgJ5Dkkst16R1Aj6vc1E769BR5r6+jhfv+M65hmHqNEsUxtRi+bke5ry6lqikGP4bnc1jDXP5Oq7sVkLPoclIBPQamoy4Z6jWfL+7mqI1NVVY73oSkRHAU0Ak8IKqPlJi+ZXAne5kFnCLqq6s3iiNOf6kZeTx3cYDrH9lA4kFyoYoL1twEsQbi7cz5dJepa535tiuxzyAl/LtLurFRaGqiEip65jaL2wtChGJBJ4Bzgd6AGNFpEeJYluBM1W1NzAF+G/1RmlMxU2cPZHer/bmlq9vYWfGTnzqq9btqypfr9lHvylfcerDc3hoxioSCxRBONETybiBbRFAFf41ewOq/p+dOHNcV86+qhtHczykrj9cPR/C1EjhPPV0KrBJVbeoaj4wA7ikeAFVXaiqhX+hi4DW1RyjMRXy1tq3+GH3DyjK97u+54IPL+Dk105m8neTq2X7y7YdYvRzP3DDa8s45F6APuVoFCD4UHLb1Ofhy05i08MXMLp/a56es5GOd8/ivo9S/NZ74inNiUuIZtWcndXwKUxNJeV9q6iyDYuMAkao6g3u9ARgoKpOKqP8X4BuheVLLJsITARo3rx5/xkzZgQVU1ZWFvHx8UGtW5VqalxQc2OrzriWZi3ltYOv0SiyEenedE6KO4lVuatQnP+tO1rcQft67assrtRMH/cucJ5/6HpCBK0aRLB0p4ebMmJp3EloNeDY74M+Va770rkFVoCXRzTwG1fazz72r4bOFwj1Eqv39JP9fQWmMnGdddZZy1V1QGnLwnmNorS/uFKzloicBVwPnFHaclX9L+5pqQEDBuiwYcOCCmjevHkEu25VqqlxQc2NrTri8vq83PL1Lfxw8AeaxTVj1u9mUS+yHgAPLXqIdza8Q1xkHE/sfQKAy7tezumcHvK4/vDmj4CTKDalK1/e+Rt++GgzP365nQuuGkRSs/q/Wmfs4VVMX7KTqAihbc8B7Fi9rMy4cvrl8+o9C4jLbsXQi6u3A8G6/PcVjKqKK5yJIhVoU2y6NfCr2ytEpDfwAnC+qh6sptiMKdWRo0f4y/y/sHjPYqIjosn35QNwIO9AUZIAmDxoMpMHTSY9L50hbw8B4J0N73B629NDGs+GfZnMStlDr+RE1u7OZNzAtuTneUiZv4tOfZuWmiQApo7szaSzT+S3//6em15fzh29lQKvj30ZeRzOLiDP4+W5+ZuZuy6Nkf1a07dxLD/P38WWlfsZfGknOvRpSkys9QBUV4TzN70UOFFEOgC7gCuAccULiEhb4ANggqpuqP4QjYH9Ofu5fd7trNi/4pj5Bb4CBrUcxJK9S7i8y+WlrpsUm8TFnS5m5uaZNIltUu4FZICf/nUpJx+Zy/qEQXT/82cQWfa/6dNzNtIgJorXrxvICQ1iAFjx9Q7ycz30Pa8dePIhcw9kH4D5j6AbvyY3dhB7Zu0hPy2PGckNWZLfgtb/t5En2g/m2ZNH/mob7y1PpV16LBEIWen5fP3KWmAt3U9vydkTupf7eczxL2yJQlU9IjIJ+BLn9tiXVHW1iNzsLn8OuB9oDDzr3prnKescmjGVtWr/Ku6Ydz7kNnUAABt6SURBVAf7cvbRvVF3YqNi+THtx2PKCMI5bc9h7s65jO4ymsmDyr9Y/dAZD3Fy05OZsmgKi7MXcxZnlVk25/Ae+hyZiwh0z1rEjt90JTs1mqiEKOr37sHRTZs4mpZD0uB2ZE19j89+3sPvh3XihAYx5GTks3HZPhZ9vBmAdd+k0HzPSLy5eeTujyFtVQJH05sD23DO8greXRn0JwOAC7f+wP/2Gel08yFwXo/mzF6zj37tTmDlmkxOzo9iZYyHfgXRqMLahXssUdQRYW07quosYFaJec8Ve38D8KuL18aEkqry2prXeHL5k3jUA8CaQ2uKlgvC+R3O58ttX1Y4OZQ0qssoPtvyGR8e+JAbc2+kcVzjomW5K1aQ+sdb8ezfD82i6DxMiACWpXYlMfUIIHgyPWxOrcfqE/+Br1s96ufs4cC0H7kjI5aGCw/zytzvyU7PP2abq5dm02pJAp6cJI65JCjQsG9Tjvy0n6QOOeR5YsnbEYEAD+f+yL2x/Rg3sB1/v6QnqCIREdz70c9MW7SDpLhoxnduxervdhOfVA9TN9hJRlOn3fPdPXyy5RMAzml7Dg3rNeTjTR8z8sSR5Bbk8vm2z4uSw6NDH/VbV+ptfybzyy+pP2gQRESQ88MPJF0+mpYPPkiERPDA4AcY+cHFjHn+TC5OPJ1LvveQ88MPzoMNhdI8rF7Ul+SLR5H4zjPk14smKt9LSt+xHEg8wykrQk79ltTP8ALCkX25RWlABHr2gdU/eWmd9j2eHPdfXCBp9GjS3/+ApMsvp+UD99NKFVa8CR//Ad+pwp4lSfT54i0+5S3ki1jW3ZUHKIknN+Mfb39Lv7YncPs7KynoewJ946JY+fVO8rIKiI2PDvnvxdQslihMnbQ7azcv/PxCUZIQhCeGPYGI8LfT/lZUburQqRWq7/Db75D5xRcAzsHflT7jbbLmzcezbx8RiYm8ecTrPrz0LUV9tIrg7RRD5OY8aCrU23OQA//5D1GtWzNr8H3U21+AIBxpHcuWfZn0zY8kedd3SJKwK/50omPX0HXgCFZ/t4uenQ8wYMUkWi48AaLrUX/4cDLnzClKDi3//vdfghaBvuNh2/fIyum0GnyYjB2xgKB5hd2NCxkr02j29l+4+Lf38USjOP4zdxP/d9FJ/PTVDras2E+PM1oF8yswxxFLFKbO+dM3f+Kbnd8gCJ2TOrPlyBYu73J5UF1UqNdL2iMPcej16UQlRuHJLCCxjXOQzdgRR0zDAvL37gXAd+RI0Td/n8CC7nDaWljQM56JPdcjA8CjEcxccQd7WgwmwnuU2P0eQEDgnntP476PUvjX4h08491Lu++/pQsziG7gIWrHVzRbswX51scOT2NASWyVQfLTT5X/IS57jvknXMGwFtkkLb+Z9M0NSOqUA407kb5kD4iw/bGPabf8RV7sMpLhm0ayIf8oiU3j2LhsnyWKOsAShalzvtn5DQAiwoeXfBhUHerzkTP7A3bfPRlPTgQxiQV0HLEbiQAkAvpeRfJPr0PLk9kzc5N78M0mI7EbvhW72Xn6cJ4+fQ7/vkRBcxid2oTEgkMsa3Ipe1oOBgRfVD1ad01i18b0oh5fp1zaiymX9kL1fNb16AEqFGRHUbBmixOXJ8K5HKFCxo76lN5PbBm6XUjLm35Hyx9fgwHXwoXTaAnkrlzJtivGsGlmcxp2+pq4fqMY/+ISbmnUmMz1h8nJyKd+YkxQ+9EcHyxRmDplc7pzR5AgZd7S6o+qsn38BHKXL3fnOG2E/MwopPdoWP0Bnn7XMPHAWObmDadbTgJ/GPQUF/SfQ7ok0pUl0AU66yuMzGjCR4n1UBG+uux+ruh5Ne23HGH56uUg0Gto62M66CtOREi6Yizp77xD0shL8C19g4ztcSR1zoUB1zvzLw/88/HbJ51XMXEnn1z0OY9sjsPTOx+I4v39h7haY9myYj+9hgaUksxxxhKFqVOmr5tOTEQMs0fPplFso4DXPzx9erEkoSSd0oL0ZXtJGtyOm3Nv5svcy4j6QSjwpQGwdm8mk7gOuA6AzfXGEyk+IlH+fmg/fzuk3NKiGdN++g8DWw1l+bsHqZ8Yw5V/H1TqA205BTnkenIp8BUQ9ddb6P7A/c6Cz/JIXvay2xK4n5aF80Mk6YqxpM+YDgrT4r7n1pxhxDePI6l+HJuW7bNEUctZojB1RkZ+BjM3z+T8DueXnyR8PnjvWlj7SdFpmJyF89n3j38QVd+DJzeSpM65tHx9Hi1xOuX74jnnIrbHp5zdrRnz1+9n3MC2ALy1eAfjBrZl3rpzOTP3a5Y1uZRBHRshy17m762GM+LID9zx4t85Z+sEfuj6Af96+xY6JHZg4skT6diwI4v2LGLOjjms2r/qmDAFYUzXMUy+cBpcOM3vR1JVdmXtIuVgCi+seoH1h9fTOLYxeZ48sj3ZjFo4igdOe6Co7PhZ41l1YBX9mvVj2v9Mo8ufb2PL2YPo+fksrr59DNNX7icitj67NqTz9StrOPeakp0/m9rCEoWpMz7a+BG5nlzGdS/WAcCnt8Pyl6HX7+Cy5wGBtR/D/McgbbVTZumLFMR2JfUvTxDTwEP7CS2JPJziJBBg+8FsJr6+nITYKHKOehk3sO2vxnsonJ437w9EDXuXQYULLpxGM0BeOoWBO35LWoMdrDzhWwC2Zmzl7u/uLqqjR+MeCIKiRT8V5Z0N75T6bEe+N5+rP7+alIMpJMYkklOQU/ScSKGDeb/0ivPexve4Y8Ad1I+uz2NLH2PVAScp/Zj2I2e94zwkePOYjpz94mauWvIir0ZexKFd2QCsX7zXEkUtZiPcmTrB6/Myfd10+jXrR4/G7gHNkw/LXgL1wc/vwsPJMDUZ3r0GjqTibTaQ7H31OLgugS23PY43V4lt14TIW7+FBw7BhdM4klPAda8sxafKzElnsHnqBWUOClSWnesOcc3KKcTnJ5HUuAFXdBtDpERyeZfLiRDnXzRCInj7orcZ09VZNqbrGC7rfBkAsZGxZORnHFPn9oztjJ81npSDTjfiGfkZeNVbVNfoLqOJlEiu6HoFV3S9AnGvQdz41Y3ct+A+3lj7BicmnUikRDKi/Yii5c81244v0Uf+J3N59+eH2OB2VBoVFYHXW73jb5jqYy0KUydMmjOJ1KxU2iY6p4IoyIN3rwb3+3lWy0Fspz3xb35FblpDIqIVX8FOnB5koLDLi4zVh/ntlK84lF3ACfWjOerxkZPvZXiP5nRo0iCgmL74bwqbf3SuZUTg3DVUL7Uxf3Y7FATnoP7uhncZ3WU08Etng4VGnjiSa764hgcXPsidp9xJWk4a05ZNY3nacqIjohmSPISFuxcWrV9Y1+RBk7l/8C/XMU7POx1fRx+3zb2NlIMp9Grci7cufKvoluGkeklOb7hRcWim0yppsPkQH5+Uy78u6sKeT3eydcUBOvdvFtA+MMcHSxSm1sv15PL97u8BWLxnMcy8FX58FYDXGt3KA7tO5ez5P3LNms+JzHO6pfAWiHOQVMUrERzo0JDmWw+xr0OjooGBDuf8Mvb0nLVpv9ququLJ95Gf5xxY49wnmA/uzmLpJ1vZ/NN+p6BAjzNasXbB7qLbYAuVTAwl9WnWh1v73coTy59g9vbZxyzzqpdnz332V/WV5ey2ZyMiqCprD6095rmSwjgy8jN48dNB/OZHpSBS6NbAw3u7DzCiUSwp81MtUdRSlihMrff8yucB95RL88Fs+8en5O5viUQqnSI/57P89xAgsnsPtnAirdf9yKz2gxDg/G2L+LrTafw08ka+33iAcQPbMoFfLk5T4j1AxoFc3n98OTkl+l5ygoDVviVIJDRrl8D+nZn0HJLMmWO7ctaV3YL6fNf0vIYnlz+JokQQwbntzmXOjjlFrYhAXN7l8mNaMCUlxiSS9cex/G32DB58y8eNO5/hjuw/0eWERjTdkM7B3Vk0blXzBvQxlWOJwtRqGw5v4NXVr3JZTEv+vn4J6XP2sWf/CQD4vMIJ3mz3+TThxPffpUuEc00gzx1a9JmTRxIpwubrTj2m3imX9sLn9fH58z/TMj2WbpmRzvaW7GX+W+vJz3OuBxQ9iq3ue98v06PvPiUknzFCIhjTdcwxp5WCVV4LBuC+wfdx4ORbWDl7KInrdtJxyAbeOdiFP0bVZ/X8XQwt49kPc/yyRGFqLZ/6+NsPfyMhJoHbNywjY2c99ixJIjvxBGIz0/miw2AuPKkV+V/OpumlFyARv9zbMaB9I8YPasdbi3Ywvk8yadsz8Hmdzvu8Hh/bVh1gw5J95GQ4rYa1C/awcek+PPk+6idG0/7kJmxcuq/oVNLq73bRc0gyu3btIn0LvzrFVFkVOcCHUpP6TWhx5XginnydRrEv0KZ5IxIO/JOf5+/C6/Vx1njrfrw2sURhaq0bvryBVftXMahBWzK+aUj23npEJtRjwtC/4I2sR8+CSE7w1Cdv0FlEHBCSn15BTkY+B1OzqJ8UQ5s8L7fnxcLcg7w799eDKyY0jqVtj0bsXHuIpu0TSdvq3HmUm1XAedf25LxrexaVLXzCet68PYz7y7Bq+fxVrftVt7H8f1/nguXKk5ce5tS1Th9XaxbssURRy1iiMLWST30s3bcUgAYLtpK9NxYAT7aHC/Li6eCJRBDycC40+zxKbqaTJIBjry+I232S08M3uO+zDudx1UOnFRWbP319UcuhLoioX5+CpGgGrSvgD596yeofSex2L5GRQn6ex4ZKrUXsOQpTK63KXQWqXLbQx02fK1HNm0FEBAv6jClKEiLQa2gyEgG9zkxmzORTj5nudab7fmgyPd35PYu/L5EQzhzbld8/e3aZ/TPVRifs9yLAGSmwssE/uewv/fB6lJT5u8IdmgkhS/mm1lFV5hyZw6OveemwG6JPiKbT7NlM/3Ib2Z/tJKZeJBT4iu42OnPcLwf2M8eVmB5b/vu6LGnMGNKnT6cgBtbEbyMlM4U2PRrx0+wdnDSsNdH1IsMdogkBa1GYWmfF/hXEbNlK+93OxeeC9Hw+fXEthz7biUYIV08ZXOe++VeVlg/cT6t/Pkq9fOi2E95efg+nXNiBvKwCfp6fGu7wTIhYojC1zltL/sttH3uJiFIQRU4bwPaVBxGEaB80SLSxnkMpYfhwIhISuGCFsiT6MPd+M4I2PRqxZOYWnv39N8yfvj7cIZpKskRhapWt6Vvp9uJ8GmUq7R76Ey3mLmd+w4kUoPhQVsZ4yq/EBCQiNpbEiy6k50alfp6yNDqTUy5oj9ejqM+5Ndgc3yxRmFol5fKLOG2tcqCZ8P2hM3nrwcXk5hTwQRMPT55wlBZn27CdVSHpd6OI8cAZq30okB2/g3r1nUugdeUusNrMEoWpNVZ9/gaddjiPPicdqMeGxfsAiAT+fdPAoHp2NRUT27MH9bp146r1LYlReHL2/ZxyUQcAeg6x5Hy8s0RhaoXcTRvx3v0w2bHgEWHZwGtQwIey84QI+rRJCneItZqIENGgATHbdzPlHWWhZxPx3SAyKoI1C/aEOzxTSZYozHHPc+AAG667irxI5eCEBPIe+4S8mN7Miy1gWlIe75Mb7hDrhNwVPwHQfquPmKPKv+Y9SMc+TdiweC+eAm+YozOVYYnCHNdUlc0jf0d0Wjp7Wvko8D3Gkk+3kxOtLKvnIUI4pmdXU3WSLh8DEREIcNfnXhYcXcK07Ac5muNhy4r94Q7PVIIlCnNcS3/vPXxpaQjQYVsCOzY731xjC+DWczqzZeqFdl2imrR84H66r1lNk0mT6LpeGLjWy+6GG8iod5C1dvrpuGaJwhy3CvbtY/fUhzkYD16B7091xlDwoWxq4GXS2SeGOcK6qcnNNxF3Ug/+8KmP6Y8W0OLwAlLXHebZW+yZiuOVJQpzXFJVtt57JwX5eTxxBdxz48lERJ/Cz0kwLSmP3a19xETZn3c4SFQUraY9QbRPiFTovXIx4HSkaM9UHJ/sP8kcl7Zfex3e7xazozlMa9CWyzaNon7sYb5S58L18jS7eBpOMW3bEjdgAADbm6ZzIH4vAMldTwhnWCZIlijMcSdrwQJyFi0CoG1aA+Ztv48cXyN+9CTQqXk8kSIMa239XYZbu9dfo8GA3nTZq3zXaip747exZeM+so8cDXdoJkCWKMxxJXvhQrbdPJHMODjUsAPfD76LLHfsiC6eSGb9aQibp17AVT2tP6dwExFaPv4U0VExTPrMw7yObxDhhXlvrkdVwx2eCYAlCnNcUFV23DiR7dddT1aUMmfY7fzU9w40qj7rozz4UFbFeImOtD/pmiS6RQta3HcvXXfB80/vQXJmsm3VAZ79/Vzmvbku3OGZCrL/KlOj+XJyOPz2O2y9+GKyv/uO/JhEtpz4exrmdkIQ8NVjUQuxfpxqsMSRzt1oApyzeC6KgkLKd7s4uCsrvMGZCrETuaZGUlUyPv2M3ffeC0ePkh0n/Hjq7ymI64HiY38sNMlTNicK3915NrHRNkBOTSUiJI0dS/qMGUSo0nTftxxoNgTwMGPKEhDocUYrzrqyW7hDNWUIa4tCREaIyHoR2SQid5WyXETkaXf5KhHpF444TfU6unkzO669ht1//SueAi+7W57Gz73upaB+T2fQahFejc1lWlIen0TmWZI4DrR84H66r11D66ef4qS1b3P2/D9yxsL7nHtmFdZ8u4tNy9Ps2kUNFbYWhYhEAs8A5wGpwFIRmamqa4oVOx840X0NBP7X/WmOQ6qK5ueTm32EjMw0Mg+lkbl9F7k70tC5K9G0XI7GJrC32WlkJF6FnDESX2R9RCJRXybbory080SwLSmSUf1a8+FPu6x7juNMwvDhJA1ow5FlO4mrl03yrm/ZlTyEqIIcvvy/FFAl0nOA7MR86uW2JCt+K03yY2jcKImEpknENWtERGw98HrxebyoKpEx0UikfVmoShKuDC4ig4EHVfU37vTdAKo6tViZ54F5qjrdnV4PDFPVMvsDGDBggC5btizgeF686t/kxfUAde+/l0hQLxHqwSdRRdPFl9WE98dXfD63RVDBhqwqKiAIio9/nXAUn0KkCJunXuB31Xnz5jFs2LCKbacaWVzHem9UX7qvzmN/UgSrez/l/G2oOn8nZSm5XJ1+giGi1vzfBB9rBLFHf+D6V+4re/+VQUSWq+qA0paF8xpFMrCz2HQqv24tlFYmGTgmUYjIRGCiO5nlJpSAtGlyYn/nclth4nTe7zywcXlZy2rC+9oYn/iy0YgGiC+bbGJy60fExOX48nPTvblZkbEJTb15mfvlkX078K8JcKCcMuFgcZWh7Yar+mlEvIgvS6O9SH50PDEFWeRHx1MT/i7D9T6YWG+Q+5cTuHZlLQhnoijtK0PJ5k1FyqCq/wX+W+mARJaVlVHDqabGBTU3NosrMBZXYOpaXOG8mJ0KtCk23RrYHUQZY4wxVSiciWIpcKKIdBCRGOAKYGaJMjOBq9y7nwYBR/xdnzDGGBN6YTv1pKoeEZkEfIkzrPFLqrpaRG52lz8HzAIuADYBOcC1VRxWpU9fVZGaGhfU3NgsrsBYXIGpU3GF7a4nY4wxxwfrwsMYY4xfliiMMcb4VecShYiMFpHVIuITkQEllt3tdheyXkR+U8b6jURktohsdH+GfCQWEXlbRFa4r20isqKMcttE5Ge3XOBPGQYe14MisqtYbKU+9VZe1yxVENdjIrLO7eblQxFJKqNcteyvmtg1jYi0EZG5IrLW/fv/UyllhonIkWK/3/urOq5i2/b7uwnTPutabF+sEJEMEbmtRJlq2Wci8pKIpIlISrF5FToWheT/UVXr1AvoDnQF5gEDis3vAawE6gEdgM1AZCnr/xO4y31/F/BoFcc7Dbi/jGXbgCbVuO8eBP5STplId991BGLcfdqjiuMaDkS57x8t63dSHfurIp8f5waNz3GeExoELK6G311LoJ/7PgHYUEpcw4BPq+vvKZDfTTj2WSm/171Au3DsM2Ao0A9IKTav3GNRqP4f61yLQlXXqmppT25fAsxQ1aOquhXnTqtTyyj3qvv+VeDSqonU+RYFXA5Mr6ptVIFTgU2qukVV84EZOPusyqjqV6rqcScX4TxvEy4V+fyXAK+pYxGQJCItqzIoVd2jqj+67zOBtTi9HBwvqn2flXAOsFlVt1fjNouo6rfAoRKzK3IsCsn/Y51LFH6U1V1ISc3VfZbD/dmsCmMaAuxT1Y1lLFfgKxFZ7nZjUh0muU3/l8po6lZ0P1aV63C+eZamOvZXRT5/WPeRiLQH+gKLS1k8WERWisjnItKzumKi/N9NuP+urqDsL2zh2mcVORaFZL/VyvEoRORroEUpiyar6sdlrVbKvCq7d7iCMY7Ff2vidFXdLSLNgNkiss795lElceH03jsFZ79MwTktdl3JKkpZt9L7sSL7S0QmAx7gzTKqCfn+Ki3UUuYF1TVNVRCReOB94DZVzSix+EecUytZ7vWnj3B6bq4O5f1uwrnPYoCLgbtLWRzOfVYRIdlvtTJRqOq5QaxW0e5C9olIS1Xd4zZ906oiRhGJAkYC/f3Usdv9mSYiH+I0Myt14KvovhOR/wM+LWVRlXS7UoH9dTVwEXCOuidnS6kj5PurFDW2axoRicZJEm+q6gcllxdPHKo6S0SeFZEmqlrlnQVW4HcTzu58zgd+VNV9JReEc59RsWNRSPabnXr6xUzgChGpJyIdcL4VLCmj3NXu+6uBsloolXUusE5VU0tbKCINRCSh8D3OBd2U0sqGSolzwpeVsb2KdM0S6rhGAHcCF6tqThllqmt/1ciuadzrXS8Ca1X1X2WUaeGWQ0ROxTk+HKzKuNxtVeR3E87ufMps2Ydrn7kqciwKzf9jVV+tr2kvnANcKnAU2Ad8WWzZZJw7BNYD5xeb/wLuHVJAY2AOsNH92aiK4nwFuLnEvFbALPd9R5w7GFYCq3FOwVT1vnsd+BlY5f6xtSwZlzt9Ac5dNZurKa5NOOdhV7iv58K5v0r7/MDNhb9PnNMBz7jLf6bY3XdVGNMZOKccVhXbTxeUiGuSu29W4twUcFpVx+XvdxPufeZutz7Ogb9hsXnVvs9wEtUeoMA9fl1f1rGoKv4frQsPY4wxftmpJ2OMMX5ZojDGGOOXJQpjjDF+WaIwxhjjlyUKY4wxflmiMMYY45clCmOMMX5ZojCmiokzDsR57vt/iMjT4Y7JmEDUyr6ejKlhHgD+7nZ41xengzljjhv2ZLYx1UBE5gPxwDB1xoMw5rhhp56MqWIichLOCHNHLUmY45ElCmOqkNvj7ps4o4plSxljsRtTk1miMKaKiEh94APgDlVdizPY04NhDcqYINg1CmOMMX5Zi8IYY4xfliiMMcb4ZYnCGGOMX5YojDHG+GWJwhhjjF+WKIwxxvhlicIYY4xf/w8Upltc60W+1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_bins_4, n_x_4,'-o', markersize=2,label=r\"$g=4$\")\n",
    "plt.plot(x_bins_5, n_x_5,'-o', markersize=2,label=r\"$g=5$\")\n",
    "plt.plot(x_bins_6, n_x_6,'-o', markersize=2,label=r\"$g=6$\")\n",
    "plt.plot(x_bins_7, n_x_7,'-o', markersize=2,label=r\"$g=7$\")\n",
    "plt.plot(x_bins_8, n_x_8,'-o', markersize=2,label=r\"$g=8$\")\n",
    "plt.title(r\"5+5 Local Density Profile\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.ylabel(\"$n(x)/\\int dx n(x)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
