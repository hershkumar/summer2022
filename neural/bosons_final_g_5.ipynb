{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import trange\n",
    "import cProfile\n",
    "import pickle\n",
    "\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "\n",
    "#TODO: plot relative error against the number of parameters\n",
    "\n",
    "num_particles = 2\n",
    "N = num_particles\n",
    "# structure = [50,100,200,200,200,200,100,50]\n",
    "structure = [50,100,50]\n",
    "num_nodes = np.sum(structure)\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = .5\n",
    "sigma = -g/2\n",
    "C = 3\n",
    "FILENAME = \"2_boson_energies_-5.csv\"\n",
    "PARAMS_FILE = \"2_bosons_g-5.npy\"\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.tail_weight = 1/2\n",
    "        \n",
    "        # Initialize weights and biases for each layer\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        if hidden_sizes != [0]:\n",
    "            sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        else:\n",
    "            sizes = [input_size, output_size]\n",
    "\n",
    "        for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def transform(self, coords):\n",
    "       # if running into NaNs, try to increase this\n",
    "        ret = jnp.zeros(num_particles)\n",
    "        for i in range(num_particles):\n",
    "            ret = ret.at[i].set(jnp.sum(jnp.power(coords/C, i + 1)))\n",
    "        return ret \n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def __call__(self, x, params):\n",
    "        x = self.transform(x)\n",
    "        self.weights, self.biases, self.tail_weight = self.unflatten_params(params)\n",
    "        a = x\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = jnp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = celu(z)\n",
    "        a = jnp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        return a[0][0]\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def flatten_params(self):\n",
    "        params = jnp.array([])\n",
    "        for i in range(len(self.weights)):\n",
    "            params = jnp.concatenate((params, self.weights[i].flatten()))\n",
    "            params = jnp.concatenate((params, self.biases[i].flatten()))\n",
    "        params = jnp.append(params, self.tail_weight)\n",
    "        return jnp.array(params)\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def unflatten_params(self, params):\n",
    "        tail_weight = params[-1]\n",
    "        params = params[:-1]\n",
    "        weights = []\n",
    "        biases = []\n",
    "        start = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            end = start + self.weights[i].size\n",
    "            weights.append(jnp.reshape(jnp.array(params[start:end]), self.weights[i].shape))\n",
    "            start = end\n",
    "            end = start + self.biases[i].size\n",
    "            biases.append(jnp.reshape(jnp.array(params[start:end]), self.biases[i].shape))\n",
    "            start = end\n",
    "        return weights, biases, tail_weight\n",
    "    \n",
    "\n",
    "# initialize the network\n",
    "nn = NeuralNetwork(num_particles, structure, 1)\n",
    "\n",
    "# symmetrization transformation\n",
    "# I1 = x_1/C + x_2/C + ... + x_N/C\n",
    "# I2 = (x_1/C)^2 + (x_2/C)^2 + ... + (x_N/C)^2\n",
    "# ...\n",
    "# IN = (x_1/C)^N + (x_2/C)^N + ... + (x_N/C)^N\n",
    "\n",
    "@jit\n",
    "def A(coords, params):\n",
    "    return nn(coords, params) + omega * jnp.sum(coords**2) * params[-1]\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return jnp.exp(-A(coords, params)) \n",
    "\n",
    "# sample_body function except it also returns whether or not the move was accepted\n",
    "# @jit\n",
    "# def sample_body_accept(coords_t, params, key, variation_size):\n",
    "#     gen_rand = jax.random.uniform(key, minval=-variation_size, maxval=variation_size)\n",
    "#     new_key, subkey = jax.random.split(key)\n",
    "    \n",
    "#     coords_prime = coords_t + gen_rand\n",
    "#     r = jax.random.uniform(subkey, minval=0, maxval=1)\n",
    "#     condition = r <= psi(coords_prime, params)**2/psi(coords_t, params)**2\n",
    "#     return (jax.lax.cond(condition, lambda x, _: x, lambda _, y : y, coords_prime, coords_t), new_key, condition)\n",
    "\n",
    "\n",
    "# the sample function without any thermalization steps or skipping steps\n",
    "def accept_ratio(params, num_samples=10**3, variation_size=5.0, key=jax.random.PRNGKey(np.random.randint(0,100))):\n",
    "    coords_t = np.random.uniform(-variation_size, variation_size)\n",
    "    num_accepted = 0\n",
    "    for _ in range(num_samples):\n",
    "        coords_t, key, accepted = sample_body_accept(coords_t, params, key, variation_size)\n",
    "        if accepted:\n",
    "            num_accepted += 1\n",
    "\n",
    "    return num_accepted / num_samples\n",
    "\n",
    "\n",
    "#### New sampling function\n",
    "# def sample(params, num_samples=10**3, thermalization_steps=200, skip_count=50, variation_size=1.0):\n",
    "#     outputs = []\n",
    "#     num_accepted = 0\n",
    "#     num_total = num_samples * skip_count + thermalization_steps + 1\n",
    "#     rand_coords = np.random.uniform(-variation_size, variation_size, size=(num_total, num_particles))\n",
    "#     rand_accepts = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "#     coords_t = jnp.zeros(num_particles)\n",
    "#     for step in range(num_total):\n",
    "#         coords_t, accepted = sample_body(params, coords_t, rand_coords[step], rand_accepts[step])\n",
    "#         if accepted:\n",
    "#             num_accepted += 1\n",
    "#         if ((step > thermalization_steps) and (step % skip_count == 0)):\n",
    "#             outputs.append(coords_t)\n",
    "#     # create a second output array, where the second coordinate is equal to the first coordinate\n",
    "#     outputs_prime = outputs.copy()\n",
    "#     for i in range(len(outputs)):\n",
    "#         a = np.array(outputs[i])\n",
    "#         a[1] = a[0]\n",
    "#         outputs_prime[i] = jnp.array(a)\n",
    "#     return jnp.array(outputs), jnp.array(outputs_prime), num_accepted/num_total\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[1] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime) , counter/num_total\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def sample_body(params, coords_t, rand_coords, rand_accepts):\n",
    "    coords_prime = coords_t + rand_coords\n",
    "    return jax.lax.cond(rand_accepts < psi(coords_prime, params)**2/psi(coords_t, params)**2, lambda x,_: (x,True) , lambda _,y: (y,False), coords_prime, coords_t)\n",
    "\n",
    "\n",
    "# ----- Adapted from fermion code -----\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "    subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "    randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "    randoms = jnp.transpose(randoms)\n",
    "    subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "    limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev = val\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev\n",
    "    \n",
    "    sq, _ = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev))\n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[1].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# first derivative of the neural network with respect to the coordinates\n",
    "# in Andy's notation this is dA/dx\n",
    "dA_dx = jit(grad(A, 0)) # type: ignore\n",
    "\n",
    "# second derivative of the neural network with respect to the coordinates\n",
    "# in Andy's notation this is d^2A/dx^2\n",
    "A_hessian = jax.jacfwd(dA_dx, 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def d2A_dx2(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(A_hessian(coords, params))\n",
    "\n",
    "@jit\n",
    "def Hpsi(coords, coords_prime, params, alpha):\n",
    "    return Hpsi_without_delta(coords, params) + delta_potential(coords,coords_prime, params, alpha)\n",
    "\n",
    "@jit\n",
    "def sigma_term(coords):\n",
    "    N = num_particles \n",
    "    sigma_term = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            sigma_term += sigma* jnp.abs(coords[i] - coords[j])  \n",
    "\n",
    "@jit\n",
    "def Hpsi_without_delta(coords, params):\n",
    "   # sigma term\n",
    "    N = num_particles \n",
    "    sigma_term = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            sigma_term += sigma* jnp.abs(coords[i] - coords[j]) \n",
    "    # return jnp.sum((m*.5*omega**2*coords**2)) - hbar**2 / (2*m) * jnp.sum(ddpsi(coords, params) ) * 1/psi(coords, params) + sigma_term \n",
    "    return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + m*.5*harmonic_omega**2* jnp.sum(coords**2) + sigma_term\n",
    "    # return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2))\n",
    "    # return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + m*.5*omega**2* jnp.sum(coords**2)\n",
    "\n",
    "@jit\n",
    "def second_term(coords, params):\n",
    "    return dnn_dtheta(coords, params) * Hpsi_without_delta(coords, params)\n",
    "\n",
    "vsecond_term = jit(vmap(second_term, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def third_term(coords,coords_prime, params, y_max):\n",
    "    return dnn_dtheta(coords_prime, params) * delta_potential(coords, coords_prime, params, y_max)\n",
    "\n",
    "vthird_term = jit(vmap(third_term, in_axes=(0,0, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def delta_potential(coords, coords_prime, params, alpha):\n",
    "    N = num_particles    \n",
    "    # compute e^(-2 NN(params_prime))\n",
    "    # ratio = jnp.exp(-2 * A(coords_prime, params) + 2 * A(coords, params))\n",
    "    ratio = (psi(coords_prime, params)**2)/(psi(coords, params)**2)\n",
    "    delta_dist = (1/(jnp.sqrt(jnp.pi) * alpha)) * jnp.exp(-(coords[1]**2)/(alpha**2))\n",
    "    return g * N*(N-1)/2 * ratio * delta_dist\n",
    "\n",
    "vdelta_potential = jit(vmap(delta_potential, in_axes=(0,0, None, None), out_axes=0))\n",
    "venergy = jit(vmap(Hpsi, in_axes=(0,0, None, None), out_axes=0))\n",
    "vHpsi_without_delta = jit(vmap(Hpsi_without_delta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "# derivative of the neural network with respect to every parameter\n",
    "# in Andy's notation this is dA/dtheta\n",
    "dnn_dtheta = jit(grad(A, 1)) \n",
    "vdnn_dtheta = vmap(dnn_dtheta, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "vboth = vmap(jnp.multiply, in_axes=(0, 0), out_axes=0)\n",
    "\n",
    "def gradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False):\n",
    "    # get the samples\n",
    "    samples, samples_prime  = sample_pmap(params, num_samples, thermal, skip, variation_size, jax.random.key(int(time.time())))\n",
    "#     samples, samples_prime,_ = sample(params, num_samples, thermal, skip, variation_size, INITIAL_SAMPLE)\n",
    "\n",
    "    y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "    alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "\n",
    "    psiHpsi = venergy(samples, samples_prime, params, alpha) \n",
    "    # Hpsi_terms_without_delta = vHpsi_without_delta(samples, params)\n",
    "    # delta_term = vdelta_potential(samples,samples_prime, params, samples)\n",
    "\n",
    "    # delta function additions\n",
    "    dA_dtheta = vdnn_dtheta(samples, params)\n",
    "    # dA_dtheta_repeated = vdnn_dtheta(samples_prime, params)\n",
    "\n",
    "    dA_dtheta_avg = 1/num_samples * jnp.sum(dA_dtheta, 0)\n",
    "\n",
    "    second_term = 1/num_samples * jnp.sum(vsecond_term(samples, params), 0)\n",
    "    third_term = 1/num_samples * jnp.sum(vthird_term(samples, samples_prime, params, alpha), 0)\n",
    "    # third_term =1/num_samples * jnp.sum(vboth(dA_dtheta_repeated,delta_term), 0)\n",
    "    uncert = jnp.std(psiHpsi)/jnp.sqrt(num_samples)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(psiHpsi)\n",
    "\n",
    "   \n",
    "    if verbose:\n",
    "        print(energy)\n",
    "\n",
    "    gradient_calc = 2 * energy * dA_dtheta_avg - 2 * second_term - 2*third_term\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "def ugradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False):\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "    alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "    Es = []\n",
    "    dA_dthetas = []\n",
    "    seconds = []\n",
    "    thirds = []\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        coord = samples[i]\n",
    "        coord_prime = samples_prime[i]\n",
    "\n",
    "        Es.append(Hpsi(coord, coord_prime, params, alpha))\n",
    "        dA_dthetas.append(dnn_dtheta(coord, params)) \n",
    "        seconds.append(second_term(coord, params))\n",
    "        thirds.append(third_term(coord, coord_prime, params, alpha))\n",
    "\n",
    "\n",
    "    Es = jnp.array(Es)\n",
    "    dA_dthetas = jnp.array(dA_dthetas)\n",
    "    seconds = jnp.array(seconds)\n",
    "    thirds = jnp.array(thirds)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(Es)\n",
    "    avg_dA_dtheta = 1/num_samples * jnp.sum(dA_dthetas, 0)\n",
    "    second = 1/num_samples * jnp.sum(seconds, 0)\n",
    "    third =  1/num_samples * jnp.sum(thirds, 0)\n",
    "\n",
    "    uncert = jnp.std(Es)/jnp.sqrt(num_samples)\n",
    "    \n",
    "    gradient_calc = 2 * energy * avg_dA_dtheta - 2 * second - 2 * third\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "\n",
    "# define a function that takes in samples, bins them, and returns the average of each bin\n",
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "# define a function that gets all samples, and then bins them with different bin sizes\n",
    "def autocorrelation(params):\n",
    "    samples = sample(params, num_samples=10**3, thermalization_steps=200, skip_count=40, variation_size=1)[0]\n",
    "    energies = [Hpsi(s, params) for s in samples]\n",
    "    \n",
    "    bins = np.linspace(1, 100, 100, dtype=int)\n",
    "    # now plot the average energy as a function of the number of bins\n",
    "    us = []\n",
    "    for b_size in bins:\n",
    "        us.append(bin_samples(energies, b_size))\n",
    "    plt.scatter(bins, us)\n",
    "    plt.title(\"Bin size vs. Uncertainty\")\n",
    "    plt.xlabel(\"Bin size\")\n",
    "    plt.ylabel(\"Uncertainty\")\n",
    "    plt.show()\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size):\n",
    "        gr = gradient(params_arg, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size):\n",
    "    hs = []\n",
    "    us = []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = step(\n",
    "            old_params, step_num, N, thermal, skip, variation_size\n",
    "        )\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        # write the energy to the file\n",
    "        with open(FILENAME, mode=\"a\") as f:\n",
    "            f.write(str(energy) + \",\" + str(uncert) + \"\\n\")\n",
    "        with open(PARAMS_FILE, \"wb\") as f:\n",
    "            jnp.save(f, new_params)\n",
    "        old_params = new_params.copy()\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "\n",
    "def train_notqdm(params, iterations, N, thermal, skip, variation_size):\n",
    "    hs = []\n",
    "    us = []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in range(iterations):\n",
    "        new_params, energy, uncert = step(\n",
    "            old_params, step_num, N, thermal, skip, variation_size\n",
    "        )\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        # write the energy to the file\n",
    "        with open(FILENAME, mode=\"a\") as f:\n",
    "            f.write(str(energy) + \",\" + str(uncert) + \"\\n\")\n",
    "        with open(PARAMS_FILE, \"wb\") as f:\n",
    "            jnp.save(f, new_params)\n",
    "        old_params = new_params.copy()\n",
    "#         pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        print(str(energy))\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .05\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        it_num += 1\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "        \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    print(\"step size:\",best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters 10352\n",
      "Log of parameters 4.015024263324626\n"
     ]
    }
   ],
   "source": [
    "print(\"number of parameters\" , len(nn.flatten_params()))\n",
    "print(\"Log of parameters\", np.log10(len(nn.flatten_params())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.10566936, dtype=float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(jnp.array([0,0]),nn.flatten_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 1.2000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.9670708319678403: 100%|██████████| 20/20 [00:07<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "open(FILENAME, 'w').close()\n",
    "# start_params = nn.flatten_params()\n",
    "start_params = nn.flatten_params()\n",
    "# start_params = jnp.load(\"40_params_best.npy\", allow_pickle=True)\n",
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "\n",
    "resultsa = train(start_params, 20, 2000, 50, 5, find_step_size(start_params, .85))\n",
    "# 0 -> energies\n",
    "# 1 -> uncert\n",
    "# 2 -> steps\n",
    "# 3 -> params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsa[3][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 1.3000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.9454137893958998: 100%|██████████| 1000/1000 [36:12<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-4))\n",
    "resultsb = train(resultsa[3], 1000, 10000, 50, 10, find_step_size(resultsa[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 1.4000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.771359628690294: 100%|██████████| 100/100 [12:39<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-5))\n",
    "resultsc = train(resultsb[3], 50, 60000, 1000, 5, find_step_size(resultsb[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-6))\n",
    "resultsd = train(resultsc[3], 50, 50000, 1000, 5, find_step_size(resultsc[3], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "resultse = train(resultsd[3], 50, 10000, 1000, 5, find_step_size(resultsd[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = resultse[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value:  0.9454(15)\n",
      "Fractional percent error:  0.84(16)\n",
      "0.9454137893958998\n",
      "0.0014563504925456969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "def harmonic_energy(n):\n",
    "    return .5 + 2*n - np.sqrt(2/np.pi) * (n+1/2)/g\n",
    "\n",
    "def astra_energy():\n",
    "    return (N * omega)/2 - m * g**2  * (N*(N**2 - 1))/(24)\n",
    "\n",
    "\n",
    "# true_energy = .5 * hbar * omega * num_particles\n",
    "# true_energy = harmonic_energy(0)\n",
    "true_energy = astra_energy()\n",
    "#g = 1, sigma = -g/2\n",
    "# true_energy = .75\n",
    "# g = .1, sigma = 0:\n",
    "# true_energy = 1.03881\n",
    "# g= .8, sigma= -g\n",
    "# true_energy = .9375\n",
    "# true_energy = 0.3098\n",
    "\n",
    "total_hists =  resultsa[0]   + resultsb[0]  \n",
    "# + resultsc[0]\n",
    "# + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]  + resultsb[1] \n",
    "# + resultsc[1] \n",
    "# + resultsd[1] \n",
    "# + resultse[1]\n",
    "# + resultsd[1]\n",
    "\n",
    "# get index of minimum value\n",
    "min_val = np.min(total_hists)\n",
    "min_val = total_hists[-1]\n",
    "min_index = total_hists.index(min_val)\n",
    "min_err = total_uncerts[min_index]\n",
    "val = gv.gvar(min_val, min_err)\n",
    "fractional_error = (val - true_energy)/true_energy\n",
    "print(\"Minimum value: \", val)\n",
    "print(\"Fractional percent error: \", fractional_error * 100)\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists, label=\"Adam: \" + str(val))\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# get the network structure\n",
    "structure = nn.hidden_sizes\n",
    "plt.annotate(\" Network Structure: \" + str(structure), xy=(0.1, 0.95), xycoords='axes fraction')\n",
    "plt.plot(np.arange(0, len(total_hists)), [true_energy for x in np.arange(0, len(total_hists))], label=r\"Analytic: \" + str(round(true_energy,3)))\n",
    "pdiff = (min_val - true_energy)/true_energy*100\n",
    "# plt.annotate(\" Final Percent Diff = \" + str(round(pdiff,3)) + \"%\", xy=(.1, .9), xycoords= 'axes fraction')\n",
    "plt.legend()\n",
    "plt.title(r\"Modified LL model ($g = $\" + str(g) + r\", $\\sigma =\" + str(sigma) + \"$), \" + str(num_particles) + \" particles\")\n",
    "print(min_val)\n",
    "print(min_err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "355\n",
      "437\n",
      "438\n",
      "439\n",
      "459\n",
      "465\n",
      "481\n",
      "483\n",
      "488\n",
      "490\n",
      "494\n",
      "495\n",
      "516\n",
      "518\n",
      "522\n",
      "525\n",
      "544\n",
      "556\n",
      "559\n",
      "571\n",
      "576\n",
      "579\n",
      "583\n",
      "589\n",
      "593\n",
      "603\n",
      "604\n",
      "606\n",
      "615\n",
      "617\n",
      "636\n",
      "639\n",
      "642\n",
      "645\n",
      "647\n",
      "650\n",
      "654\n",
      "660\n",
      "669\n",
      "680\n",
      "682\n",
      "685\n",
      "690\n",
      "700\n",
      "702\n",
      "704\n",
      "709\n",
      "710\n",
      "714\n",
      "721\n",
      "723\n",
      "725\n",
      "730\n",
      "732\n",
      "735\n",
      "736\n",
      "738\n",
      "740\n",
      "741\n",
      "742\n",
      "747\n",
      "754\n",
      "756\n",
      "764\n",
      "766\n",
      "768\n",
      "770\n",
      "774\n",
      "777\n",
      "779\n",
      "784\n",
      "786\n",
      "789\n",
      "792\n",
      "799\n",
      "802\n",
      "805\n",
      "808\n",
      "810\n",
      "812\n",
      "819\n",
      "823\n",
      "824\n",
      "829\n",
      "830\n",
      "833\n",
      "834\n",
      "836\n",
      "839\n",
      "841\n",
      "844\n",
      "847\n",
      "865\n",
      "867\n",
      "869\n",
      "872\n",
      "876\n",
      "877\n",
      "878\n",
      "880\n",
      "885\n",
      "892\n",
      "895\n",
      "897\n",
      "898\n",
      "903\n",
      "907\n",
      "912\n",
      "913\n",
      "914\n",
      "921\n",
      "922\n",
      "925\n",
      "926\n",
      "928\n",
      "934\n",
      "935\n",
      "936\n",
      "941\n",
      "943\n",
      "944\n",
      "945\n",
      "948\n",
      "950\n",
      "951\n",
      "952\n",
      "956\n",
      "960\n",
      "962\n",
      "964\n",
      "972\n",
      "973\n",
      "974\n",
      "977\n",
      "979\n",
      "981\n",
      "982\n",
      "986\n",
      "988\n",
      "991\n",
      "992\n",
      "994\n",
      "995\n",
      "996\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1010\n",
      "1013\n",
      "1018\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "#finding the first step that has below 1% error\n",
    "for stepnum in range(len(total_hists)):\n",
    "    energy = total_hists[stepnum]\n",
    "    pdiff = (energy - true_energy)/true_energy * 100\n",
    "    if pdiff <= 1:\n",
    "        print(stepnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-261d663b85f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "samples, samples_prime, _ = sample(params, 4*10**4, 100, 10, 1)\n",
    "y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "energies = venergy(samples,samples_prime, params, alpha)\n",
    "mean_energy = jnp.mean(energies)\n",
    "print(mean_energy)\n",
    "\n",
    "# bins = np.linspace(1, 100, 100, dtype=int)\n",
    "bins = np.array([1,2,5,10,20,50,100,150,200,250,300,360,450,500,550,600,660,750,900,990,1100])\n",
    "# now plot the average energy as a function of the number of bins\n",
    "us = []\n",
    "for b_size in bins:\n",
    "    us.append(bin_samples(energies, b_size))\n",
    "plt.scatter(bins, us)\n",
    "plt.title(\"Bin size vs. Uncertainty\")\n",
    "plt.xlabel(\"Bin size\")\n",
    "plt.ylabel(\"Uncertainty\")\n",
    "print(max(us))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = gv.gvar(mean_energy, max(us))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(-5, 5, .05)\n",
    "ys = np.arange(-5, 5, .05)\n",
    "wavs = []\n",
    "for i in range(len(xs)):\n",
    "    for j in range(len(ys)):\n",
    "        wavs.append(psi(np.array([xs[i], ys[j]]), params)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(xs,ys)\n",
    "Z = np.array(wavs).reshape(len(xs), len(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.contourf(X, Y, Z, 100)\n",
    "\n",
    "plt.plot(xs,-xs)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def astra_wf(coords):\n",
    "    ret = 1\n",
    "    a_s = -2/(m*g) \n",
    "    a_ho = jnp.sqrt(1/(m * harmonic_omega))\n",
    "    for i in range(N):\n",
    "        for j in range(0,i):\n",
    "            ret *= jnp.exp(-jnp.abs(coords[i] - coords[j])/a_s)\n",
    "        ret *= jnp.exp(-coords[i]**2/(2*a_ho**2))\n",
    "    return ret\n",
    "\n",
    "@jit\n",
    "def mcstep_E_exact(xis, limit, positions):\n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = astra_wf(newpositions)**2 / astra_wf(positions)**2\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample_exact(Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E_exact(randoms[i], limits[i], positions_prev)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E_exact(randoms[i], limits[i], positions_prev)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[1] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(params, 3 * 10**4, 100, 10, .85)\n",
    "samples_exact = sample_exact(3 * 10**4, 100, 10, .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_density(samples):\n",
    "    x_bins = np.linspace(-9, 9, 72)\n",
    "    dx = x_bins[1] - x_bins[0]  # Bin width\n",
    "    n_x = np.zeros_like(x_bins)\n",
    "\n",
    "    # bin the x_1s\n",
    "    for x in samples[0][:,0]:\n",
    "        n_x[np.digitize(x, x_bins)] += 1\n",
    "\n",
    "    # Normalize\n",
    "    n_x /= (dx * np.sum(n_x))\n",
    "\n",
    "    return x_bins, n_x\n",
    "\n",
    "x_bins, n_x = local_density(samples)\n",
    "x_bins_exact, n_x_exact = local_density(samples_exact)\n",
    "plt.plot(x_bins, n_x,'-o', markersize=2, color=\"red\")\n",
    "plt.plot(x_bins_exact, n_x_exact,'-o', markersize=2, color=\"black\")\n",
    "plt.title(r\"$N = 2$ Local Density Profile\")\n",
    "plt.xlabel(\"$x$\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.ylabel(\"$n(x)/\\int dx n(x)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
