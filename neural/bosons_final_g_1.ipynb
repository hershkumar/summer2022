{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import trange\n",
    "import cProfile\n",
    "import pickle\n",
    "\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "\n",
    "#TODO: plot relative error against the number of parameters\n",
    "\n",
    "num_particles = 2\n",
    "N = num_particles\n",
    "# structure = [50,100,200,200,200,200,100,50]\n",
    "structure = [100,150,100]\n",
    "num_nodes = np.sum(structure)\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = 1\n",
    "sigma = -g/2\n",
    "C = 3\n",
    "FILENAME = \"2_boson_energies_-5.csv\"\n",
    "PARAMS_FILE = \"2_bosons_g-5.npy\"\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.tail_weight = 1/2\n",
    "        \n",
    "        # Initialize weights and biases for each layer\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        if hidden_sizes != [0]:\n",
    "            sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        else:\n",
    "            sizes = [input_size, output_size]\n",
    "\n",
    "        for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def transform(self, coords):\n",
    "       # if running into NaNs, try to increase this\n",
    "        ret = jnp.zeros(num_particles)\n",
    "        for i in range(num_particles):\n",
    "            ret = ret.at[i].set(jnp.sum(jnp.power(coords/C, i + 1)))\n",
    "        return ret \n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def __call__(self, x, params):\n",
    "        x = self.transform(x)\n",
    "        self.weights, self.biases, self.tail_weight = self.unflatten_params(params)\n",
    "        a = x\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = jnp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = celu(z)\n",
    "        a = jnp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        return a[0][0]\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def flatten_params(self):\n",
    "        params = jnp.array([])\n",
    "        for i in range(len(self.weights)):\n",
    "            params = jnp.concatenate((params, self.weights[i].flatten()))\n",
    "            params = jnp.concatenate((params, self.biases[i].flatten()))\n",
    "        params = jnp.append(params, self.tail_weight)\n",
    "        return jnp.array(params)\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def unflatten_params(self, params):\n",
    "        tail_weight = params[-1]\n",
    "        params = params[:-1]\n",
    "        weights = []\n",
    "        biases = []\n",
    "        start = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            end = start + self.weights[i].size\n",
    "            weights.append(jnp.reshape(jnp.array(params[start:end]), self.weights[i].shape))\n",
    "            start = end\n",
    "            end = start + self.biases[i].size\n",
    "            biases.append(jnp.reshape(jnp.array(params[start:end]), self.biases[i].shape))\n",
    "            start = end\n",
    "        return weights, biases, tail_weight\n",
    "    \n",
    "\n",
    "# initialize the network\n",
    "nn = NeuralNetwork(num_particles, structure, 1)\n",
    "\n",
    "# symmetrization transformation\n",
    "# I1 = x_1/C + x_2/C + ... + x_N/C\n",
    "# I2 = (x_1/C)^2 + (x_2/C)^2 + ... + (x_N/C)^2\n",
    "# ...\n",
    "# IN = (x_1/C)^N + (x_2/C)^N + ... + (x_N/C)^N\n",
    "\n",
    "@jit\n",
    "def A(coords, params):\n",
    "    return nn(coords, params) + omega * jnp.sum(coords**2) * params[-1]\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return jnp.exp(-A(coords, params)) \n",
    "\n",
    "# sample_body function except it also returns whether or not the move was accepted\n",
    "# @jit\n",
    "# def sample_body_accept(coords_t, params, key, variation_size):\n",
    "#     gen_rand = jax.random.uniform(key, minval=-variation_size, maxval=variation_size)\n",
    "#     new_key, subkey = jax.random.split(key)\n",
    "    \n",
    "#     coords_prime = coords_t + gen_rand\n",
    "#     r = jax.random.uniform(subkey, minval=0, maxval=1)\n",
    "#     condition = r <= psi(coords_prime, params)**2/psi(coords_t, params)**2\n",
    "#     return (jax.lax.cond(condition, lambda x, _: x, lambda _, y : y, coords_prime, coords_t), new_key, condition)\n",
    "\n",
    "\n",
    "# the sample function without any thermalization steps or skipping steps\n",
    "def accept_ratio(params, num_samples=10**3, variation_size=5.0, key=jax.random.PRNGKey(np.random.randint(0,100))):\n",
    "    coords_t = np.random.uniform(-variation_size, variation_size)\n",
    "    num_accepted = 0\n",
    "    for _ in range(num_samples):\n",
    "        coords_t, key, accepted = sample_body_accept(coords_t, params, key, variation_size)\n",
    "        if accepted:\n",
    "            num_accepted += 1\n",
    "\n",
    "    return num_accepted / num_samples\n",
    "\n",
    "\n",
    "#### New sampling function\n",
    "# def sample(params, num_samples=10**3, thermalization_steps=200, skip_count=50, variation_size=1.0):\n",
    "#     outputs = []\n",
    "#     num_accepted = 0\n",
    "#     num_total = num_samples * skip_count + thermalization_steps + 1\n",
    "#     rand_coords = np.random.uniform(-variation_size, variation_size, size=(num_total, num_particles))\n",
    "#     rand_accepts = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "#     coords_t = jnp.zeros(num_particles)\n",
    "#     for step in range(num_total):\n",
    "#         coords_t, accepted = sample_body(params, coords_t, rand_coords[step], rand_accepts[step])\n",
    "#         if accepted:\n",
    "#             num_accepted += 1\n",
    "#         if ((step > thermalization_steps) and (step % skip_count == 0)):\n",
    "#             outputs.append(coords_t)\n",
    "#     # create a second output array, where the second coordinate is equal to the first coordinate\n",
    "#     outputs_prime = outputs.copy()\n",
    "#     for i in range(len(outputs)):\n",
    "#         a = np.array(outputs[i])\n",
    "#         a[1] = a[0]\n",
    "#         outputs_prime[i] = jnp.array(a)\n",
    "#     return jnp.array(outputs), jnp.array(outputs_prime), num_accepted/num_total\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[1] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime) , counter/num_total\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def sample_body(params, coords_t, rand_coords, rand_accepts):\n",
    "    coords_prime = coords_t + rand_coords\n",
    "    return jax.lax.cond(rand_accepts < psi(coords_prime, params)**2/psi(coords_t, params)**2, lambda x,_: (x,True) , lambda _,y: (y,False), coords_prime, coords_t)\n",
    "\n",
    "\n",
    "# ----- Adapted from fermion code -----\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "    subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "    randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "    randoms = jnp.transpose(randoms)\n",
    "    subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "    limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev = val\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev\n",
    "    \n",
    "    sq, _ = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev))\n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[1].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# first derivative of the neural network with respect to the coordinates\n",
    "# in Andy's notation this is dA/dx\n",
    "dA_dx = jit(grad(A, 0)) # type: ignore\n",
    "\n",
    "# second derivative of the neural network with respect to the coordinates\n",
    "# in Andy's notation this is d^2A/dx^2\n",
    "A_hessian = jax.jacfwd(dA_dx, 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def d2A_dx2(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(A_hessian(coords, params))\n",
    "\n",
    "@jit\n",
    "def Hpsi(coords, coords_prime, params, alpha):\n",
    "    return Hpsi_without_delta(coords, params) + delta_potential(coords,coords_prime, params, alpha)\n",
    "\n",
    "@jit\n",
    "def sigma_term(coords):\n",
    "    N = num_particles \n",
    "    sigma_term = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            sigma_term += sigma* jnp.abs(coords[i] - coords[j])  \n",
    "\n",
    "@jit\n",
    "def Hpsi_without_delta(coords, params):\n",
    "   # sigma term\n",
    "    N = num_particles \n",
    "    sigma_term = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            sigma_term += sigma* jnp.abs(coords[i] - coords[j]) \n",
    "    # return jnp.sum((m*.5*omega**2*coords**2)) - hbar**2 / (2*m) * jnp.sum(ddpsi(coords, params) ) * 1/psi(coords, params) + sigma_term \n",
    "    return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + m*.5*harmonic_omega**2* jnp.sum(coords**2) + sigma_term\n",
    "    # return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2))\n",
    "    # return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + m*.5*omega**2* jnp.sum(coords**2)\n",
    "\n",
    "@jit\n",
    "def second_term(coords, params):\n",
    "    return dnn_dtheta(coords, params) * Hpsi_without_delta(coords, params)\n",
    "\n",
    "vsecond_term = jit(vmap(second_term, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def third_term(coords,coords_prime, params, y_max):\n",
    "    return dnn_dtheta(coords_prime, params) * delta_potential(coords, coords_prime, params, y_max)\n",
    "\n",
    "vthird_term = jit(vmap(third_term, in_axes=(0,0, None, None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def delta_potential(coords, coords_prime, params, alpha):\n",
    "    N = num_particles    \n",
    "    # compute e^(-2 NN(params_prime))\n",
    "    # ratio = jnp.exp(-2 * A(coords_prime, params) + 2 * A(coords, params))\n",
    "    ratio = (psi(coords_prime, params)**2)/(psi(coords, params)**2)\n",
    "    delta_dist = (1/(jnp.sqrt(jnp.pi) * alpha)) * jnp.exp(-(coords[1]**2)/(alpha**2))\n",
    "    return g * N*(N-1)/2 * ratio * delta_dist\n",
    "\n",
    "vdelta_potential = jit(vmap(delta_potential, in_axes=(0,0, None, None), out_axes=0))\n",
    "venergy = jit(vmap(Hpsi, in_axes=(0,0, None, None), out_axes=0))\n",
    "vHpsi_without_delta = jit(vmap(Hpsi_without_delta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "# derivative of the neural network with respect to every parameter\n",
    "# in Andy's notation this is dA/dtheta\n",
    "dnn_dtheta = jit(grad(A, 1)) \n",
    "vdnn_dtheta = vmap(dnn_dtheta, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "vboth = vmap(jnp.multiply, in_axes=(0, 0), out_axes=0)\n",
    "\n",
    "def gradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False):\n",
    "    # get the samples\n",
    "    samples, samples_prime  = sample_pmap(params, num_samples, thermal, skip, variation_size, jax.random.key(int(time.time())))\n",
    "#     samples, samples_prime,_ = sample(params, num_samples, thermal, skip, variation_size, INITIAL_SAMPLE)\n",
    "\n",
    "    y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "    alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "\n",
    "    psiHpsi = venergy(samples, samples_prime, params, alpha) \n",
    "    # Hpsi_terms_without_delta = vHpsi_without_delta(samples, params)\n",
    "    # delta_term = vdelta_potential(samples,samples_prime, params, samples)\n",
    "\n",
    "    # delta function additions\n",
    "    dA_dtheta = vdnn_dtheta(samples, params)\n",
    "    # dA_dtheta_repeated = vdnn_dtheta(samples_prime, params)\n",
    "\n",
    "    dA_dtheta_avg = 1/num_samples * jnp.sum(dA_dtheta, 0)\n",
    "\n",
    "    second_term = 1/num_samples * jnp.sum(vsecond_term(samples, params), 0)\n",
    "    third_term = 1/num_samples * jnp.sum(vthird_term(samples, samples_prime, params, alpha), 0)\n",
    "    # third_term =1/num_samples * jnp.sum(vboth(dA_dtheta_repeated,delta_term), 0)\n",
    "    uncert = jnp.std(psiHpsi)/jnp.sqrt(num_samples)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(psiHpsi)\n",
    "\n",
    "   \n",
    "    if verbose:\n",
    "        print(energy)\n",
    "\n",
    "    gradient_calc = 2 * energy * dA_dtheta_avg - 2 * second_term - 2*third_term\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "def ugradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False):\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "    alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "    Es = []\n",
    "    dA_dthetas = []\n",
    "    seconds = []\n",
    "    thirds = []\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        coord = samples[i]\n",
    "        coord_prime = samples_prime[i]\n",
    "\n",
    "        Es.append(Hpsi(coord, coord_prime, params, alpha))\n",
    "        dA_dthetas.append(dnn_dtheta(coord, params)) \n",
    "        seconds.append(second_term(coord, params))\n",
    "        thirds.append(third_term(coord, coord_prime, params, alpha))\n",
    "\n",
    "\n",
    "    Es = jnp.array(Es)\n",
    "    dA_dthetas = jnp.array(dA_dthetas)\n",
    "    seconds = jnp.array(seconds)\n",
    "    thirds = jnp.array(thirds)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(Es)\n",
    "    avg_dA_dtheta = 1/num_samples * jnp.sum(dA_dthetas, 0)\n",
    "    second = 1/num_samples * jnp.sum(seconds, 0)\n",
    "    third =  1/num_samples * jnp.sum(thirds, 0)\n",
    "\n",
    "    uncert = jnp.std(Es)/jnp.sqrt(num_samples)\n",
    "    \n",
    "    gradient_calc = 2 * energy * avg_dA_dtheta - 2 * second - 2 * third\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "\n",
    "# define a function that takes in samples, bins them, and returns the average of each bin\n",
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "# define a function that gets all samples, and then bins them with different bin sizes\n",
    "def autocorrelation(params):\n",
    "    samples = sample(params, num_samples=10**3, thermalization_steps=200, skip_count=40, variation_size=1)[0]\n",
    "    energies = [Hpsi(s, params) for s in samples]\n",
    "    \n",
    "    bins = np.linspace(1, 100, 100, dtype=int)\n",
    "    # now plot the average energy as a function of the number of bins\n",
    "    us = []\n",
    "    for b_size in bins:\n",
    "        us.append(bin_samples(energies, b_size))\n",
    "    plt.scatter(bins, us)\n",
    "    plt.title(\"Bin size vs. Uncertainty\")\n",
    "    plt.xlabel(\"Bin size\")\n",
    "    plt.ylabel(\"Uncertainty\")\n",
    "    plt.show()\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size):\n",
    "        gr = gradient(params_arg, N, thermal, skip, variation_size)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size):\n",
    "    hs = []\n",
    "    us = []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = step(\n",
    "            old_params, step_num, N, thermal, skip, variation_size\n",
    "        )\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        # write the energy to the file\n",
    "        with open(FILENAME, mode=\"a\") as f:\n",
    "            f.write(str(energy) + \",\" + str(uncert) + \"\\n\")\n",
    "        with open(PARAMS_FILE, \"wb\") as f:\n",
    "            jnp.save(f, new_params)\n",
    "        old_params = new_params.copy()\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "\n",
    "def train_notqdm(params, iterations, N, thermal, skip, variation_size):\n",
    "    hs = []\n",
    "    us = []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in range(iterations):\n",
    "        new_params, energy, uncert = step(\n",
    "            old_params, step_num, N, thermal, skip, variation_size\n",
    "        )\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        # write the energy to the file\n",
    "        with open(FILENAME, mode=\"a\") as f:\n",
    "            f.write(str(energy) + \",\" + str(uncert) + \"\\n\")\n",
    "        with open(PARAMS_FILE, \"wb\") as f:\n",
    "            jnp.save(f, new_params)\n",
    "        old_params = new_params.copy()\n",
    "#         pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        print(str(energy))\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .05\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        it_num += 1\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "        \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    print(\"step size:\",best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters 30652\n",
      "Log of parameters 4.486458816884649\n"
     ]
    }
   ],
   "source": [
    "print(\"number of parameters\" , len(nn.flatten_params()))\n",
    "print(\"Log of parameters\", np.log10(len(nn.flatten_params())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(98.66854384, dtype=float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(jnp.array([0,0]),nn.flatten_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.8160945151794727: 100%|██████████| 40/40 [00:34<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "open(FILENAME, 'w').close()\n",
    "# start_params = nn.flatten_params()\n",
    "start_params = nn.flatten_params()\n",
    "# start_params = jnp.load(\"40_params_best.npy\", allow_pickle=True)\n",
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "\n",
    "resultsa = train(start_params, 40, 2000, 50, 5, find_step_size(start_params, .85))\n",
    "# 0 -> energies\n",
    "# 1 -> uncert\n",
    "# 2 -> steps\n",
    "# 3 -> params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsa[3][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 1.3500000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.7899097714847362:  45%|████▌     | 225/500 [1:16:42<1:33:36, 20.42s/it]"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-5))\n",
    "resultsb = train(resultsa[3], 500, 60000, 50, 5, find_step_size(resultsa[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 1.4000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.771359628690294: 100%|██████████| 100/100 [12:39<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-5))\n",
    "resultsc = train(resultsb[3], 50, 60000, 1000, 5, find_step_size(resultsb[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-6))\n",
    "resultsd = train(resultsc[3], 50, 50000, 1000, 5, find_step_size(resultsc[3], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "resultse = train(resultsd[3], 50, 10000, 1000, 5, find_step_size(resultsd[3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = resultse[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value:  0.77983(78)\n",
      "Fractional percent error:  3.98(10)\n",
      "0.7798255640389163\n",
      "0.0007771076781336534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "def harmonic_energy(n):\n",
    "    return .5 + 2*n - np.sqrt(2/np.pi) * (n+1/2)/g\n",
    "\n",
    "def astra_energy():\n",
    "    return (N * omega)/2 - m * g**2  * (N*(N**2 - 1))/(24)\n",
    "\n",
    "\n",
    "# true_energy = .5 * hbar * omega * num_particles\n",
    "# true_energy = harmonic_energy(0)\n",
    "true_energy = astra_energy()\n",
    "#g = 1, sigma = -g/2\n",
    "# true_energy = .75\n",
    "# g = .1, sigma = 0:\n",
    "# true_energy = 1.03881\n",
    "# g= .8, sigma= -g\n",
    "# true_energy = .9375\n",
    "# true_energy = 0.3098\n",
    "\n",
    "total_hists =  resultsa[0] + resultsb[0]  \n",
    "# + resultsc[0]\n",
    "# + resultsd[0] \n",
    "# + resultse[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1]+ resultsb[1] \n",
    "# + resultsc[1] \n",
    "# + resultsd[1] \n",
    "# + resultse[1]\n",
    "# + resultsd[1]\n",
    "\n",
    "# get index of minimum value\n",
    "min_val = np.min(total_hists)\n",
    "min_val = total_hists[-1]\n",
    "min_index = total_hists.index(min_val)\n",
    "min_err = total_uncerts[min_index]\n",
    "val = gv.gvar(min_val, min_err)\n",
    "fractional_error = (val - true_energy)/true_energy\n",
    "print(\"Minimum value: \", val)\n",
    "print(\"Fractional percent error: \", fractional_error * 100)\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists, label=\"Adam: \" + str(val))\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# get the network structure\n",
    "structure = nn.hidden_sizes\n",
    "plt.annotate(\" Network Structure: \" + str(structure), xy=(0.1, 0.95), xycoords='axes fraction')\n",
    "plt.plot(np.arange(0, len(total_hists)), [true_energy for x in np.arange(0, len(total_hists))], label=r\"Analytic: \" + str(round(true_energy,3)))\n",
    "pdiff = (min_val - true_energy)/true_energy*100\n",
    "# plt.annotate(\" Final Percent Diff = \" + str(round(pdiff,3)) + \"%\", xy=(.1, .9), xycoords= 'axes fraction')\n",
    "plt.legend()\n",
    "plt.title(r\"Modified LL model ($g = $\" + str(g) + r\", $\\sigma =\" + str(sigma) + \"$), \" + str(num_particles) + \" particles\")\n",
    "print(min_val)\n",
    "print(min_err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the first step that has below 1% error\n",
    "for stepnum in range(len(total_hists)):\n",
    "    energy = total_hists[stepnum]\n",
    "    pdiff = (energy - true_energy)/true_energy * 100\n",
    "    if pdiff <= 1:\n",
    "        print(stepnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-261d663b85f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "samples, samples_prime, _ = sample(params, 4*10**4, 100, 10, 1)\n",
    "y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "energies = venergy(samples,samples_prime, params, alpha)\n",
    "mean_energy = jnp.mean(energies)\n",
    "print(mean_energy)\n",
    "\n",
    "# bins = np.linspace(1, 100, 100, dtype=int)\n",
    "bins = np.array([1,2,5,10,20,50,100,150,200,250,300,360,450,500,550,600,660,750,900,990,1100])\n",
    "# now plot the average energy as a function of the number of bins\n",
    "us = []\n",
    "for b_size in bins:\n",
    "    us.append(bin_samples(energies, b_size))\n",
    "plt.scatter(bins, us)\n",
    "plt.title(\"Bin size vs. Uncertainty\")\n",
    "plt.xlabel(\"Bin size\")\n",
    "plt.ylabel(\"Uncertainty\")\n",
    "print(max(us))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = gv.gvar(mean_energy, max(us))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(-5, 5, .05)\n",
    "ys = np.arange(-5, 5, .05)\n",
    "wavs = []\n",
    "for i in range(len(xs)):\n",
    "    for j in range(len(ys)):\n",
    "        wavs.append(psi(np.array([xs[i], ys[j]]), params)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(xs,ys)\n",
    "Z = np.array(wavs).reshape(len(xs), len(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.contourf(X, Y, Z, 100)\n",
    "\n",
    "plt.plot(xs,-xs)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def astra_wf(coords):\n",
    "    ret = 1\n",
    "    a_s = -2/(m*g) \n",
    "    a_ho = jnp.sqrt(1/(m * harmonic_omega))\n",
    "    for i in range(N):\n",
    "        for j in range(0,i):\n",
    "            ret *= jnp.exp(-jnp.abs(coords[i] - coords[j])/a_s)\n",
    "        ret *= jnp.exp(-coords[i]**2/(2*a_ho**2))\n",
    "    return ret\n",
    "\n",
    "@jit\n",
    "def mcstep_E_exact(xis, limit, positions):\n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = astra_wf(newpositions)**2 / astra_wf(positions)**2\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample_exact(Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E_exact(randoms[i], limits[i], positions_prev)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E_exact(randoms[i], limits[i], positions_prev)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[1] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(params, 3 * 10**4, 100, 10, .85)\n",
    "samples_exact = sample_exact(3 * 10**4, 100, 10, .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_density(samples):\n",
    "    x_bins = np.linspace(-9, 9, 72)\n",
    "    dx = x_bins[1] - x_bins[0]  # Bin width\n",
    "    n_x = np.zeros_like(x_bins)\n",
    "\n",
    "    # bin the x_1s\n",
    "    for x in samples[0][:,0]:\n",
    "        n_x[np.digitize(x, x_bins)] += 1\n",
    "\n",
    "    # Normalize\n",
    "    n_x /= (dx * np.sum(n_x))\n",
    "\n",
    "    return x_bins, n_x\n",
    "\n",
    "x_bins, n_x = local_density(samples)\n",
    "x_bins_exact, n_x_exact = local_density(samples_exact)\n",
    "plt.plot(x_bins, n_x,'-o', markersize=2, color=\"red\")\n",
    "plt.plot(x_bins_exact, n_x_exact,'-o', markersize=2, color=\"black\")\n",
    "plt.title(r\"$N = 2$ Local Density Profile\")\n",
    "plt.xlabel(\"$x$\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.ylabel(\"$n(x)/\\int dx n(x)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
