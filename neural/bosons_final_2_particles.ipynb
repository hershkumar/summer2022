{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"True\"\n",
    "import multiprocessing\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count={}\".format(\n",
    "    multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import grad, hessian, jit, vmap\n",
    "from jax.nn import celu\n",
    "import gvar as gv\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "from tqdm import trange\n",
    "import cProfile\n",
    "import pickle\n",
    "\n",
    "\n",
    "# set the default device to the cpu\n",
    "jax.default_device(jax.devices(\"cpu\")[0])\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "\n",
    "#TODO: plot relative error against the number of parameters\n",
    "\n",
    "num_particles = 2\n",
    "N = num_particles\n",
    "# structure = [50,100,200,200,200,200,100,50]\n",
    "structure = [25,50,25]\n",
    "num_nodes = np.sum(structure)\n",
    "m = 1\n",
    "hbar = 1\n",
    "omega = 1\n",
    "harmonic_omega = 1\n",
    "g = .5\n",
    "sigma = -g/2\n",
    "C = 3\n",
    "FILENAME = \"2_boson_energies_-5.csv\"\n",
    "PARAMS_FILE = \"2_bosons_g-5.npy\"\n",
    "\n",
    "INITIAL_SAMPLE = jnp.array(np.random.uniform(-2, 2, N))\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.tail_weight = 1/2\n",
    "        \n",
    "        # Initialize weights and biases for each layer\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        if hidden_sizes != [0]:\n",
    "            sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        else:\n",
    "            sizes = [input_size, output_size]\n",
    "\n",
    "        for i in range(len(sizes) - 1):\n",
    "            w = np.random.randn(sizes[i], sizes[i+1]) * np.sqrt(2/sizes[i])\n",
    "            b = np.random.randn(1, sizes[i+1]) \n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def transform(self, coords):\n",
    "       # if running into NaNs, try to increase this\n",
    "        ret = jnp.zeros(num_particles)\n",
    "        for i in range(num_particles):\n",
    "            ret = ret.at[i].set(jnp.sum(jnp.power(coords/C, i + 1)))\n",
    "        return ret \n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def __call__(self, x, params):\n",
    "        x = self.transform(x)\n",
    "        self.weights, self.biases, self.tail_weight = self.unflatten_params(params)\n",
    "        a = x\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = jnp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = celu(z)\n",
    "        a = jnp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        return a[0][0]\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def flatten_params(self):\n",
    "        params = jnp.array([])\n",
    "        for i in range(len(self.weights)):\n",
    "            params = jnp.concatenate((params, self.weights[i].flatten()))\n",
    "            params = jnp.concatenate((params, self.biases[i].flatten()))\n",
    "        params = jnp.append(params, self.tail_weight)\n",
    "        return jnp.array(params)\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def unflatten_params(self, params):\n",
    "        tail_weight = params[-1]\n",
    "        params = params[:-1]\n",
    "        weights = []\n",
    "        biases = []\n",
    "        start = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            end = start + self.weights[i].size\n",
    "            weights.append(jnp.reshape(jnp.array(params[start:end]), self.weights[i].shape))\n",
    "            start = end\n",
    "            end = start + self.biases[i].size\n",
    "            biases.append(jnp.reshape(jnp.array(params[start:end]), self.biases[i].shape))\n",
    "            start = end\n",
    "        return weights, biases, tail_weight\n",
    "    \n",
    "\n",
    "# initialize the network\n",
    "nn = NeuralNetwork(num_particles, structure, 1)\n",
    "\n",
    "# symmetrization transformation\n",
    "# I1 = x_1/C + x_2/C + ... + x_N/C\n",
    "# I2 = (x_1/C)^2 + (x_2/C)^2 + ... + (x_N/C)^2\n",
    "# ...\n",
    "# IN = (x_1/C)^N + (x_2/C)^N + ... + (x_N/C)^N\n",
    "\n",
    "@jit\n",
    "def A(coords, params):\n",
    "    return nn(coords, params) + omega * jnp.sum(coords**2) * params[-1]\n",
    "\n",
    "@jit\n",
    "def psi(coords, params):\n",
    "    return jnp.exp(-A(coords, params)) \n",
    "\n",
    "# sample_body function except it also returns whether or not the move was accepted\n",
    "# @jit\n",
    "# def sample_body_accept(coords_t, params, key, variation_size):\n",
    "#     gen_rand = jax.random.uniform(key, minval=-variation_size, maxval=variation_size)\n",
    "#     new_key, subkey = jax.random.split(key)\n",
    "    \n",
    "#     coords_prime = coords_t + gen_rand\n",
    "#     r = jax.random.uniform(subkey, minval=0, maxval=1)\n",
    "#     condition = r <= psi(coords_prime, params)**2/psi(coords_t, params)**2\n",
    "#     return (jax.lax.cond(condition, lambda x, _: x, lambda _, y : y, coords_prime, coords_t), new_key, condition)\n",
    "\n",
    "\n",
    "# the sample function without any thermalization steps or skipping steps\n",
    "def accept_ratio(params, num_samples=10**3, variation_size=5.0, key=jax.random.PRNGKey(np.random.randint(0,100))):\n",
    "    coords_t = np.random.uniform(-variation_size, variation_size)\n",
    "    num_accepted = 0\n",
    "    for _ in range(num_samples):\n",
    "        coords_t, key, accepted = sample_body_accept(coords_t, params, key, variation_size)\n",
    "        if accepted:\n",
    "            num_accepted += 1\n",
    "\n",
    "    return num_accepted / num_samples\n",
    "\n",
    "\n",
    "#### New sampling function\n",
    "# def sample(params, num_samples=10**3, thermalization_steps=200, skip_count=50, variation_size=1.0):\n",
    "#     outputs = []\n",
    "#     num_accepted = 0\n",
    "#     num_total = num_samples * skip_count + thermalization_steps + 1\n",
    "#     rand_coords = np.random.uniform(-variation_size, variation_size, size=(num_total, num_particles))\n",
    "#     rand_accepts = np.random.uniform(0, 1, size=num_total)\n",
    "\n",
    "#     coords_t = jnp.zeros(num_particles)\n",
    "#     for step in range(num_total):\n",
    "#         coords_t, accepted = sample_body(params, coords_t, rand_coords[step], rand_accepts[step])\n",
    "#         if accepted:\n",
    "#             num_accepted += 1\n",
    "#         if ((step > thermalization_steps) and (step % skip_count == 0)):\n",
    "#             outputs.append(coords_t)\n",
    "#     # create a second output array, where the second coordinate is equal to the first coordinate\n",
    "#     outputs_prime = outputs.copy()\n",
    "#     for i in range(len(outputs)):\n",
    "#         a = np.array(outputs[i])\n",
    "#         a[1] = a[0]\n",
    "#         outputs_prime[i] = jnp.array(a)\n",
    "#     return jnp.array(outputs), jnp.array(outputs_prime), num_accepted/num_total\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcstep_E(xis, limit, positions, params):\n",
    "    \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "    \n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = psi(newpositions, params)**2./psi(positions, params)**2.\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample(params, Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    params = jax.device_put(params, device=jax.devices(\"cpu\")[0])\n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[1] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime) , counter/num_total\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def sample_body(params, coords_t, rand_coords, rand_accepts):\n",
    "    coords_prime = coords_t + rand_coords\n",
    "    return jax.lax.cond(rand_accepts < psi(coords_prime, params)**2/psi(coords_t, params)**2, lambda x,_: (x,True) , lambda _,y: (y,False), coords_prime, coords_t)\n",
    "\n",
    "\n",
    "# ----- Adapted from fermion code -----\n",
    "@partial(jit, static_argnums=(1,2,3,4))\n",
    "def sample_pmap(params, Nsweeps, Ntherm, keep, stepsize, key, positions_initial=INITIAL_SAMPLE):\n",
    "\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "    sq = jnp.empty((Nsweeps+1, N))\n",
    "    sq_prime = jnp.empty((Nsweeps+1, N))\n",
    "    \n",
    "    # How many keys do we need?\n",
    "    subkeys = jax.random.split(key, N)\n",
    "    # key, shape, datatype, then bounds\n",
    "    randoms = vmap(jax.random.uniform, in_axes=(0,None,None, None,None))(subkeys,(num_total,), jnp.float32,-stepsize, stepsize)\n",
    "    randoms = jnp.transpose(randoms)\n",
    "    subkeys = jax.random.split(subkeys[-1], num_total)\n",
    "    limits = vmap(jax.random.uniform, in_axes=(0,None, None, None, None))(subkeys,(), jnp.float32,0.0,1.0)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    \n",
    "    def true_fun(sq, new, i):\n",
    "        return sq.at[(i - Ntherm)//keep].set(new)\n",
    "    def false_fun(sq, new, i):\n",
    "        return sq\n",
    "    \n",
    "    def body_fun(i, val):\n",
    "        # unpack val\n",
    "        sq, positions_prev = val\n",
    "        new, moved = mcstep_E(randoms[i], limits[i], positions_prev, params)\n",
    "        sq = jax.lax.cond(jnp.logical_and(jnp.mod(i, keep) == 0,i >= Ntherm), true_fun, false_fun, sq, new, i)\n",
    "        positions_prev = new\n",
    "        return sq, positions_prev\n",
    "    \n",
    "    sq, _ = jax.lax.fori_loop(0, num_total, body_fun, (sq, positions_prev))\n",
    "\n",
    "    def set_prime(a):\n",
    "        # Set sample[N_up] = sample[0] for each sample\n",
    "        return a.at[1].set(a[0])\n",
    "\n",
    "    # Apply the `set_prime` function to every sample in `sq` using vmap\n",
    "    sq_prime = jax.vmap(set_prime)(sq)\n",
    "        \n",
    "    return jnp.array(sq), jnp.array(sq_prime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# first derivative of the neural network with respect to the coordinates\n",
    "# in Andy's notation this is dA/dx\n",
    "dA_dx = jit(grad(A, 0)) # type: ignore\n",
    "\n",
    "# second derivative of the neural network with respect to the coordinates\n",
    "# in Andy's notation this is d^2A/dx^2\n",
    "A_hessian = jax.jacfwd(dA_dx, 0) # type: ignore\n",
    "\n",
    "@jit\n",
    "def d2A_dx2(coords, params):\n",
    "    #return jnp.diagonal(A_hessian(transform(coords), params))\n",
    "    return jnp.diag(A_hessian(coords, params))\n",
    "\n",
    "@jit\n",
    "def Hpsi(coords, coords_prime, params, alpha,g,sigma):\n",
    "    return Hpsi_without_delta(coords, params,sigma) + delta_potential(coords,coords_prime, params, alpha,g)\n",
    "\n",
    "@jit\n",
    "def sigma_term(coords,sigma):\n",
    "    N = num_particles \n",
    "    sigma_term = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            sigma_term += sigma* jnp.abs(coords[i] - coords[j])  \n",
    "\n",
    "@jit\n",
    "def Hpsi_without_delta(coords, params,sigma):\n",
    "   # sigma term\n",
    "    N = num_particles \n",
    "    sigma_term = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            sigma_term += sigma * jnp.abs(coords[i] - coords[j]) \n",
    "    # return jnp.sum((m*.5*omega**2*coords**2)) - hbar**2 / (2*m) * jnp.sum(ddpsi(coords, params) ) * 1/psi(coords, params) + sigma_term \n",
    "    return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + m*.5*harmonic_omega**2* jnp.sum(coords**2) + sigma_term\n",
    "    # return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2))\n",
    "    # return 1/(2*m) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + m*.5*omega**2* jnp.sum(coords**2)\n",
    "\n",
    "@jit\n",
    "def second_term(coords, params, g,sigma):\n",
    "    return dnn_dtheta(coords, params) * Hpsi_without_delta(coords, params,sigma)\n",
    "\n",
    "vsecond_term = jit(vmap(second_term, in_axes=(0, None, None,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def third_term(coords,coords_prime, params, y_max,g):\n",
    "    return dnn_dtheta(coords_prime, params) * delta_potential(coords, coords_prime, params, y_max, g)\n",
    "\n",
    "vthird_term = jit(vmap(third_term, in_axes=(0,0, None, None,None), out_axes=0))\n",
    "\n",
    "@jit\n",
    "def delta_potential(coords, coords_prime, params, alpha, g):\n",
    "    N = num_particles    \n",
    "    # compute e^(-2 NN(params_prime))\n",
    "    # ratio = jnp.exp(-2 * A(coords_prime, params) + 2 * A(coords, params))\n",
    "    ratio = (psi(coords_prime, params)**2)/(psi(coords, params)**2)\n",
    "    delta_dist = (1/(jnp.sqrt(jnp.pi) * alpha)) * jnp.exp(-(coords[1]**2)/(alpha**2))\n",
    "    return g * N*(N-1)/2 * ratio * delta_dist\n",
    "\n",
    "vdelta_potential = jit(vmap(delta_potential, in_axes=(0,0, None, None,None), out_axes=0))\n",
    "venergy = jit(vmap(Hpsi, in_axes=(0,0, None, None,None,None), out_axes=0))\n",
    "vHpsi_without_delta = jit(vmap(Hpsi_without_delta, in_axes=(0, None,None), out_axes=0))\n",
    "\n",
    "\n",
    "# derivative of the neural network with respect to every parameter\n",
    "# in Andy's notation this is dA/dtheta\n",
    "dnn_dtheta = jit(grad(A, 1)) \n",
    "vdnn_dtheta = vmap(dnn_dtheta, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "vboth = vmap(jnp.multiply, in_axes=(0, 0), out_axes=0)\n",
    "\n",
    "def gradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False,g=0,sigma=0):\n",
    "    # get the samples\n",
    "    samples, samples_prime  = sample_pmap(params, num_samples, thermal, skip, variation_size, jax.random.key(int(time.time())))\n",
    "#     samples, samples_prime,_ = sample(params, num_samples, thermal, skip, variation_size, INITIAL_SAMPLE)\n",
    "\n",
    "    y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "    alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "\n",
    "    psiHpsi = venergy(samples, samples_prime, params, alpha,g,sigma) \n",
    "    # Hpsi_terms_without_delta = vHpsi_without_delta(samples, params)\n",
    "    # delta_term = vdelta_potential(samples,samples_prime, params, samples)\n",
    "\n",
    "    # delta function additions\n",
    "    dA_dtheta = vdnn_dtheta(samples, params)\n",
    "    # dA_dtheta_repeated = vdnn_dtheta(samples_prime, params)\n",
    "\n",
    "    dA_dtheta_avg = 1/num_samples * jnp.sum(dA_dtheta, 0)\n",
    "\n",
    "    second_term = 1/num_samples * jnp.sum(vsecond_term(samples, params,g,sigma), 0)\n",
    "    third_term = 1/num_samples * jnp.sum(vthird_term(samples, samples_prime, params, alpha,g), 0)\n",
    "    # third_term =1/num_samples * jnp.sum(vboth(dA_dtheta_repeated,delta_term), 0)\n",
    "    uncert = jnp.std(psiHpsi)/jnp.sqrt(num_samples)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(psiHpsi)\n",
    "\n",
    "   \n",
    "    if verbose:\n",
    "        print(energy)\n",
    "\n",
    "    gradient_calc = 2 * energy * dA_dtheta_avg - 2 * second_term - 2*third_term\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "def ugradient(params, num_samples=10**3, thermal=200, skip=50, variation_size=1.0, verbose=False):\n",
    "\n",
    "    samples, samples_prime, _ = sample(params, num_samples, thermal, skip, variation_size)\n",
    "    y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "    alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "    Es = []\n",
    "    dA_dthetas = []\n",
    "    seconds = []\n",
    "    thirds = []\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        coord = samples[i]\n",
    "        coord_prime = samples_prime[i]\n",
    "\n",
    "        Es.append(Hpsi(coord, coord_prime, params, alpha))\n",
    "        dA_dthetas.append(dnn_dtheta(coord, params)) \n",
    "        seconds.append(second_term(coord, params))\n",
    "        thirds.append(third_term(coord, coord_prime, params, alpha))\n",
    "\n",
    "\n",
    "    Es = jnp.array(Es)\n",
    "    dA_dthetas = jnp.array(dA_dthetas)\n",
    "    seconds = jnp.array(seconds)\n",
    "    thirds = jnp.array(thirds)\n",
    "\n",
    "    energy = 1/num_samples * jnp.sum(Es)\n",
    "    avg_dA_dtheta = 1/num_samples * jnp.sum(dA_dthetas, 0)\n",
    "    second = 1/num_samples * jnp.sum(seconds, 0)\n",
    "    third =  1/num_samples * jnp.sum(thirds, 0)\n",
    "\n",
    "    uncert = jnp.std(Es)/jnp.sqrt(num_samples)\n",
    "    \n",
    "    gradient_calc = 2 * energy * avg_dA_dtheta - 2 * second - 2 * third\n",
    "    return gradient_calc, energy, uncert\n",
    "\n",
    "\n",
    "# define a function that takes in samples, bins them, and returns the average of each bin\n",
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "# define a function that gets all samples, and then bins them with different bin sizes\n",
    "def autocorrelation(params):\n",
    "    samples = sample(params, num_samples=10**3, thermalization_steps=200, skip_count=40, variation_size=1)[0]\n",
    "    energies = [Hpsi(s, params) for s in samples]\n",
    "    \n",
    "    bins = np.linspace(1, 100, 100, dtype=int)\n",
    "    # now plot the average energy as a function of the number of bins\n",
    "    us = []\n",
    "    for b_size in bins:\n",
    "        us.append(bin_samples(energies, b_size))\n",
    "    plt.scatter(bins, us)\n",
    "    plt.title(\"Bin size vs. Uncertainty\")\n",
    "    plt.xlabel(\"Bin size\")\n",
    "    plt.ylabel(\"Uncertainty\")\n",
    "    plt.show()\n",
    "\n",
    "def step(params_arg, step_num, N, thermal, skip, variation_size,g, sigma):\n",
    "        gr = gradient(params_arg, N, thermal, skip, variation_size,False,g,sigma)\n",
    "        # print(gr)\n",
    "        # hs.append(gr[1])\n",
    "        # us.append(gr[2])\n",
    "        opt_state = opt_init(params_arg)\n",
    "        new = opt_update(step_num, gr[0], opt_state)\n",
    "        return get_params(new), gr[1], gr[2]\n",
    "\n",
    "def train(params, iterations, N, thermal, skip, variation_size, g, sigma):\n",
    "    hs = []\n",
    "    us = []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in pbar:\n",
    "        new_params, energy, uncert = step(\n",
    "            old_params, step_num, N, thermal, skip, variation_size, g, sigma\n",
    "        )\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        # write the energy to the file\n",
    "        with open(FILENAME, mode=\"a\") as f:\n",
    "            f.write(str(energy) + \",\" + str(uncert) + \"\\n\")\n",
    "        with open(PARAMS_FILE, \"wb\") as f:\n",
    "            jnp.save(f, new_params)\n",
    "        old_params = new_params.copy()\n",
    "        pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n",
    "\n",
    "def train_notqdm(params, iterations, N, thermal, skip, variation_size):\n",
    "    hs = []\n",
    "    us = []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    old_params = params.copy()\n",
    "    for step_num in range(iterations):\n",
    "        new_params, energy, uncert = step(\n",
    "            old_params, step_num, N, thermal, skip, variation_size\n",
    "        )\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        # write the energy to the file\n",
    "        with open(FILENAME, mode=\"a\") as f:\n",
    "            f.write(str(energy) + \",\" + str(uncert) + \"\\n\")\n",
    "        with open(PARAMS_FILE, \"wb\") as f:\n",
    "            jnp.save(f, new_params)\n",
    "        old_params = new_params.copy()\n",
    "#         pbar.set_description(\"Energy = \" + str(energy), refresh=True)\n",
    "        print(str(energy))\n",
    "        if np.isnan(energy):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            break\n",
    "    clear_output(wait=True)\n",
    "    return hs, us, ns, old_params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_step_size(params, start):\n",
    "    lr = .1\n",
    "    target = 0.5\n",
    "    tolerance = .05\n",
    "    max_it = 1000\n",
    "    step = start\n",
    "    best_step = start\n",
    "    best_acc = 0\n",
    "    it_num = 0\n",
    "    # get the samples \n",
    "    _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "    # while the acceptance rate is not within +/- .5 of the target\n",
    "    while (acc < target - tolerance or acc > target + tolerance) and it_num < max_it:\n",
    "        it_num += 1\n",
    "        # if the acceptance rate is too low, increase the step size\n",
    "        if acc < target - tolerance:\n",
    "            step -= lr\n",
    "        # if the acceptance rate is too high, decrease the step size\n",
    "        elif acc > target + tolerance:\n",
    "            step += lr\n",
    "        # if we cross the target, decrease the learning rate and go back\n",
    "        if (acc < target and best_acc > target) or (acc > target and best_acc < target):\n",
    "            lr /= 2\n",
    "            step = best_step\n",
    "        # keep track of the best step size\n",
    "        if abs(acc - target) < abs(best_acc - target):\n",
    "            best_acc = acc\n",
    "            best_step = step\n",
    "        \n",
    "        # get the samples for the next step size\n",
    "        _, _, acc = sample(params, 1000, 100, 10, step)\n",
    "#     print(\"step size:\",best_step)\n",
    "    return best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters 2677\n",
      "Log of parameters 3.4276483711869328\n"
     ]
    }
   ],
   "source": [
    "print(\"number of parameters\" , len(nn.flatten_params()))\n",
    "print(\"Log of parameters\", np.log10(len(nn.flatten_params())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.51409285, dtype=float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(jnp.array([0,0]),nn.flatten_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.0040629461157613: 100%|██████████| 100/100 [00:12<00:00,  7.75it/s]\n"
     ]
    }
   ],
   "source": [
    "open(FILENAME, 'w').close()\n",
    "# start_params = nn.flatten_params()\n",
    "start_params = nn.flatten_params()\n",
    "# start_params = jnp.load(\"40_params_best.npy\", allow_pickle=True)\n",
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "\n",
    "g=0\n",
    "sigma = -g/2\n",
    "\n",
    "resultsa = train(start_params, 100, 2000, 50, 5, find_step_size(start_params, .85),g,sigma)\n",
    "# 0 -> energies\n",
    "# 1 -> uncert\n",
    "# 2 -> steps\n",
    "# 3 -> params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5004352965903432\n"
     ]
    }
   ],
   "source": [
    "print(resultsa[3][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.9917297503961474: 100%|██████████| 100/100 [00:14<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "g = .25\n",
    "sigma = -g/2\n",
    "resultsb = train(resultsa[3], 100, 2000, 50, 5, find_step_size(resultsa[3], 1), g, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.9562216026932746: 100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "g = .5\n",
    "sigma = -g/2\n",
    "\n",
    "resultsc = train(resultsb[3], 100, 3000, 1000, 3, find_step_size(resultsb[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.8916065033774874: 100%|██████████| 100/100 [00:22<00:00,  4.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "g = .75\n",
    "sigma = -g/2\n",
    "resultsd = train(resultsc[3], 100, 4000, 1000, 3, find_step_size(resultsc[3], 1),g,sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.8679182998570668: 100%|██████████| 100/100 [00:24<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10**(-3))\n",
    "g= .8\n",
    "sigma = -g/2\n",
    "resultse = train(resultsd[3], 100, 5000, 1000, 3, find_step_size(resultsd[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.7669546275485258: 100%|██████████| 2500/2500 [10:51<00:00,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# opt_init, opt_update, get_params = jax_opt.adam(10**(-4))\n",
    "g = 1.0\n",
    "sigma = -g/2\n",
    "resultsf = train(resultse[3], 2500, 5000, 1000, 3, find_step_size(resultse[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.44581480017345393: 100%|██████████| 200/200 [00:58<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# opt_init, opt_update, get_params = jax_opt.adam(10**(-4))\n",
    "g = 1.5\n",
    "sigma = -g/2\n",
    "resultsg = train(resultsf[3], 200, 6000, 1000, 3, find_step_size(resultsf[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 0.016646895841978475: 100%|██████████| 200/200 [00:56<00:00,  3.56it/s] \n"
     ]
    }
   ],
   "source": [
    "# opt_init, opt_update, get_params = jax_opt.adam(10**(-4))\n",
    "g = 2.0\n",
    "sigma = -g/2\n",
    "resultsh = train(resultsg[3], 200, 6000, 1000, 3, find_step_size(resultsg[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = -0.5480099344695954: 100%|██████████| 200/200 [01:04<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# opt_init, opt_update, get_params = jax_opt.adam(10**(-4))\n",
    "g = 2.5\n",
    "sigma = -g/2\n",
    "resultsi = train(resultsh[3], 200, 7000, 1000, 3, find_step_size(resultsh[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = -1.2396626848185064: 100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# opt_init, opt_update, get_params = jax_opt.adam(10**(-4))\n",
    "g = 3.0\n",
    "sigma = -g/2\n",
    "resultsj = train(resultsi[3], 200, 7000, 1000, 3, find_step_size(resultsi[3], 1),g,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2514(21)\n",
      "-1.2513517911681817\n",
      "0.002100013334054278\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "def harmonic_energy(n):\n",
    "    return .5 + 2*n - np.sqrt(2/np.pi) * (n+1/2)/g\n",
    "\n",
    "def astra_energy():\n",
    "    return (N * omega)/2 - m * g**2  * (N*(N**2 - 1))/(24)\n",
    "\n",
    "\n",
    "# true_energy = .5 * hbar * omega * num_particles\n",
    "# true_energy = harmonic_energy(0)\n",
    "true_energy = astra_energy()\n",
    "#g = 1, sigma = -g/2\n",
    "# true_energy = .75\n",
    "# g = .1, sigma = 0:\n",
    "# true_energy = 1.03881\n",
    "# g= .8, sigma= -g\n",
    "# true_energy = .9375\n",
    "# true_energy = 0.3098\n",
    "\n",
    "total_hists =  resultsa[0]  + resultsb[0]  + resultsc[0]  + resultsd[0]  + resultse[0]+ resultsf[0] + resultsg[0]+ resultsh[0]+ resultsi[0]+ resultsj[0]\n",
    "\n",
    "# + resultsd[0]\n",
    "total_uncerts = resultsa[1] + resultsb[1] + resultsc[1]   + resultsd[1]  + resultse[1]+ resultsf[1] + resultsg[1]+ resultsh[1]+ resultsi[1]+ resultsj[1]\n",
    "# + resultsd[1]\n",
    "\n",
    "# get index of minimum value\n",
    "min_val = np.min(total_hists)\n",
    "# min_val = total_hists[-1]\n",
    "min_index = total_hists.index(min_val)\n",
    "min_err = total_uncerts[min_index]\n",
    "val = gv.gvar(min_val, min_err)\n",
    "print(val)\n",
    "# fractional_error = (val - true_energy)/true_energy\n",
    "# print(\"Minimum value: \", val)\n",
    "# print(\"Fractional percent error: \", fractional_error * 100)\n",
    "\n",
    "plt.plot(np.arange(0, len(total_hists)), total_hists, label=\"Adam: \" + str(val))\n",
    "# plot the uncertainties\n",
    "a_hists = np.array(total_hists)\n",
    "a_uncerts = np.array(total_uncerts)\n",
    "plt.fill_between(np.arange(0,len(total_hists)), a_hists - a_uncerts, a_hists + a_uncerts, alpha=.4)\n",
    "# get the network structure\n",
    "structure = nn.hidden_sizes\n",
    "plt.annotate(\" Network Structure: \" + str(structure), xy=(0.1, 0.95), xycoords='axes fraction')\n",
    "plt.plot(np.arange(0, len(total_hists)), [true_energy for x in np.arange(0, len(total_hists))], label=r\"Analytic: \" + str(round(true_energy,3)))\n",
    "pdiff = (min_val - true_energy)/true_energy*100\n",
    "# plt.annotate(\" Final Percent Diff = \" + str(round(pdiff,3)) + \"%\", xy=(.1, .9), xycoords= 'axes fraction')\n",
    "plt.legend()\n",
    "plt.title(r\"Modified LL model ($g = $\" + str(g) + r\", $\\sigma =\" + str(sigma) + \"$), \" + str(num_particles) + \" particles\")\n",
    "print(min_val)\n",
    "print(min_err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3602\n",
      "-1.243234080346222\n"
     ]
    }
   ],
   "source": [
    "#finding the first step that has below 1% error\n",
    "for stepnum in range(len(total_hists)):\n",
    "    energy = total_hists[stepnum]\n",
    "    pdiff = (energy - true_energy)/true_energy * 100\n",
    "    if np.abs(pdiff) <= 1:\n",
    "        print(stepnum)\n",
    "        break\n",
    "print(total_hists[stepnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-261d663b85f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "def bin_samples(energies, bin_size):\n",
    "    # first, bin the samples\n",
    "    binned = np.array_split(energies, bin_size)\n",
    "    # now, calculate the average of each bin\n",
    "    binned_averages = [np.mean(b) for b in binned]\n",
    "    # now, calculate the uncertainty of each bin\n",
    "    bin_uncerts = np.std(binned_averages)/np.sqrt(bin_size)\n",
    "    return bin_uncerts\n",
    "\n",
    "\n",
    "samples, samples_prime, _ = sample(params, 4*10**4, 100, 10, 1)\n",
    "y_max = jnp.max(jnp.abs(jnp.array(samples[:,1])))\n",
    "alpha = y_max/(jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 10**(-10))))\n",
    "energies = venergy(samples,samples_prime, params, alpha)\n",
    "mean_energy = jnp.mean(energies)\n",
    "print(mean_energy)\n",
    "\n",
    "# bins = np.linspace(1, 100, 100, dtype=int)\n",
    "bins = np.array([1,2,5,10,20,50,100,150,200,250,300,360,450,500,550,600,660,750,900,990,1100])\n",
    "# now plot the average energy as a function of the number of bins\n",
    "us = []\n",
    "for b_size in bins:\n",
    "    us.append(bin_samples(energies, b_size))\n",
    "plt.scatter(bins, us)\n",
    "plt.title(\"Bin size vs. Uncertainty\")\n",
    "plt.xlabel(\"Bin size\")\n",
    "plt.ylabel(\"Uncertainty\")\n",
    "print(max(us))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = gv.gvar(mean_energy, max(us))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(-5, 5, .05)\n",
    "ys = np.arange(-5, 5, .05)\n",
    "wavs = []\n",
    "for i in range(len(xs)):\n",
    "    for j in range(len(ys)):\n",
    "        wavs.append(psi(np.array([xs[i], ys[j]]), params)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(xs,ys)\n",
    "Z = np.array(wavs).reshape(len(xs), len(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.contourf(X, Y, Z, 100)\n",
    "\n",
    "plt.plot(xs,-xs)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def astra_wf(coords):\n",
    "    ret = 1\n",
    "    a_s = -2/(m*g) \n",
    "    a_ho = jnp.sqrt(1/(m * harmonic_omega))\n",
    "    for i in range(N):\n",
    "        for j in range(0,i):\n",
    "            ret *= jnp.exp(-jnp.abs(coords[i] - coords[j])/a_s)\n",
    "        ret *= jnp.exp(-coords[i]**2/(2*a_ho**2))\n",
    "    return ret\n",
    "\n",
    "@jit\n",
    "def mcstep_E_exact(xis, limit, positions):\n",
    "    newpositions = jnp.array(positions) + xis\n",
    "    \n",
    "    prob = astra_wf(newpositions)**2 / astra_wf(positions)**2\n",
    "    \n",
    "    def truefunc(p):\n",
    "        return [newpositions, True]\n",
    "\n",
    "    def falsefunc(p):\n",
    "        return [positions, False]\n",
    "    \n",
    "    return jax.lax.cond(prob >= limit, truefunc, falsefunc, prob)\n",
    "\n",
    "def sample_exact(Nsweeps, Ntherm, keep, stepsize, positions_initial=INITIAL_SAMPLE, progress=False):\n",
    "    sq = []\n",
    "    sq_prime = []\n",
    "    counter = 0\n",
    "    num_total = Nsweeps * keep + Ntherm + 1 \n",
    "\n",
    "    randoms = np.random.uniform(-stepsize, stepsize, size = (num_total, N))\n",
    "    limits = np.random.uniform(0, 1, size = num_total)\n",
    "\n",
    "    positions_prev = positions_initial\n",
    "    \n",
    "    if progress:\n",
    "        for i in tqdm(range(0, num_total), position = 0, leave = True, desc = \"MC\"):\n",
    "            \n",
    "            new, moved = mcstep_E_exact(randoms[i], limits[i], positions_prev)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "                \n",
    "    else: \n",
    "        for i in range(num_total):\n",
    "            new, moved = mcstep_E_exact(randoms[i], limits[i], positions_prev)\n",
    "        \n",
    "            if moved == True:\n",
    "                counter += 1\n",
    "                \n",
    "            if i%keep == 0 and i >= Ntherm:\n",
    "                #sq = np.vstack((sq, np.array(new)))\n",
    "                sq.append(new)\n",
    "                \n",
    "            positions_prev = new\n",
    "    # generate the primed samples by going through every sample and making sample[N_up] = sample[0]\n",
    "    sq_prime = sq.copy()\n",
    "    for i in range(len(sq)):\n",
    "        a = np.array(sq[i])\n",
    "        a[1] = a[0]\n",
    "        sq_prime[i] = jnp.array(a) \n",
    "\n",
    "    return jnp.array(sq), jnp.array(sq_prime), counter/num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(params, 3 * 10**4, 100, 10, .85)\n",
    "samples_exact = sample_exact(3 * 10**4, 100, 10, .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_density(samples):\n",
    "    x_bins = np.linspace(-9, 9, 72)\n",
    "    dx = x_bins[1] - x_bins[0]  # Bin width\n",
    "    n_x = np.zeros_like(x_bins)\n",
    "\n",
    "    # bin the x_1s\n",
    "    for x in samples[0][:,0]:\n",
    "        n_x[np.digitize(x, x_bins)] += 1\n",
    "\n",
    "    # Normalize\n",
    "    n_x /= (dx * np.sum(n_x))\n",
    "\n",
    "    return x_bins, n_x\n",
    "\n",
    "x_bins, n_x = local_density(samples)\n",
    "x_bins_exact, n_x_exact = local_density(samples_exact)\n",
    "plt.plot(x_bins, n_x,'-o', markersize=2, color=\"red\")\n",
    "plt.plot(x_bins_exact, n_x_exact,'-o', markersize=2, color=\"black\")\n",
    "plt.title(r\"$N = 2$ Local Density Profile\")\n",
    "plt.xlabel(\"$x$\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.ylabel(\"$n(x)/\\int dx n(x)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
